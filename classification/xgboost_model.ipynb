{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\"Machine learning tools\"\n",
    "import pickle\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "\n",
    "\n",
    "from classification.datasets import Dataset\n",
    "from classification.utils.audio_student import AudioUtil, Feature_vector_DS\n",
    "\n",
    "from classification.utils.plots import (\n",
    "    plot_decision_boundaries,\n",
    "    plot_specgram,\n",
    "    show_confusion_matrix,\n",
    ")\n",
    "from classification.utils.utils import accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chainsaw\n",
      "fire\n",
      "fireworks\n",
      "gunshot\n"
     ]
    }
   ],
   "source": [
    "### TO RUN\n",
    "dataset = Dataset()\n",
    "classnames = dataset.list_classes()\n",
    "\n",
    "print(\"\\n\".join(classnames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TO RUN\n",
    "fm_dir = \"data/feature_matrices/\"  # where to save the features matrices\n",
    "new_dataset_dir = \"src/classification/datasets/new_dataset/melvecs/\"\n",
    "model_dir = \"data/models/xgboost\"  # where to save the models\n",
    "os.makedirs(fm_dir, exist_ok=True)\n",
    "os.makedirs(model_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TO RUN\n",
    "\n",
    "\"Creation of the dataset\"\n",
    "myds = Feature_vector_DS(dataset, Nft=512, nmel=20, duration=950, shift_pct=0.0)\n",
    "\n",
    "\"Some attributes...\"\n",
    "myds.nmel\n",
    "myds.duration\n",
    "myds.shift_pct\n",
    "myds.sr\n",
    "myds.data_aug\n",
    "myds.ncol\n",
    "\n",
    "idx = 0\n",
    "\n",
    "# XGBOOST PARAMETERS\n",
    "n_estimators = 259\n",
    "max_depth = 9\n",
    "learning_rate = 0.2446\n",
    "subsample = 0.5064\n",
    "colsample_bytree = 0.8427"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRANSFORMATION ON FEATURE VECTOR\n",
    "\n",
    "def add_noise(feature_vector, snr_db=20):\n",
    "    \"\"\"Adds white noise to a feature vector based on the given SNR (Signal-to-Noise Ratio).\"\"\"\n",
    "    power_signal = np.mean(feature_vector ** 2)\n",
    "    power_noise = power_signal / (10 ** (snr_db / 10))\n",
    "    noise = np.random.normal(0, np.sqrt(power_noise), feature_vector.shape)\n",
    "    return feature_vector + noise\n",
    "\n",
    "def shifting(feature_vector, shift_max=20):\n",
    "    \"\"\"Shifts mel spectrogram feature vectors along the time axis by a random shift between 0 and shift_max.\"\"\"\n",
    "    shift = np.random.randint(0, shift_max)\n",
    "    return np.roll(feature_vector, shift, axis=0)  # Rolling along the first axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the basic feature matrix : (268, 400)\n",
      "Number of labels : (268,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "\n",
    "train_pct = 0.7\n",
    "data_aug_factor = 1\n",
    "featveclen = len(myds[\"fire\", 0, \"\", \"\"])  # Same for all classes\n",
    "classnames = [\"chainsaw\", \"fire\", \"fireworks\", \"gunshot\"]  # Or wherever you store class names\n",
    "nclass = len(classnames)\n",
    "\n",
    "# Determine number of samples per class\n",
    "naudio_per_class = {\"chainsaw\" : 76, \"fire\" : 76, \"fireworks\" : 76, \"gunshot\" : 40}\n",
    "\n",
    "\n",
    "# Allocate feature matrix\n",
    "total_samples_basic = sum(naudio_per_class[c] for c in classnames)\n",
    "X_basic = np.zeros((total_samples_basic, featveclen))\n",
    "y_basic = np.zeros((total_samples_basic), dtype=object)\n",
    "total_samples_basic\n",
    "# Fill feature matrix\n",
    "idx = 0\n",
    "for class_idx, classname in enumerate(classnames):\n",
    "    for i in range(naudio_per_class[classname]):\n",
    "        featvec = myds[classname, i, \"\", \"\"]\n",
    "        X_basic[idx, :] = featvec\n",
    "        y_basic[idx] = classname\n",
    "        idx += 1\n",
    "\n",
    "# Save features and labels\n",
    "np.save(fm_dir + \"X_basic.npy\", X_basic)\n",
    "np.save(fm_dir + \"y_basic.npy\", y_basic)\n",
    "\n",
    "print(f\"Shape of the basic feature matrix : {X_basic.shape}\")\n",
    "print(f\"Number of labels : {y_basic.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now create a new augmented dataset and observe if the classification results improve. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of transformations :  3\n",
      "Shape of the feature matrix : (804, 400)\n",
      "Number of labels : (804,)\n",
      "------------------------------------------------------------\n",
      "Transformations: ['original', 'noise', 'shifting']. Labels aligned dynamically with class sizes.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "### AUGMENTED DATASET\n",
    "list_augmentation = [\"original\", \"noise\", \"shifting\"]\n",
    "myds.mod_data_aug(list_augmentation)\n",
    "print(\"Number of transformations : \", myds.data_aug_factor)\n",
    "\n",
    "\n",
    "# Calcul total des Ã©chantillons\n",
    "total_aug_samples = sum(naudio_per_class[c] for c in classnames) * len(list_augmentation)\n",
    "X_basic_aug = np.zeros((total_aug_samples, featveclen))\n",
    "y_basic_aug = np.zeros((total_aug_samples), dtype=object)\n",
    "\n",
    "# Remplissage des features\n",
    "idx = 0\n",
    "for aug in list_augmentation:\n",
    "    for classname in classnames:\n",
    "        for i in range(naudio_per_class[classname]):\n",
    "            featvec = myds[classname, i, aug, \"\"]\n",
    "            X_basic_aug[idx, :] = featvec\n",
    "            y_basic_aug[idx] = classname\n",
    "            idx += 1\n",
    "\n",
    "# Sauvegarde\n",
    "np.save(fm_dir + \"X_basic_aug.npy\", X_basic_aug)\n",
    "np.save(fm_dir + \"y_basic_aug.npy\", y_basic_aug)\n",
    "\n",
    "print(f\"Shape of the feature matrix : {X_basic_aug.shape}\")\n",
    "print(f\"Number of labels : {y_basic_aug.shape}\")\n",
    "print(f\"------------------------------------------------------------\")\n",
    "print(f\"Transformations: {list_augmentation}. Labels aligned dynamically with class sizes.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot specgram(myds[\"chainsaw1\", 0, \"original\", \"\"])\n",
    "from classification.utils.plots import plot_specgram_textlabel\n",
    "X_basic_aug = np.load(os.path.join(fm_dir, \"X_basic_aug.npy\"))\n",
    "melvec = X_basic_aug[132]\n",
    "plot_specgram_textlabel(\n",
    "    melvec.reshape((20, 20)),\n",
    "    ax=plt.gca(),\n",
    "    is_mel=True,\n",
    "    title=f\"MEL Spectrogram #{20}\",\n",
    "    xlabel=\"Mel vector\",\n",
    "    textlabel=\"\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FINAL MODEL SAVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "TEST_SET = False\n",
    "\n",
    "# Load datasets\n",
    "X_basic_aug = np.load(os.path.join(fm_dir, \"X_basic_aug.npy\"))\n",
    "y_basic_aug = np.load(os.path.join(fm_dir, \"y_basic_aug.npy\"), allow_pickle=True)\n",
    "\n",
    "X_basic = np.load(os.path.join(fm_dir, \"X_basic.npy\"))\n",
    "y_basic = np.load(os.path.join(fm_dir, \"y_basic.npy\"), allow_pickle=True)\n",
    "\n",
    "# Encode labels\n",
    "label_encoder = LabelEncoder()\n",
    "y_basic = label_encoder.fit_transform(y_basic)\n",
    "y_basic_aug = label_encoder.transform(y_basic_aug)\n",
    "\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "if TEST_SET:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_basic, y_basic, test_size=0.3, random_state=42)\n",
    "    X_train_aug, X_test_aug, y_train_aug, y_test_aug = train_test_split(X_basic_aug, y_basic_aug, test_size=0.3, random_state=42)\n",
    "else:\n",
    "    X_train = X_basic\n",
    "    y_train = y_basic\n",
    "    X_train_aug = X_basic_aug\n",
    "    y_train_aug = y_basic_aug\n",
    "\n",
    "# =========================\n",
    "# SCENARIO A: WITH PCA (no aug)\n",
    "# =========================\n",
    "pca = PCA(n_components=0.98)\n",
    "X_train_pca = pca.fit_transform(X_train)\n",
    "if TEST_SET:\n",
    "    X_test_pca = pca.transform(X_test)\n",
    "\n",
    "pca_filename = os.path.join(model_dir, \"pca_noaug_nonorm.pickle\")\n",
    "with open(pca_filename, \"wb\") as f:\n",
    "    pickle.dump(pca, f)\n",
    "\n",
    "xgb_pca = XGBClassifier(n_estimators=100, max_depth=5, learning_rate=0.1,\n",
    "                        subsample=0.8, colsample_bytree=0.8, eval_metric='mlogloss', random_state=42)\n",
    "xgb_pca.fit(X_train_pca, y_train)\n",
    "\n",
    "model_filename = os.path.join(model_dir, \"xgb_pca_noaug_nonorm.pickle\")\n",
    "with open(model_filename, \"wb\") as f:\n",
    "    pickle.dump(xgb_pca, f)\n",
    "\n",
    "# =========================\n",
    "# SCENARIO B: WITHOUT PCA (no aug)\n",
    "# =========================\n",
    "xgb_no_pca = XGBClassifier(n_estimators=100, max_depth=5, learning_rate=0.1,\n",
    "                           subsample=0.8, colsample_bytree=0.8, eval_metric='mlogloss', random_state=42)\n",
    "xgb_no_pca.fit(X_train, y_train)\n",
    "\n",
    "model_filename = os.path.join(model_dir, \"xgb_nopca_noaug_nonorm.pickle\")\n",
    "with open(model_filename, \"wb\") as f:\n",
    "    pickle.dump(xgb_no_pca, f)\n",
    "\n",
    "# =========================\n",
    "# SCENARIO C: WITH PCA (aug)\n",
    "# =========================\n",
    "pca = PCA(n_components=0.98)\n",
    "X_train_aug_pca = pca.fit_transform(X_train_aug)\n",
    "if TEST_SET:\n",
    "    X_test_aug_pca = pca.transform(X_test_aug)\n",
    "\n",
    "pca_filename = os.path.join(model_dir, \"pca_aug_nonorm.pickle\")\n",
    "with open(pca_filename, \"wb\") as f:\n",
    "    pickle.dump(pca, f)\n",
    "\n",
    "xgb_model_pca = XGBClassifier(n_estimators=n_estimators, max_depth=max_depth, learning_rate=learning_rate,\n",
    "                              subsample=subsample, colsample_bytree=colsample_bytree,\n",
    "                              eval_metric='mlogloss', random_state=42)\n",
    "xgb_model_pca.fit(X_train_aug_pca, y_train_aug)\n",
    "\n",
    "model_filename = os.path.join(model_dir, \"xgb_pca_aug_nonorm.pickle\")\n",
    "with open(model_filename, \"wb\") as f:\n",
    "    pickle.dump(xgb_model_pca, f)\n",
    "\n",
    "# =========================\n",
    "# SCENARIO D: WITHOUT PCA (aug)\n",
    "# =========================\n",
    "xgb_model_no_pca = XGBClassifier(n_estimators=n_estimators, max_depth=max_depth, learning_rate=learning_rate,\n",
    "                                 subsample=subsample, colsample_bytree=colsample_bytree,\n",
    "                                 eval_metric='mlogloss', random_state=42)\n",
    "xgb_model_no_pca.fit(X_train_aug, y_train_aug)\n",
    "\n",
    "model_filename = os.path.join(model_dir, \"xgb_nopca_aug_nonorm.pickle\")\n",
    "with open(model_filename, \"wb\") as f:\n",
    "    pickle.dump(xgb_model_no_pca, f)\n",
    "\n",
    "# =========================\n",
    "# SCENARIO E: NO DATA TRANSFORMATION (no aug)\n",
    "# =========================\n",
    "xgb_model_no_transform = XGBClassifier(n_estimators=n_estimators, max_depth=max_depth, learning_rate=learning_rate,\n",
    "                                       subsample=subsample, colsample_bytree=colsample_bytree,\n",
    "                                       eval_metric='mlogloss', random_state=42)\n",
    "xgb_model_no_transform.fit(X_train, y_train)\n",
    "\n",
    "model_filename = os.path.join(model_dir, \"xgb_nopca_noaug_nonorm.pickle\")\n",
    "with open(model_filename, \"wb\") as f:\n",
    "    pickle.dump(xgb_model_no_transform, f)\n",
    "\n",
    "# =========================\n",
    "# SCENARIO F: NORMALIZATION + PCA (no aug)\n",
    "# =========================\n",
    "X_train_norm = np.array([x/np.linalg.norm(x) if np.linalg.norm(x) != 0 else x for x in X_train])\n",
    "if TEST_SET:\n",
    "    X_test_norm = np.array([x/np.linalg.norm(x) if np.linalg.norm(x) != 0 else x for x in X_test])\n",
    "\n",
    "pca = PCA(n_components=0.98)\n",
    "X_train_norm_pca = pca.fit_transform(X_train_norm)\n",
    "if TEST_SET:\n",
    "    X_test_norm_pca = pca.transform(X_test_norm)\n",
    "\n",
    "pca_filename = os.path.join(model_dir, \"pca_noaug_norm.pickle\")\n",
    "with open(pca_filename, \"wb\") as f:\n",
    "    pickle.dump(pca, f)\n",
    "\n",
    "xgb_model_norm_pca = XGBClassifier(n_estimators=n_estimators, max_depth=max_depth, learning_rate=learning_rate,\n",
    "                                   subsample=subsample, colsample_bytree=colsample_bytree,\n",
    "                                   eval_metric='mlogloss', random_state=42)\n",
    "xgb_model_norm_pca.fit(X_train_norm_pca, y_train)\n",
    "\n",
    "model_filename = os.path.join(model_dir, \"xgb_pca_noaug_norm.pickle\")\n",
    "with open(model_filename, \"wb\") as f:\n",
    "    pickle.dump(xgb_model_norm_pca, f)\n",
    "\n",
    "# =========================\n",
    "# SCENARIO G: NORMALIZATION + AUG + PCA\n",
    "# =========================\n",
    "X_train_aug_norm = np.array([x/np.linalg.norm(x) if np.linalg.norm(x) != 0 else x for x in X_train_aug])\n",
    "if TEST_SET:\n",
    "    X_test_aug_norm = np.array([x/np.linalg.norm(x) if np.linalg.norm(x) != 0 else x for x in X_test_aug])\n",
    "\n",
    "pca = PCA(n_components=0.98)\n",
    "X_train_aug_norm_pca = pca.fit_transform(X_train_aug_norm)\n",
    "if TEST_SET:\n",
    "    X_test_aug_norm_pca = pca.transform(X_test_aug_norm)\n",
    "\n",
    "pca_filename = os.path.join(model_dir, \"pca_aug_norm.pickle\")\n",
    "with open(pca_filename, \"wb\") as f:\n",
    "    pickle.dump(pca, f)\n",
    "\n",
    "xgb_model_norm_aug_pca = XGBClassifier(n_estimators=n_estimators, max_depth=max_depth, learning_rate=learning_rate,\n",
    "                                       subsample=subsample, colsample_bytree=colsample_bytree,\n",
    "                                       eval_metric='mlogloss', random_state=42)\n",
    "xgb_model_norm_aug_pca.fit(X_train_aug_norm_pca, y_train_aug)\n",
    "\n",
    "model_filename = os.path.join(model_dir, \"xgb_pca_aug_norm.pickle\")\n",
    "with open(model_filename, \"wb\") as f:\n",
    "    pickle.dump(xgb_model_norm_aug_pca, f)\n",
    "\n",
    "# =========================\n",
    "# EVALUATION FUNCTION\n",
    "# =========================\n",
    "def evaluate_model(model, X_test, y_test, description):\n",
    "    predict = model.predict(X_test)\n",
    "\n",
    "    classes = np.unique(y_test)\n",
    "    precision_per_class = precision_score(y_test, predict, average=None, labels=classes)\n",
    "    recall_per_class = recall_score(y_test, predict, average=None, labels=classes)\n",
    "    test_accuracy_per_class = []\n",
    "    conf_matrix = confusion_matrix(y_test, predict, labels=classes)\n",
    "\n",
    "    for i, cls in enumerate(classes):\n",
    "        acc = conf_matrix[i, i] / conf_matrix[i, :].sum()\n",
    "        test_accuracy_per_class.append(acc)\n",
    "\n",
    "    cv_scores = cross_val_score(model, X_test, y_test, cv=5, scoring='accuracy')\n",
    "    mean_cv_accuracy = np.mean(cv_scores)\n",
    "\n",
    "    print(f\"\\n=== {description} ===\")\n",
    "    print(f\"Test Accuracy (Overall): {np.mean(predict == y_test):.4f}\")\n",
    "    print(f\"Mean CV Accuracy: {mean_cv_accuracy:.4f}\")\n",
    "\n",
    "    print(\"\\nPer-Class Metrics:\")\n",
    "    for i, cls in enumerate(classes):\n",
    "        print(f\"Class {cls}: Precision={precision_per_class[i]:.4f}, Recall={recall_per_class[i]:.4f}, Accuracy={test_accuracy_per_class[i]:.4f}\")\n",
    "\n",
    "# =========================\n",
    "# EVALUATE ALL MODELS\n",
    "# =========================\n",
    "if TEST_SET:\n",
    "    evaluate_model(xgb_pca, X_test_pca, y_test, \"Scenario A: PCA NOAUG NONORM\")\n",
    "    evaluate_model(xgb_no_pca, X_test, y_test, \"Scenario B: NOPCA NOAUG NONORM\")\n",
    "    evaluate_model(xgb_model_pca, X_test_aug_pca, y_test_aug, \"Scenario C: PCA AUG NONORM\")\n",
    "    evaluate_model(xgb_model_no_pca, X_test, y_test, \"Scenario D: NOPCA AUG NONORM\")\n",
    "    evaluate_model(xgb_model_no_transform, X_test, y_test, \"Scenario E: NOPCA NOAUG NONORM\")\n",
    "    evaluate_model(xgb_model_norm_pca, X_test_norm_pca, y_test, \"Scenario F: PCA NOAUG NORM\")\n",
    "    evaluate_model(xgb_model_norm_aug_pca, X_test_aug_norm_pca, y_test_aug, \"Scenario G: PCA AUG NORM\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HYPERPARAMETER TUNING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Bayesian Optimization...\n",
      "|   iter    |  target   | colsam... | learni... | max_depth | n_esti... | subsample |\n",
      "-------------------------------------------------------------------------------------\n",
      "| \u001b[39m1        \u001b[39m | \u001b[39m0.919    \u001b[39m | \u001b[39m0.6873   \u001b[39m | \u001b[39m0.2857   \u001b[39m | \u001b[39m11.52    \u001b[39m | \u001b[39m259.5    \u001b[39m | \u001b[39m0.578    \u001b[39m |\n",
      "| \u001b[39m2        \u001b[39m | \u001b[39m0.9103   \u001b[39m | \u001b[39m0.578    \u001b[39m | \u001b[39m0.02684  \u001b[39m | \u001b[39m13.26    \u001b[39m | \u001b[39m260.4    \u001b[39m | \u001b[39m0.854    \u001b[39m |\n",
      "| \u001b[35m3        \u001b[39m | \u001b[35m0.9203   \u001b[39m | \u001b[35m0.5103   \u001b[39m | \u001b[35m0.2913   \u001b[39m | \u001b[35m12.82    \u001b[39m | \u001b[35m124.3    \u001b[39m | \u001b[35m0.5909   \u001b[39m |\n",
      "| \u001b[39m4        \u001b[39m | \u001b[39m0.919    \u001b[39m | \u001b[39m0.7083   \u001b[39m | \u001b[39m0.2484   \u001b[39m | \u001b[39m13.05    \u001b[39m | \u001b[39m124.2    \u001b[39m | \u001b[39m0.8287   \u001b[39m |\n",
      "| \u001b[39m5        \u001b[39m | \u001b[39m0.9165   \u001b[39m | \u001b[39m0.5358   \u001b[39m | \u001b[39m0.1226   \u001b[39m | \u001b[39m11.52    \u001b[39m | \u001b[39m124.8    \u001b[39m | \u001b[39m0.8773   \u001b[39m |\n",
      "| \u001b[39m6        \u001b[39m | \u001b[39m0.9103   \u001b[39m | \u001b[39m0.584    \u001b[39m | \u001b[39m0.02728  \u001b[39m | \u001b[39m10.21    \u001b[39m | \u001b[39m258.8    \u001b[39m | \u001b[39m0.5973   \u001b[39m |\n",
      "| \u001b[35m7        \u001b[39m | \u001b[35m0.9277   \u001b[39m | \u001b[35m0.7569   \u001b[39m | \u001b[35m0.2999   \u001b[39m | \u001b[35m12.08    \u001b[39m | \u001b[35m123.7    \u001b[39m | \u001b[35m0.571    \u001b[39m |\n",
      "| \u001b[39m8        \u001b[39m | \u001b[39m0.9227   \u001b[39m | \u001b[39m0.6008   \u001b[39m | \u001b[39m0.2221   \u001b[39m | \u001b[39m12.36    \u001b[39m | \u001b[39m122.9    \u001b[39m | \u001b[39m0.573    \u001b[39m |\n",
      "| \u001b[39m9        \u001b[39m | \u001b[39m0.9065   \u001b[39m | \u001b[39m0.7425   \u001b[39m | \u001b[39m0.06019  \u001b[39m | \u001b[39m11.64    \u001b[39m | \u001b[39m123.5    \u001b[39m | \u001b[39m0.9047   \u001b[39m |\n",
      "| \u001b[39m10       \u001b[39m | \u001b[39m0.9115   \u001b[39m | \u001b[39m0.5377   \u001b[39m | \u001b[39m0.2455   \u001b[39m | \u001b[39m8.067    \u001b[39m | \u001b[39m157.0    \u001b[39m | \u001b[39m0.6494   \u001b[39m |\n",
      "| \u001b[39m11       \u001b[39m | \u001b[39m0.9215   \u001b[39m | \u001b[39m0.7869   \u001b[39m | \u001b[39m0.2147   \u001b[39m | \u001b[39m11.51    \u001b[39m | \u001b[39m259.9    \u001b[39m | \u001b[39m0.6792   \u001b[39m |\n",
      "| \u001b[39m12       \u001b[39m | \u001b[39m0.9153   \u001b[39m | \u001b[39m0.7158   \u001b[39m | \u001b[39m0.2875   \u001b[39m | \u001b[39m12.25    \u001b[39m | \u001b[39m122.9    \u001b[39m | \u001b[39m0.5339   \u001b[39m |\n",
      "| \u001b[39m13       \u001b[39m | \u001b[39m0.9215   \u001b[39m | \u001b[39m0.5668   \u001b[39m | \u001b[39m0.2238   \u001b[39m | \u001b[39m5.918    \u001b[39m | \u001b[39m116.3    \u001b[39m | \u001b[39m0.6134   \u001b[39m |\n",
      "| \u001b[39m14       \u001b[39m | \u001b[39m0.9265   \u001b[39m | \u001b[39m0.6357   \u001b[39m | \u001b[39m0.199    \u001b[39m | \u001b[39m2.808    \u001b[39m | \u001b[39m311.5    \u001b[39m | \u001b[39m0.9796   \u001b[39m |\n",
      "| \u001b[39m15       \u001b[39m | \u001b[39m0.9128   \u001b[39m | \u001b[39m0.5819   \u001b[39m | \u001b[39m0.03932  \u001b[39m | \u001b[39m5.093    \u001b[39m | \u001b[39m369.3    \u001b[39m | \u001b[39m0.8976   \u001b[39m |\n",
      "| \u001b[39m16       \u001b[39m | \u001b[39m0.924    \u001b[39m | \u001b[39m0.8887   \u001b[39m | \u001b[39m0.1137   \u001b[39m | \u001b[39m12.89    \u001b[39m | \u001b[39m377.1    \u001b[39m | \u001b[39m0.5815   \u001b[39m |\n",
      "| \u001b[39m17       \u001b[39m | \u001b[39m0.9128   \u001b[39m | \u001b[39m0.7528   \u001b[39m | \u001b[39m0.1584   \u001b[39m | \u001b[39m12.29    \u001b[39m | \u001b[39m165.6    \u001b[39m | \u001b[39m0.9612   \u001b[39m |\n",
      "| \u001b[39m18       \u001b[39m | \u001b[39m0.9153   \u001b[39m | \u001b[39m0.9319   \u001b[39m | \u001b[39m0.1759   \u001b[39m | \u001b[39m7.411    \u001b[39m | \u001b[39m114.1    \u001b[39m | \u001b[39m0.6407   \u001b[39m |\n",
      "| \u001b[39m19       \u001b[39m | \u001b[39m0.9078   \u001b[39m | \u001b[39m0.8124   \u001b[39m | \u001b[39m0.2313   \u001b[39m | \u001b[39m6.986    \u001b[39m | \u001b[39m116.5    \u001b[39m | \u001b[39m0.9188   \u001b[39m |\n",
      "| \u001b[39m20       \u001b[39m | \u001b[39m0.8917   \u001b[39m | \u001b[39m0.7831   \u001b[39m | \u001b[39m0.02513  \u001b[39m | \u001b[39m6.734    \u001b[39m | \u001b[39m107.1    \u001b[39m | \u001b[39m0.5775   \u001b[39m |\n",
      "| \u001b[39m21       \u001b[39m | \u001b[39m0.9178   \u001b[39m | \u001b[39m0.768    \u001b[39m | \u001b[39m0.2425   \u001b[39m | \u001b[39m12.74    \u001b[39m | \u001b[39m242.3    \u001b[39m | \u001b[39m0.7731   \u001b[39m |\n",
      "| \u001b[39m22       \u001b[39m | \u001b[39m0.9203   \u001b[39m | \u001b[39m0.8227   \u001b[39m | \u001b[39m0.2926   \u001b[39m | \u001b[39m12.19    \u001b[39m | \u001b[39m123.8    \u001b[39m | \u001b[39m0.716    \u001b[39m |\n",
      "| \u001b[39m23       \u001b[39m | \u001b[39m0.9228   \u001b[39m | \u001b[39m0.9783   \u001b[39m | \u001b[39m0.1456   \u001b[39m | \u001b[39m2.821    \u001b[39m | \u001b[39m311.6    \u001b[39m | \u001b[39m0.6769   \u001b[39m |\n",
      "=====================================================================================\n",
      "Iteration 1, CV Accuracy: 0.9190, Parameters: {'colsample_bytree': np.float64(0.6872700594236812), 'learning_rate': np.float64(0.28570714885887566), 'max_depth': np.float64(11.515921243548267), 'n_estimators': np.float64(259.5304694689628), 'subsample': np.float64(0.5780093202212182)}\n",
      "\n",
      "Early stopping: Found cross-validation accuracy above 0.9\n",
      "\n",
      "\n",
      "=== BEST HYPERPARAMETERS FOUND ===\n",
      "n_estimators = 123\n",
      "max_depth = 12\n",
      "learning_rate = 0.2999\n",
      "subsample = 0.5710\n",
      "colsample_bytree = 0.7569\n",
      "CV Accuracy = 0.9277\n",
      "\n",
      "=== FINAL EVALUATION ON HOLDOUT TEST SET ===\n",
      "Test Accuracy: 0.8802\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score\n",
    "from bayes_opt import BayesianOptimization\n",
    "\n",
    "# Your custom accuracy function\n",
    "from classification.utils.utils import accuracy\n",
    "\n",
    "# --- CONFIG FLAGS ---\n",
    "NORMALIZATION = False\n",
    "TRANSFORMATION = True\n",
    "\n",
    "# --- STEP 1: Load/Select Data ---\n",
    "if TRANSFORMATION:\n",
    "    try:\n",
    "        X = X_basic_aug   # Make sure X_basic_aug is defined in your environment\n",
    "        y = y_basic_aug   # Make sure y_basic_aug is defined in your environment\n",
    "    except NameError:\n",
    "        raise ValueError(\"X_aug and y_aug must be defined before running this script.\")\n",
    "else:\n",
    "    try:\n",
    "        X = X_basic       # Make sure X_basic is defined in your environment\n",
    "        y = y_basic       # Make sure y_basic is defined in your environment\n",
    "    except NameError:\n",
    "        raise ValueError(\"X and y must be defined before running this script.\")\n",
    "\n",
    "# Optional normalization\n",
    "if NORMALIZATION:\n",
    "    X = np.array([\n",
    "        x / np.linalg.norm(x) if np.linalg.norm(x) != 0 else x\n",
    "        for x in X\n",
    "    ])\n",
    "\n",
    "# --- STEP 2: Define the Objective Function for Bayesian Optimization ---\n",
    "def xgb_cv(\n",
    "    n_estimators,\n",
    "    max_depth,\n",
    "    learning_rate,\n",
    "    subsample,\n",
    "    colsample_bytree\n",
    "):\n",
    "    \"\"\"\n",
    "    This function trains an XGBClassifier with given hyperparameters\n",
    "    and returns the mean CV accuracy as the objective to maximize.\n",
    "    \"\"\"\n",
    "    # Convert some parameters to int, as required by XGBoost\n",
    "    n_estimators = int(n_estimators)\n",
    "    max_depth = int(max_depth)\n",
    "\n",
    "    model = XGBClassifier(n_estimators=n_estimators, max_depth=max_depth, learning_rate=learning_rate, subsample=subsample, colsample_bytree=colsample_bytree,\n",
    "        eval_metric='mlogloss',\n",
    "        # remove use_label_encoder (deprecated)\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    # 5-fold cross-validation on the *entire dataset* X, y\n",
    "    cv_scores = cross_val_score(model, X, y, cv=5, scoring='accuracy')\n",
    "    \n",
    "    # Return the mean of cross-validation accuracy\n",
    "    return cv_scores.mean()\n",
    "\n",
    "# --- STEP 3: Set Up the Bayesian Optimizer ---\n",
    "# Hyperparameter search space\n",
    "pbounds = {\n",
    "    'n_estimators': (50, 400),      # e.g. from 50 to 300\n",
    "    'max_depth': (2, 15),           # integer between 2 and 12\n",
    "    'learning_rate': (0.01, 0.3),   # from 0.01 to 0.3\n",
    "    'subsample': (0.5, 1),        # from 0.5 to 1.0\n",
    "    'colsample_bytree': (0.5, 1)  # from 0.5 to 1.0\n",
    "}\n",
    "\n",
    "optimizer = BayesianOptimization(\n",
    "    f=xgb_cv,        # The function we want to maximize\n",
    "    pbounds=pbounds, # The search space\n",
    "    random_state=42  # Ensures reproducibility\n",
    ")\n",
    "\n",
    "# --- STEP 4: Run the Bayesian Optimization Loop ---\n",
    "# We'll do a few initial random explorations (init_points) \n",
    "# and then a certain number of optimization steps (n_iter).\n",
    "init_points = 3\n",
    "n_iter = 20\n",
    "\n",
    "print(\"Starting Bayesian Optimization...\")\n",
    "best_score_so_far = -1.0\n",
    "early_stop_threshold = 0.90  # Stop if we exceed 90% cross-val accuracy\n",
    "\n",
    "optimizer.maximize(init_points=init_points, n_iter=n_iter)\n",
    "\n",
    "for i, res in enumerate(optimizer.res):\n",
    "    score = res['target']\n",
    "    print(f\"Iteration {i+1}, CV Accuracy: {score:.4f}, Parameters: {res['params']}\")\n",
    "    \n",
    "    if score > best_score_so_far:\n",
    "        best_score_so_far = score\n",
    "    \n",
    "    # Early stopping if we found a \"good\" configuration\n",
    "    if best_score_so_far > early_stop_threshold:\n",
    "        print(f\"\\nEarly stopping: Found cross-validation accuracy above {early_stop_threshold}\\n\")\n",
    "        break\n",
    "\n",
    "# --- STEP 5: Get the Best Found Hyperparameters ---\n",
    "best_params = optimizer.max['params']\n",
    "best_n_estimators = int(best_params['n_estimators'])\n",
    "best_max_depth = int(best_params['max_depth'])\n",
    "best_learning_rate = best_params['learning_rate']\n",
    "best_subsample = best_params['subsample']\n",
    "best_colsample_bytree = best_params['colsample_bytree']\n",
    "\n",
    "print(\"\\n=== BEST HYPERPARAMETERS FOUND ===\")\n",
    "print(f\"n_estimators = {best_n_estimators}\")\n",
    "print(f\"max_depth = {best_max_depth}\")\n",
    "print(f\"learning_rate = {best_learning_rate:.4f}\")\n",
    "print(f\"subsample = {best_subsample:.4f}\")\n",
    "print(f\"colsample_bytree = {best_colsample_bytree:.4f}\")\n",
    "print(f\"CV Accuracy = {optimizer.max['target']:.4f}\")\n",
    "\n",
    "# --- STEP 6: Train/Validate Model Once More on a Train/Test Split ---\n",
    "# Final check on a separate holdout set\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, stratify=y, random_state=999\n",
    ")\n",
    "\n",
    "final_model = XGBClassifier(\n",
    "    n_estimators=best_n_estimators,\n",
    "    max_depth=best_max_depth,\n",
    "    learning_rate=best_learning_rate,\n",
    "    subsample=best_subsample,\n",
    "    colsample_bytree=best_colsample_bytree,\n",
    "    eval_metric='mlogloss',\n",
    "    random_state=999\n",
    ")\n",
    "\n",
    "final_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = final_model.predict(X_test)\n",
    "test_acc = accuracy(y_pred, y_test)\n",
    "\n",
    "print(\"\\n=== FINAL EVALUATION ON HOLDOUT TEST SET ===\")\n",
    "print(f\"Test Accuracy: {test_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MEAN ACCURACY ON 100 ITERATIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration 1/3\n",
      "Test Accuracy: 0.9091 | Mean CV Accuracy: 0.8860\n",
      "\n",
      "Iteration 2/3\n",
      "Test Accuracy: 0.9174 | Mean CV Accuracy: 0.9004\n",
      "\n",
      "Iteration 3/3\n",
      "Test Accuracy: 0.9174 | Mean CV Accuracy: 0.9004\n",
      "\n",
      "=== FINAL RESULTS AFTER 20 ITERATIONS ===\n",
      "Mean Test Accuracy: 0.9146 Â± 0.0039\n",
      "Mean Cross-Validation Accuracy: 0.8956 Â± 0.0068\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score\n",
    "from classification.utils.utils import accuracy\n",
    "\n",
    "\n",
    "NORMALIZATION = True\n",
    "TRANSFORMATION = True\n",
    "\n",
    "# Ensure dataset (X_aug, y_aug) exists\n",
    "if TRANSFORMATION:\n",
    "    try:\n",
    "        X = X_basic_aug\n",
    "        y = y_basic_aug\n",
    "    except NameError:\n",
    "        raise ValueError(\"X_aug and y_aug must be defined before running this script.\")\n",
    "else:\n",
    "    try:\n",
    "        X = X_basic\n",
    "        y = y_basic\n",
    "    except NameError:\n",
    "        raise ValueError(\"X and y must be defined before running this script.\")\n",
    "\n",
    "# Normalize if needed\n",
    "if NORMALIZATION:\n",
    "    X = np.array([x / np.linalg.norm(x) if np.linalg.norm(x) != 0 else x for x in X])\n",
    "\n",
    "# Number of iterations\n",
    "num_iterations = 3\n",
    "\n",
    "# Lists to store scores\n",
    "accuracy_scores = []\n",
    "cv_accuracy_scores = []\n",
    "\n",
    "for i in range(num_iterations):\n",
    "    print(f\"\\nIteration {i + 1}/{num_iterations}\")\n",
    "    \n",
    "    # Split the dataset into training and testing subsets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.3, stratify=y, random_state=i\n",
    "    )\n",
    "\n",
    "    # Train the XGBoost model\n",
    "    model = XGBClassifier(\n",
    "        n_estimators=200,\n",
    "        max_depth=5,\n",
    "        learning_rate=0.1,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        eval_metric='mlogloss',\n",
    "        random_state=i\n",
    "    )\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Compute overall accuracy\n",
    "    test_accuracy = accuracy(y_pred, y_test)\n",
    "    accuracy_scores.append(test_accuracy)\n",
    "\n",
    "    # Perform cross-validation on the training set\n",
    "    cv_scores = cross_val_score(model, X_train, y_train, cv=10, scoring='accuracy')\n",
    "    mean_cv_accuracy = np.mean(cv_scores)\n",
    "    cv_accuracy_scores.append(mean_cv_accuracy)\n",
    "\n",
    "    print(f\"Test Accuracy: {test_accuracy:.4f} | Mean CV Accuracy: {mean_cv_accuracy:.4f}\")\n",
    "\n",
    "# Compute overall statistics\n",
    "mean_test_accuracy = np.mean(accuracy_scores)\n",
    "std_test_accuracy = np.std(accuracy_scores)\n",
    "\n",
    "mean_cv_accuracy = np.mean(cv_accuracy_scores)\n",
    "std_cv_accuracy = np.std(cv_accuracy_scores)\n",
    "\n",
    "# Print final results\n",
    "print(\"\\n=== FINAL RESULTS AFTER 20 ITERATIONS ===\")\n",
    "print(f\"Mean Test Accuracy: {mean_test_accuracy:.4f} Â± {std_test_accuracy:.4f}\")\n",
    "print(f\"Mean Cross-Validation Accuracy: {mean_cv_accuracy:.4f} Â± {std_cv_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy without PCA: 88.62%\n",
      "PCA components: 1, Mean Accuracy: 49.65%\n",
      "PCA components: 2, Mean Accuracy: 56.94%\n",
      "PCA components: 3, Mean Accuracy: 68.15%\n",
      "PCA components: 4, Mean Accuracy: 71.72%\n",
      "PCA components: 5, Mean Accuracy: 76.16%\n",
      "PCA components: 6, Mean Accuracy: 77.95%\n",
      "PCA components: 7, Mean Accuracy: 79.73%\n",
      "PCA components: 8, Mean Accuracy: 80.44%\n",
      "PCA components: 9, Mean Accuracy: 82.03%\n",
      "PCA components: 10, Mean Accuracy: 83.82%\n",
      "PCA components: 11, Mean Accuracy: 85.24%\n",
      "PCA components: 12, Mean Accuracy: 85.06%\n",
      "PCA components: 13, Mean Accuracy: 86.48%\n",
      "PCA components: 14, Mean Accuracy: 86.31%\n",
      "PCA components: 15, Mean Accuracy: 85.60%\n",
      "PCA components: 16, Mean Accuracy: 86.48%\n",
      "PCA components: 17, Mean Accuracy: 85.60%\n",
      "PCA components: 18, Mean Accuracy: 85.95%\n",
      "PCA components: 19, Mean Accuracy: 85.42%\n",
      "PCA components: 20, Mean Accuracy: 86.49%\n",
      "PCA components: 21, Mean Accuracy: 86.49%\n",
      "PCA components: 22, Mean Accuracy: 87.56%\n",
      "PCA components: 23, Mean Accuracy: 86.13%\n",
      "PCA components: 24, Mean Accuracy: 86.31%\n",
      "PCA components: 25, Mean Accuracy: 85.95%\n",
      "PCA components: 26, Mean Accuracy: 87.02%\n",
      "PCA components: 27, Mean Accuracy: 86.30%\n",
      "PCA components: 28, Mean Accuracy: 86.31%\n",
      "PCA components: 29, Mean Accuracy: 86.67%\n",
      "PCA components: 30, Mean Accuracy: 87.20%\n",
      "PCA components: 31, Mean Accuracy: 86.67%\n",
      "PCA components: 32, Mean Accuracy: 86.48%\n",
      "PCA components: 33, Mean Accuracy: 87.56%\n",
      "PCA components: 34, Mean Accuracy: 87.73%\n",
      "PCA components: 35, Mean Accuracy: 88.44%\n",
      "PCA components: 36, Mean Accuracy: 86.49%\n",
      "PCA components: 37, Mean Accuracy: 87.73%\n",
      "PCA components: 38, Mean Accuracy: 87.91%\n",
      "PCA components: 39, Mean Accuracy: 88.63%\n",
      "PCA components: 40, Mean Accuracy: 87.02%\n",
      "PCA components: 41, Mean Accuracy: 86.67%\n",
      "PCA components: 42, Mean Accuracy: 87.38%\n",
      "PCA components: 43, Mean Accuracy: 87.91%\n",
      "PCA components: 44, Mean Accuracy: 86.49%\n",
      "PCA components: 45, Mean Accuracy: 85.42%\n",
      "PCA components: 46, Mean Accuracy: 87.20%\n",
      "PCA components: 47, Mean Accuracy: 87.56%\n",
      "PCA components: 48, Mean Accuracy: 87.38%\n",
      "PCA components: 49, Mean Accuracy: 86.85%\n",
      "Test set accuracy with best XGBoost model: 85.12%\n"
     ]
    }
   ],
   "source": [
    "# PCA TESTS\n",
    "\n",
    "# Rewriting the user's friend's approach using the user's own data and structure.\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "\n",
    "\n",
    "# Load datasets\n",
    "X_aug = np.load(os.path.join(fm_dir, \"X_basic_aug.npy\"))\n",
    "y_aug = np.load(os.path.join(fm_dir, \"y_basic_aug.npy\"), allow_pickle=True)\n",
    "\n",
    "# Label encoding\n",
    "label_encoder = LabelEncoder()\n",
    "y_aug_encoded = label_encoder.fit_transform(y_aug)\n",
    "classnames = label_encoder.classes_\n",
    "\n",
    "# Normalize data\n",
    "X_aug_normalized = np.array([x / np.linalg.norm(x) if np.linalg.norm(x) != 0 else x for x in X_aug])\n",
    "\n",
    "# Split data\n",
    "X_train_normalized, X_test_normalized, y_train, y_test = train_test_split(\n",
    "    X_aug_normalized, y_aug_encoded, test_size=0.3, random_state=42)\n",
    "\n",
    "# Best hyperparameters for XGBoost\n",
    "best_params = {'colsample_bytree': 0.8, 'gamma': 0.1, 'learning_rate': 0.2,\n",
    "               'max_depth': 5, 'min_child_weight': 1, 'n_estimators': 50,\n",
    "               'subsample': 0.8}\n",
    "\n",
    "# Define model\n",
    "best_xgc = XGBClassifier(\n",
    "    colsample_bytree=best_params['colsample_bytree'],\n",
    "    gamma=best_params['gamma'],\n",
    "    learning_rate=best_params['learning_rate'],\n",
    "    max_depth=best_params['max_depth'],\n",
    "    min_child_weight=best_params['min_child_weight'],\n",
    "    n_estimators=best_params['n_estimators'],\n",
    "    subsample=best_params['subsample'],\n",
    "    objective=\"multi:softmax\",\n",
    "    num_class=len(classnames),\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# [1] Evaluate without PCA\n",
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "accuracies_no_pca = []\n",
    "\n",
    "for train_idx, val_idx in kf.split(X_train_normalized, y_train):\n",
    "    best_xgc.fit(X_train_normalized[train_idx], y_train[train_idx])\n",
    "    y_pred = best_xgc.predict(X_train_normalized[val_idx])\n",
    "    accuracy = accuracy_score(y_train[val_idx], y_pred)\n",
    "    accuracies_no_pca.append(accuracy)\n",
    "\n",
    "mean_accuracy_no_pca = np.mean(accuracies_no_pca)\n",
    "print(f\"Mean Accuracy without PCA: {mean_accuracy_no_pca * 100:.2f}%\")\n",
    "\n",
    "# [2] Evaluate with PCA (1 to 50 components)\n",
    "pca_components = range(1, min(X_train_normalized.shape[1], 50))\n",
    "mean_accuracies_with_pca = []\n",
    "\n",
    "for n_components in pca_components:\n",
    "    accuracies_with_pca = []\n",
    "    pca = PCA(n_components=n_components, whiten=True)\n",
    "\n",
    "    for train_idx, val_idx in kf.split(X_train_normalized, y_train):\n",
    "        X_train_pca = pca.fit_transform(X_train_normalized[train_idx])\n",
    "        X_val_pca = pca.transform(X_train_normalized[val_idx])\n",
    "\n",
    "        best_xgc.fit(X_train_pca, y_train[train_idx])\n",
    "        y_pred = best_xgc.predict(X_val_pca)\n",
    "        accuracy = accuracy_score(y_train[val_idx], y_pred)\n",
    "        accuracies_with_pca.append(accuracy)\n",
    "\n",
    "    mean_accuracy_with_pca = np.mean(accuracies_with_pca)\n",
    "    mean_accuracies_with_pca.append(mean_accuracy_with_pca)\n",
    "    print(f\"PCA components: {n_components}, Mean Accuracy: {mean_accuracy_with_pca * 100:.2f}%\")\n",
    "\n",
    "# [3] Plot results\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(pca_components, [acc * 100 for acc in mean_accuracies_with_pca], marker='o', label='With PCA')\n",
    "plt.axhline(y=mean_accuracy_no_pca * 100, color='r', linestyle='--', label='Without PCA')\n",
    "plt.xlabel('Number of PCA Components')\n",
    "plt.xticks(np.arange(0, 50, 5))\n",
    "plt.ylabel('Mean Accuracy (%)')\n",
    "plt.title('Comparison of XGBoost with and without PCA')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "\n",
    "# Save to PDF\n",
    "pdf_filename = os.path.join(model_dir, \"GB_with_vs_without_pca.pdf\")\n",
    "with PdfPages(pdf_filename) as pdf:\n",
    "    pdf.savefig()\n",
    "    plt.close()\n",
    "\n",
    "# [4] Final evaluation on test set with 29 PCA components\n",
    "pca_final = PCA(n_components=29, whiten=True)\n",
    "X_train_pca_final = pca_final.fit_transform(X_train_normalized)\n",
    "X_test_pca_final = pca_final.transform(X_test_normalized)\n",
    "\n",
    "# Save PCA model\n",
    "filename_pca = os.path.join(model_dir, \"pca_29_GB_components.pickle\")\n",
    "pickle.dump(pca_final, open(filename_pca, \"wb\"))\n",
    "\n",
    "# Train final model\n",
    "best_xgc.fit(X_train_pca_final, y_train)\n",
    "\n",
    "# Save model\n",
    "filename_model = os.path.join(model_dir, \"best_GB_model.pickle\")\n",
    "pickle.dump(best_xgc, open(filename_model, \"wb\"))\n",
    "\n",
    "# Accuracy on test set\n",
    "y_pred_test = best_xgc.predict(X_test_pca_final)\n",
    "accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "print(f\"Test set accuracy with best XGBoost model: {accuracy_test * 100:.2f}%\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
