{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-04 23:43:45.661835: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-05-04 23:43:45.692514: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-05-04 23:43:45.872630: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-05-04 23:43:46.035223: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1746395026.167005   17698 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1746395026.203800   17698 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1746395026.490458   17698 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1746395026.490566   17698 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1746395026.490571   17698 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1746395026.490574   17698 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-05-04 23:43:46.530038: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\"Machine learning tools\"\n",
    "import pickle\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "\n",
    "\n",
    "from classification.datasets import Dataset\n",
    "from classification.utils.audio_student import AudioUtil, Feature_vector_DS\n",
    "\n",
    "from classification.utils.plots import (\n",
    "    plot_decision_boundaries,\n",
    "    plot_specgram,\n",
    "    show_confusion_matrix,\n",
    ")\n",
    "from classification.utils.utils import accuracy\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization, Input\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chainsaw\n",
      "fire\n",
      "fireworks\n",
      "gunshot\n"
     ]
    }
   ],
   "source": [
    "### TO RUN\n",
    "dataset = Dataset()\n",
    "classnames = dataset.list_classes()\n",
    "\n",
    "print(\"\\n\".join(classnames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TO RUN\n",
    "fm_dir = \"data/feature_matrices/\"  # where to save the features matrices\n",
    "model_dir = \"data/models/cnn\"  # where to save the models\n",
    "os.makedirs(fm_dir, exist_ok=True)\n",
    "os.makedirs(model_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TO RUN\n",
    "\n",
    "\"Creation of the dataset\"\n",
    "myds = Feature_vector_DS(dataset, Nft=512, nmel=20, duration=950, shift_pct=0.0)\n",
    "\n",
    "\"Some attributes...\"\n",
    "myds.nmel\n",
    "myds.duration\n",
    "myds.shift_pct\n",
    "myds.sr\n",
    "myds.data_aug\n",
    "myds.ncol\n",
    "\n",
    "idx = 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now create a new augmented dataset and observe if the classification results improve. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 300x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from classification.utils.plots import show_confusion_matrix\n",
    "\n",
    "# Matrice de confusion fournie\n",
    "cm = np.array([\n",
    "    [12,  0,  0, 5],\n",
    "    [9,  0,  1,  5],\n",
    "    [3,  1,  4,  2],\n",
    "    [3,  0,  4,  1]\n",
    "])\n",
    "\n",
    "classnames = [\"chainsaw\", \"fire\", \"fireworks\", \"gunshot\"]\n",
    "\n",
    "# Reconstruction de y_true et y_pred\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "for true_label, row in enumerate(cm):\n",
    "    for pred_label, count in enumerate(row):\n",
    "        y_true.extend([true_label] * count)\n",
    "        y_pred.extend([pred_label] * count)\n",
    "\n",
    "# Affichage de la matrice de confusion\n",
    "show_confusion_matrix(y_pred, y_true, classnames, title=\"Confusion matrix : ESC-50 dataset\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'chainsaw': 315, 'fire': 303, 'fireworks': 315, 'gunshot': 40}\n",
      "Shape of the training matrix : (779, 400)\n",
      "Shape of the test matrix : (194, 400)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "from sklearn.calibration import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "data_aug_factor = 1\n",
    "featveclen = len(myds[\"fire\", 0, \"\", \"\"])  # Same for all classes\n",
    "classnames = [\"chainsaw\", \"fire\", \"fireworks\", \"gunshot\"]  # Or wherever you store class names\n",
    "nclass = len(classnames)\n",
    "\n",
    "# Determine number of samples per class\n",
    "naudio_per_class = {cls: len(dataset.files.get(cls, [])) for cls in classnames}\n",
    "print(naudio_per_class)\n",
    "\n",
    "# Allocate feature matrix\n",
    "total_samples_basic = sum(naudio_per_class[c] for c in classnames)\n",
    "\n",
    "X_train = []\n",
    "X_test = []\n",
    "y_train = []\n",
    "y_test = []\n",
    "\n",
    "for class_idx, classname in enumerate(classnames):\n",
    "    for i in range(naudio_per_class[classname]):\n",
    "        featvec = myds[classname, i, \"\", \"\"]\n",
    "        if i < naudio_per_class[classname] * 0.8:\n",
    "            X_train.append(featvec)\n",
    "            y_train.append(classname)\n",
    "        else:\n",
    "            X_test.append(featvec)\n",
    "            y_test.append(classname)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train = np.array(X_train)\n",
    "X_test = np.array(X_test)\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "# Normalization of the data\n",
    "scaler = StandardScaler()\n",
    "X_train_norm = scaler.fit_transform(X_train)\n",
    "X_test_norm = scaler.transform(X_test)\n",
    "with open(os.path.join(model_dir, f\"scaler.pkl\"), \"wb\") as f:\n",
    "    pickle.dump(scaler, f)\n",
    "\n",
    "label_encoder           = LabelEncoder()\n",
    "y_train     = label_encoder.fit_transform(y_train)\n",
    "y_test      = label_encoder.transform(y_test)\n",
    "with open(os.path.join(model_dir, f\"label_encoder.pkl\"), \"wb\") as f:\n",
    "    pickle.dump(label_encoder, f)\n",
    "\n",
    "# Save the feature matrix and labels\n",
    "np.save(os.path.join(fm_dir, \"X_train.npy\"), X_train)\n",
    "np.save(os.path.join(fm_dir, \"X_test.npy\"), X_test)\n",
    "np.save(os.path.join(fm_dir, \"y_train.npy\"), y_train)\n",
    "np.save(os.path.join(fm_dir, \"y_test.npy\"), y_test)\n",
    "np.save(os.path.join(fm_dir, \"X_train_norm.npy\"), X_train_norm)\n",
    "np.save(os.path.join(fm_dir, \"X_test_norm.npy\"), X_test_norm)\n",
    "\n",
    "print(f\"Shape of the training matrix : {X_train.shape}\")\n",
    "print(f\"Shape of the test matrix : {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from classification.utils.plots import plot_specgram_textlabel\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "BASIC = False\n",
    "if BASIC:\n",
    "    # Charger les données\n",
    "    X = np.load(os.path.join(fm_dir, \"X_train_aug.npy\"), allow_pickle=True)\n",
    "    y = np.load(os.path.join(fm_dir, \"y_train_aug.npy\"), allow_pickle=True)\n",
    "\n",
    "    # Dossier où sauvegarder les images\n",
    "    save_dir = os.path.join(\"src/classification/melspec_aug\")\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "    # Initialiser les compteurs par classe\n",
    "    class_counters = {}\n",
    "\n",
    "    for i in range(len(X)):\n",
    "        melspec = X[i]\n",
    "        class_of_spec = y[i]\n",
    "\n",
    "        # Ne traiter que si on a < 10 exemples pour cette classe\n",
    "        if class_of_spec not in class_counters:\n",
    "            class_counters[class_of_spec] = 0\n",
    "        if class_counters[class_of_spec] >= 10:\n",
    "            continue\n",
    "\n",
    "        class_idx = class_counters[class_of_spec]\n",
    "\n",
    "        # Affichage + sauvegarde\n",
    "        fig, ax = plt.subplots()\n",
    "        plot_specgram_textlabel(\n",
    "            melspec.reshape((20, 20)),\n",
    "            ax=ax,\n",
    "            is_mel=True,\n",
    "            title=f\"MEL Spectrogram - {class_of_spec} #{class_idx}\",\n",
    "            xlabel=\"Mel vector\",\n",
    "            textlabel=f\"{class_of_spec}\",\n",
    "        )\n",
    "        plt.tight_layout()\n",
    "        save_path = os.path.join(save_dir, f\"melspec_{class_of_spec}_{class_idx}.png\")\n",
    "        fig.savefig(save_path)\n",
    "        plt.close(fig)\n",
    "\n",
    "        class_counters[class_of_spec] += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of transformations :  2\n",
      "Shape of the training matrix : (1556, 400)\n",
      "Shape of the test matrix : (191, 400)\n",
      "------------------------------------------------------------\n",
      "Transformations: ['original', 'shifting'].\n"
     ]
    }
   ],
   "source": [
    "### AUGMENTED DATASET\n",
    "TEST_WITH_AUGMENTED_FV = False\n",
    "\n",
    "list_augmentation = [\"original\", \"noise\", \"shifting\"]\n",
    "myds.mod_data_aug(list_augmentation)\n",
    "print(\"Number of transformations : \", myds.data_aug_factor)\n",
    "\n",
    "n_bands = 20\n",
    "frames = 20\n",
    "# Préparer les splits\n",
    "X_train_list, y_train_list = [], []\n",
    "X_test_list,  y_test_list  = [], []\n",
    "\n",
    "for classname in classnames:\n",
    "    n = naudio_per_class[classname]\n",
    "\n",
    "    # Création des indices de base pour les sons originaux\n",
    "    limit = round(n*0.8)\n",
    "    train_idx = list(range(limit))\n",
    "    test_idx  = list(range(limit+1, n))\n",
    "    \n",
    "    for i in train_idx:\n",
    "        for aug in list_augmentation:\n",
    "            featvec = myds[classname, i, aug, \"\"]\n",
    "            X_train_list.append(featvec)\n",
    "            y_train_list.append(classname)\n",
    "\n",
    "    for i in test_idx:\n",
    "        if TEST_WITH_AUGMENTED_FV:\n",
    "            for aug in list_augmentation:\n",
    "                featvec = myds[classname, i, aug, \"\"]\n",
    "                X_test_list.append(featvec)\n",
    "                y_test_list.append(classname)\n",
    "        else:\n",
    "            featvec = myds[classname, i, \"\", \"\"]\n",
    "            X_test_list.append(featvec)\n",
    "            y_test_list.append(classname)\n",
    "\n",
    "# Conversion en tableaux numpy\n",
    "X_train_aug = np.array(X_train_list)\n",
    "y_train_aug = np.array(y_train_list, dtype=object)\n",
    "\n",
    "X_test_aug = np.array(X_test_list)\n",
    "y_test_aug = np.array(y_test_list, dtype=object)\n",
    "\n",
    "# --- 1) Z-SCORE GLOBAL -------------------------------\n",
    "scaler_global = StandardScaler().fit(X_train_aug)\n",
    "X_train_aug_norm_zscore_global = scaler_global.transform(X_train_aug)\n",
    "X_test_aug_norm_zscore_global  = scaler_global.transform(X_test_aug)\n",
    "\n",
    "with open(os.path.join(model_dir, \"scaler_aug_zscore_global.pkl\"), \"wb\") as f:\n",
    "    pickle.dump(scaler_global, f)\n",
    "np.save(os.path.join(fm_dir, \"X_train_aug_norm_zscore_global.npy\"), X_train_aug_norm_zscore_global)\n",
    "np.save(os.path.join(fm_dir, \"X_test_aug_norm_zscore_global.npy\"),  X_test_aug_norm_zscore_global)\n",
    "\n",
    "# --- 2) Z-SCORE PAR BANDE MEL ------------------------------------\n",
    "X_train_resh = X_train_aug.reshape(-1, n_bands, frames)\n",
    "X_test_resh  = X_test_aug.reshape(-1, n_bands, frames)\n",
    "\n",
    "mean_band = X_train_resh.mean(axis=(0, 2))          # (20,)\n",
    "std_band  = X_train_resh.std(axis=(0, 2)) + 1e-8    # (20,)\n",
    "\n",
    "X_train_aug_norm_zscore_band = ((X_train_resh - mean_band[None,:,None])\n",
    "                           / std_band[None,:,None]).reshape(-1, n_bands*frames)\n",
    "X_test_aug_norm_zscore_band  = ((X_test_resh  - mean_band[None,:,None])\n",
    "                           / std_band[None,:,None]).reshape(-1, n_bands*frames)\n",
    "\n",
    "np.save(os.path.join(model_dir, \"zscore_band_mean.npy\"), mean_band)\n",
    "np.save(os.path.join(model_dir, \"zscore_band_std.npy\"),  std_band)\n",
    "np.save(os.path.join(fm_dir, \"X_train_aug_norm_zscore_band.npy\"), X_train_aug_norm_zscore_band)\n",
    "np.save(os.path.join(fm_dir, \"X_test_aug_norm_zscore_band.npy\"),  X_test_aug_norm_zscore_band)\n",
    "\n",
    "# --- 3) MIN-MAX PAR BANDE MEL ------------------------------------\n",
    "min_band = X_train_resh.min(axis=(0, 2))\n",
    "max_band = X_train_resh.max(axis=(0, 2)) + 1e-8\n",
    "\n",
    "X_train_aug_norm_minmax = ((X_train_resh - min_band[None,:,None])\n",
    "                           / (max_band - min_band)[None,:,None]).reshape(-1, n_bands*frames)\n",
    "X_test_aug_norm_minmax  = ((X_test_resh  - min_band[None,:,None])\n",
    "                           / (max_band - min_band)[None,:,None]).reshape(-1, n_bands*frames)\n",
    "\n",
    "np.save(os.path.join(model_dir, \"min_band.npy\"), min_band)\n",
    "np.save(os.path.join(model_dir, \"max_band.npy\"), max_band)\n",
    "np.save(os.path.join(fm_dir, \"X_train_aug_norm_minmax.npy\"), X_train_aug_norm_minmax)\n",
    "np.save(os.path.join(fm_dir, \"X_test_aug_norm_minmax.npy\"),  X_test_aug_norm_minmax)\n",
    "\n",
    "# --- 4) GLOBAL MAX NORMALIZATION -------------------------------\n",
    "# Chaque spectrogramme est divisé par son max propre (par ligne)\n",
    "X_train_aug_norm_max = X_train_aug.copy().astype(np.float32)\n",
    "X_test_aug_norm_max  = X_test_aug.copy().astype(np.float32)\n",
    "\n",
    "X_train_max = X_train_aug_norm_max.max(axis=1, keepdims=True) + 1e-8 # éviter la division par 0\n",
    "X_test_max  = X_test_aug_norm_max.max(axis=1, keepdims=True) + 1e-8\n",
    "\n",
    "X_train_aug_norm_max /= X_train_max\n",
    "X_test_aug_norm_max  /= X_test_max\n",
    "\n",
    "np.save(os.path.join(fm_dir, \"X_train_aug_norm_max.npy\"), X_train_aug_norm_max)\n",
    "np.save(os.path.join(fm_dir, \"X_test_aug_norm_max.npy\"),  X_test_aug_norm_max)\n",
    "\n",
    "# --- 5) L2 NORMALIZATION -------------------------------\n",
    "X_train_aug_norm_l2 = X_train_aug.copy().astype(np.float32)\n",
    "X_test_aug_norm_l2  = X_test_aug.copy().astype(np.float32)\n",
    "\n",
    "X_train_l2 = np.sqrt(np.sum(X_train_aug_norm_l2**2, axis=1, keepdims=True)) + 1e-8\n",
    "X_test_l2  = np.sqrt(np.sum(X_test_aug_norm_l2**2, axis=1, keepdims=True)) + 1e-8\n",
    "\n",
    "X_train_aug_norm_l2 /= X_train_l2\n",
    "X_test_aug_norm_l2  /= X_test_l2\n",
    "\n",
    "np.save(os.path.join(fm_dir, \"X_train_aug_norm_l2.npy\"), X_train_aug_norm_l2)\n",
    "np.save(os.path.join(fm_dir, \"X_test_aug_norm_l2.npy\"),  X_test_aug_norm_l2)\n",
    "\n",
    "\n",
    "# Label encoding\n",
    "label_encoder_aug = LabelEncoder()\n",
    "y_train_aug     = label_encoder_aug.fit_transform(y_train_aug)\n",
    "y_test_aug      = label_encoder_aug.transform(y_test_aug)\n",
    "with open(os.path.join(model_dir, f\"label_encoder_aug.pkl\"), \"wb\") as f:\n",
    "    pickle.dump(label_encoder_aug, f)\n",
    "\n",
    "np.save(os.path.join(fm_dir, \"X_train_aug.npy\"), X_train_aug)\n",
    "np.save(os.path.join(fm_dir, \"X_test_aug.npy\"), X_test_aug)\n",
    "np.save(os.path.join(fm_dir, \"y_train_aug.npy\"), y_train_aug)\n",
    "np.save(os.path.join(fm_dir, \"y_test_aug.npy\"), y_test_aug)\n",
    "\n",
    "print(f\"Shape of the training matrix : {X_train_aug.shape}\")\n",
    "print(f\"Shape of the test matrix : {X_test_aug.shape}\")\n",
    "print(f\"------------------------------------------------------------\")\n",
    "print(f\"Transformations: {list_augmentation}.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FINAL MODEL SAVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-04 23:43:56.684308: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== cnn_noaug_nonorm =====\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8730    0.8730    0.8730        63\n",
      "           1     0.6623    0.8500    0.7445        60\n",
      "           2     0.7391    0.5397    0.6239        63\n",
      "           3     1.0000    1.0000    1.0000         8\n",
      "\n",
      "    accuracy                         0.7629       194\n",
      "   macro avg     0.8186    0.8157    0.8103       194\n",
      "weighted avg     0.7696    0.7629    0.7576       194\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== cnn_noaug_norm =====\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7742    0.7619    0.7680        63\n",
      "           1     0.5900    0.9833    0.7375        60\n",
      "           2     0.6957    0.2540    0.3721        63\n",
      "           3     0.8889    1.0000    0.9412         8\n",
      "\n",
      "    accuracy                         0.6753       194\n",
      "   macro avg     0.7372    0.7498    0.7047       194\n",
      "weighted avg     0.6965    0.6753    0.6371       194\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 15 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7f57a8a524c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 15 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7f57a8a524c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== cnn_aug_nonorm =====\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8667    0.8387    0.8525        62\n",
      "           1     0.7222    0.8667    0.7879        60\n",
      "           2     0.7500    0.6290    0.6842        62\n",
      "           3     1.0000    1.0000    1.0000         7\n",
      "\n",
      "    accuracy                         0.7853       191\n",
      "   macro avg     0.8347    0.8336    0.8311       191\n",
      "weighted avg     0.7883    0.7853    0.7830       191\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 14 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7f57a81ab790> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 14 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7f57a81ab790> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== cnn_aug_zscore_global =====\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7966    0.7581    0.7769        62\n",
      "           1     0.7024    0.9833    0.8194        60\n",
      "           2     0.6923    0.4355    0.5347        62\n",
      "           3     0.7778    1.0000    0.8750         7\n",
      "\n",
      "    accuracy                         0.7330       191\n",
      "   macro avg     0.7423    0.7942    0.7515       191\n",
      "weighted avg     0.7325    0.7330    0.7152       191\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== cnn_aug_zscore_band =====\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8197    0.8065    0.8130        62\n",
      "           1     0.7568    0.9333    0.8358        60\n",
      "           2     0.7660    0.5806    0.6606        62\n",
      "           3     0.7778    1.0000    0.8750         7\n",
      "\n",
      "    accuracy                         0.7801       191\n",
      "   macro avg     0.7800    0.8301    0.7961       191\n",
      "weighted avg     0.7809    0.7801    0.7730       191\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization, Input\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# ========== PARAMETERS ==========\n",
    "\n",
    "# Hyperparamètres issus de l'optimisation\n",
    "conv_filters = 63\n",
    "dense_units = 211\n",
    "dropout_rate = 0.1682\n",
    "kernel_size = 4\n",
    "n_conv_layers = 1\n",
    "batch_norm = True\n",
    "activation = 'relu'\n",
    "epochs = 30\n",
    "batch_size = 23\n",
    "patience = 5\n",
    "\n",
    "A = True  # NOAUG NONORM\n",
    "B = True  # NOAUG NORM\n",
    "C = True  # AUG NONORM\n",
    "D = True  # AUG NORM ZSCORE GLOBAL\n",
    "E = True  # AUG NORM ZSCORE BAND\n",
    "F = True  # AUG NORM MINMAX BAND\n",
    "G = True\n",
    "\n",
    "X_train_aug = np.load(os.path.join(fm_dir, \"X_train_aug.npy\"))\n",
    "X_test_aug = np.load(os.path.join(fm_dir, \"X_test_aug.npy\"))\n",
    "y_train_aug = np.load(os.path.join(fm_dir, \"y_train_aug.npy\"))\n",
    "y_test_aug = np.load(os.path.join(fm_dir, \"y_test_aug.npy\"))\n",
    "\n",
    "X_train_aug_norm_zscore_global = np.load(os.path.join(fm_dir, \"X_train_aug_norm_zscore_global.npy\"))\n",
    "X_test_aug_norm_zscore_global = np.load(os.path.join(fm_dir, \"X_test_aug_norm_zscore_global.npy\"))\n",
    "\n",
    "X_train_aug_norm_zscore_band = np.load(os.path.join(fm_dir, \"X_train_aug_norm_zscore_band.npy\"))\n",
    "X_test_aug_norm_zscore_band = np.load(os.path.join(fm_dir, \"X_test_aug_norm_zscore_band.npy\"))\n",
    "\n",
    "X_train_aug_norm_minmax = np.load(os.path.join(fm_dir, \"X_train_aug_norm_minmax.npy\"))\n",
    "X_test_aug_norm_minmax = np.load(os.path.join(fm_dir, \"X_test_aug_norm_minmax.npy\"))\n",
    "\n",
    "X_train_aug_norm_max = np.load(os.path.join(fm_dir, \"X_train_aug_norm_max.npy\"))\n",
    "X_test_aug_norm_max = np.load(os.path.join(fm_dir, \"X_test_aug_norm_max.npy\"))\n",
    "\n",
    "X_train_aug_norm_l2 = np.load(os.path.join(fm_dir, \"X_train_aug_norm_l2.npy\"))\n",
    "X_test_aug_norm_l2 = np.load(os.path.join(fm_dir, \"X_test_aug_norm_l2.npy\"))\n",
    "\n",
    "X_train = np.load(os.path.join(fm_dir, \"X_train.npy\"))\n",
    "X_train_norm = np.load(os.path.join(fm_dir, \"X_train_norm.npy\"))\n",
    "X_test = np.load(os.path.join(fm_dir, \"X_test.npy\"))\n",
    "X_test_norm = np.load(os.path.join(fm_dir, \"X_test_norm.npy\"))\n",
    "y_train = np.load(os.path.join(fm_dir, \"y_train.npy\"))\n",
    "y_test = np.load(os.path.join(fm_dir, \"y_test.npy\"))\n",
    "\n",
    "\n",
    "# ========== HELPERS ==========\n",
    "\n",
    "def reshape_for_cnn(X):\n",
    "    \"\"\"Transforme (n_samples, n_features) -> (n, h, w, 1).\"\"\"\n",
    "    if X.ndim == 2:                        # vecteurs aplatis → carrés\n",
    "        side = int(np.sqrt(X.shape[1]))    # → 20 si 400 features, etc.\n",
    "        X = X.reshape((-1, side, side, 1))\n",
    "    elif X.ndim == 3:                      # déjà (n, h, w)\n",
    "        X = X[..., np.newaxis]             # → ajoute canal unique\n",
    "    return X\n",
    "\n",
    "def build_cnn(input_shape, n_classes):\n",
    "    model = Sequential([Input(shape=input_shape)])\n",
    "    for i in range(n_conv_layers):\n",
    "        model.add(Conv2D(conv_filters * (2**i),\n",
    "                         (kernel_size, kernel_size),\n",
    "                         activation=activation))\n",
    "        if batch_norm:\n",
    "            model.add(BatchNormalization())\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(dense_units, activation=activation))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(n_classes, activation='softmax'))\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def train_cnn(X_tr, y_tr, X_val, y_val, name):\n",
    "    \"\"\"Entraîne et sauvegarde le modèle, renvoie le modèle entraîné.\"\"\"\n",
    "    n_classes = len(np.unique(y_tr))\n",
    "    y_tr_cat  = to_categorical(y_tr,  num_classes=n_classes)\n",
    "    y_val_cat = to_categorical(y_val, num_classes=n_classes)\n",
    "\n",
    "    model = build_cnn(X_tr.shape[1:], n_classes)\n",
    "    es = EarlyStopping(patience=patience, restore_best_weights=True, verbose=0)\n",
    "\n",
    "    model.fit(X_tr, y_tr_cat,\n",
    "              validation_data=(X_val, y_val_cat),\n",
    "              epochs=epochs,\n",
    "              batch_size=batch_size,\n",
    "              callbacks=[es],\n",
    "              verbose=0)\n",
    "\n",
    "    model.save(os.path.join(model_dir, f\"{name}.h5\"))\n",
    "    return model\n",
    "\n",
    "def evaluate(model, X_te, y_te, title):\n",
    "    y_pred = np.argmax(model.predict(X_te, verbose=0), axis=1)\n",
    "    print(f\"\\n===== {title} =====\")\n",
    "    print(classification_report(y_te, y_pred, digits=4))\n",
    "\n",
    "# ========== SCENARIOS ==========\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "#  SCÉNARIOS À TESTER\n",
    "# ------------------------------------------------------------------\n",
    "scenarios = {\n",
    "    \"cnn_noaug_nonorm\": dict(\n",
    "        X_train=X_train,            X_test=X_test,\n",
    "        y_train=y_train,            y_test=y_test,\n",
    "        scenario = A),\n",
    "    \"cnn_noaug_norm\": dict(\n",
    "        X_train=X_train_norm,       X_test=X_test_norm,\n",
    "        y_train=y_train,            y_test=y_test,\n",
    "        scenario = B),                # déjà normalisé → pas besoin de scaler\n",
    "    \"cnn_aug_nonorm\": dict(\n",
    "        X_train=X_train_aug,        X_test=X_test_aug,\n",
    "        y_train=y_train_aug,        y_test=y_test_aug,\n",
    "        scenario = C),\n",
    "    \"cnn_aug_zscore_global\": dict(\n",
    "        X_train=X_train_aug_norm_zscore_global, \n",
    "        X_test=X_test_aug_norm_zscore_global,\n",
    "        y_train=y_train_aug, \n",
    "        y_test=y_test_aug,\n",
    "        scenario=D),\n",
    "\n",
    "    \"cnn_aug_zscore_band\": dict(\n",
    "        X_train=X_train_aug_norm_zscore_band, \n",
    "        X_test=X_test_aug_norm_zscore_band,\n",
    "        y_train=y_train_aug, \n",
    "        y_test=y_test_aug,\n",
    "        scenario=E),\n",
    "\n",
    "    \"cnn_aug_minmax_band\": dict(\n",
    "        X_train=X_train_aug_norm_minmax, \n",
    "        X_test=X_test_aug_norm_minmax,\n",
    "        y_train=y_train_aug, \n",
    "        y_test=y_test_aug,\n",
    "        scenario=F),\n",
    "    \"cnn_aug_max\": dict(\n",
    "        X_train=X_train_aug_norm_max, \n",
    "        X_test=X_test_aug_norm_max,\n",
    "        y_train=y_train_aug, \n",
    "        y_test=y_test_aug,\n",
    "        scenario=G),\n",
    "    \"cnn_aug_l2\": dict(\n",
    "        X_train=X_train_aug_norm_l2, \n",
    "        X_test=X_test_aug_norm_l2,\n",
    "        y_train=y_train_aug, \n",
    "        y_test=y_test_aug,\n",
    "        scenario=F),\n",
    "}\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "#  BOUCLE D’ENTRAÎNEMENT + ÉVALUATION\n",
    "# ------------------------------------------------------------------\n",
    "for tag, cfg in scenarios.items():\n",
    "    # 1) mise en forme CNN\n",
    "    if cfg[\"scenario\"]:\n",
    "        X_tr = reshape_for_cnn(cfg[\"X_train\"])\n",
    "        X_te = reshape_for_cnn(cfg[\"X_test\"])\n",
    "        \n",
    "        # 2) entraînement + sauvegarde\n",
    "        model = train_cnn(X_tr, cfg[\"y_train\"], X_te, cfg[\"y_test\"], tag)\n",
    "\n",
    "        # 3) évaluation\n",
    "        evaluate(model, X_te, cfg[\"y_test\"], tag)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HYPERPARAMETER TUNING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Bayesian optimization en cours…\n",
      "|   iter    |  target   | activa... | batch_... | batch_... | conv_f... | dense_... | dropou... |  epochs   | kernel... | n_conv... | patience  |\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| \u001b[39m1        \u001b[39m | \u001b[39m0.5738   \u001b[39m | \u001b[39m0.3745   \u001b[39m | \u001b[39m0.9507   \u001b[39m | \u001b[39m51.14    \u001b[39m | \u001b[39m44.74    \u001b[39m | \u001b[39m66.95    \u001b[39m | \u001b[39m0.1624   \u001b[39m | \u001b[39m6.452    \u001b[39m | \u001b[39m4.732    \u001b[39m | \u001b[39m2.202    \u001b[39m | \u001b[39m7.665    \u001b[39m |\n",
      "| \u001b[35m2        \u001b[39m | \u001b[35m0.7304   \u001b[39m | \u001b[35m0.02058  \u001b[39m | \u001b[35m0.9699   \u001b[39m | \u001b[35m55.96    \u001b[39m | \u001b[35m26.19    \u001b[39m | \u001b[35m72.73    \u001b[39m | \u001b[35m0.1734   \u001b[39m | \u001b[35m12.61    \u001b[39m | \u001b[35m4.05     \u001b[39m | \u001b[35m1.864    \u001b[39m | \u001b[35m4.33     \u001b[39m |\n",
      "| \u001b[35m3        \u001b[39m | \u001b[35m0.8203   \u001b[39m | \u001b[35m0.6119   \u001b[39m | \u001b[35m0.1395   \u001b[39m | \u001b[35m30.02    \u001b[39m | \u001b[35m33.59    \u001b[39m | \u001b[35m134.2    \u001b[39m | \u001b[35m0.4141   \u001b[39m | \u001b[35m9.992    \u001b[39m | \u001b[35m4.028    \u001b[39m | \u001b[35m2.185    \u001b[39m | \u001b[35m2.372    \u001b[39m |\n",
      "| \u001b[35m4        \u001b[39m | \u001b[35m0.8729   \u001b[39m | \u001b[35m0.6075   \u001b[39m | \u001b[35m0.1705   \u001b[39m | \u001b[35m19.12    \u001b[39m | \u001b[35m61.55    \u001b[39m | \u001b[35m248.3    \u001b[39m | \u001b[35m0.4234   \u001b[39m | \u001b[35m12.62    \u001b[39m | \u001b[35m3.195    \u001b[39m | \u001b[35m2.368    \u001b[39m | \u001b[35m5.521    \u001b[39m |\n",
      "| \u001b[39m5        \u001b[39m | \u001b[39m0.8306   \u001b[39m | \u001b[39m0.122    \u001b[39m | \u001b[39m0.4952   \u001b[39m | \u001b[39m17.65    \u001b[39m | \u001b[39m59.65    \u001b[39m | \u001b[39m89.97    \u001b[39m | \u001b[39m0.365    \u001b[39m | \u001b[39m12.79    \u001b[39m | \u001b[39m4.04     \u001b[39m | \u001b[39m2.093    \u001b[39m | \u001b[39m3.479    \u001b[39m |\n",
      "| \u001b[39m6        \u001b[39m | \u001b[39m0.8652   \u001b[39m | \u001b[39m0.2175   \u001b[39m | \u001b[39m0.3667   \u001b[39m | \u001b[39m34.76    \u001b[39m | \u001b[39m62.87    \u001b[39m | \u001b[39m245.8    \u001b[39m | \u001b[39m0.4201   \u001b[39m | \u001b[39m11.04    \u001b[39m | \u001b[39m3.136    \u001b[39m | \u001b[39m1.634    \u001b[39m | \u001b[39m4.134    \u001b[39m |\n",
      "| \u001b[35m7        \u001b[39m | \u001b[35m0.8883   \u001b[39m | \u001b[35m0.6028   \u001b[39m | \u001b[35m0.3416   \u001b[39m | \u001b[35m18.2     \u001b[39m | \u001b[35m60.95    \u001b[39m | \u001b[35m251.2    \u001b[39m | \u001b[35m0.1391   \u001b[39m | \u001b[35m15.46    \u001b[39m | \u001b[35m3.44     \u001b[39m | \u001b[35m2.091    \u001b[39m | \u001b[35m5.896    \u001b[39m |\n",
      "| \u001b[39m8        \u001b[39m | \u001b[39m0.8806   \u001b[39m | \u001b[39m0.312    \u001b[39m | \u001b[39m0.2276   \u001b[39m | \u001b[39m25.94    \u001b[39m | \u001b[39m32.68    \u001b[39m | \u001b[39m255.9    \u001b[39m | \u001b[39m0.2995   \u001b[39m | \u001b[39m29.58    \u001b[39m | \u001b[39m4.972    \u001b[39m | \u001b[39m1.7      \u001b[39m | \u001b[39m9.459    \u001b[39m |\n",
      "| \u001b[39m9        \u001b[39m | \u001b[39m0.8062   \u001b[39m | \u001b[39m0.8701   \u001b[39m | \u001b[39m0.5717   \u001b[39m | \u001b[39m61.74    \u001b[39m | \u001b[39m40.65    \u001b[39m | \u001b[39m252.9    \u001b[39m | \u001b[39m0.4846   \u001b[39m | \u001b[39m28.29    \u001b[39m | \u001b[39m3.673    \u001b[39m | \u001b[39m1.636    \u001b[39m | \u001b[39m5.567    \u001b[39m |\n",
      "| \u001b[39m10       \u001b[39m | \u001b[39m0.8639   \u001b[39m | \u001b[39m0.8654   \u001b[39m | \u001b[39m0.8307   \u001b[39m | \u001b[39m18.97    \u001b[39m | \u001b[39m43.27    \u001b[39m | \u001b[39m216.6    \u001b[39m | \u001b[39m0.1049   \u001b[39m | \u001b[39m29.83    \u001b[39m | \u001b[39m4.106    \u001b[39m | \u001b[39m1.627    \u001b[39m | \u001b[39m4.398    \u001b[39m |\n",
      "| \u001b[39m11       \u001b[39m | \u001b[39m0.7548   \u001b[39m | \u001b[39m0.314    \u001b[39m | \u001b[39m0.4319   \u001b[39m | \u001b[39m20.4     \u001b[39m | \u001b[39m16.55    \u001b[39m | \u001b[39m235.8    \u001b[39m | \u001b[39m0.3845   \u001b[39m | \u001b[39m6.25     \u001b[39m | \u001b[39m3.153    \u001b[39m | \u001b[39m2.646    \u001b[39m | \u001b[39m3.643    \u001b[39m |\n",
      "| \u001b[39m12       \u001b[39m | \u001b[39m0.855    \u001b[39m | \u001b[39m0.4757   \u001b[39m | \u001b[39m0.3006   \u001b[39m | \u001b[39m21.5     \u001b[39m | \u001b[39m62.58    \u001b[39m | \u001b[39m237.7    \u001b[39m | \u001b[39m0.4213   \u001b[39m | \u001b[39m29.77    \u001b[39m | \u001b[39m4.461    \u001b[39m | \u001b[39m2.506    \u001b[39m | \u001b[39m7.866    \u001b[39m |\n",
      "| \u001b[39m13       \u001b[39m | \u001b[39m0.8408   \u001b[39m | \u001b[39m0.1547   \u001b[39m | \u001b[39m0.3671   \u001b[39m | \u001b[39m30.53    \u001b[39m | \u001b[39m63.93    \u001b[39m | \u001b[39m183.5    \u001b[39m | \u001b[39m0.4529   \u001b[39m | \u001b[39m26.41    \u001b[39m | \u001b[39m3.72     \u001b[39m | \u001b[39m2.92     \u001b[39m | \u001b[39m2.334    \u001b[39m |\n",
      "| \u001b[39m14       \u001b[39m | \u001b[39m0.8845   \u001b[39m | \u001b[39m0.7179   \u001b[39m | \u001b[39m0.7539   \u001b[39m | \u001b[39m18.98    \u001b[39m | \u001b[39m22.4     \u001b[39m | \u001b[39m176.3    \u001b[39m | \u001b[39m0.4605   \u001b[39m | \u001b[39m29.18    \u001b[39m | \u001b[39m3.625    \u001b[39m | \u001b[39m2.163    \u001b[39m | \u001b[39m9.588    \u001b[39m |\n",
      "| \u001b[39m15       \u001b[39m | \u001b[39m0.8614   \u001b[39m | \u001b[39m0.7567   \u001b[39m | \u001b[39m0.006892 \u001b[39m | \u001b[39m52.17    \u001b[39m | \u001b[39m21.22    \u001b[39m | \u001b[39m181.6    \u001b[39m | \u001b[39m0.2044   \u001b[39m | \u001b[39m28.46    \u001b[39m | \u001b[39m3.583    \u001b[39m | \u001b[39m1.801    \u001b[39m | \u001b[39m2.319    \u001b[39m |\n",
      "| \u001b[39m16       \u001b[39m | \u001b[39m0.8152   \u001b[39m | \u001b[39m0.2891   \u001b[39m | \u001b[39m0.1959   \u001b[39m | \u001b[39m29.75    \u001b[39m | \u001b[39m30.82    \u001b[39m | \u001b[39m184.1    \u001b[39m | \u001b[39m0.3695   \u001b[39m | \u001b[39m5.664    \u001b[39m | \u001b[39m4.63     \u001b[39m | \u001b[39m1.074    \u001b[39m | \u001b[39m9.608    \u001b[39m |\n",
      "| \u001b[39m17       \u001b[39m | \u001b[39m0.8665   \u001b[39m | \u001b[39m0.9805   \u001b[39m | \u001b[39m0.2028   \u001b[39m | \u001b[39m61.92    \u001b[39m | \u001b[39m18.24    \u001b[39m | \u001b[39m144.2    \u001b[39m | \u001b[39m0.4395   \u001b[39m | \u001b[39m29.15    \u001b[39m | \u001b[39m4.061    \u001b[39m | \u001b[39m1.05     \u001b[39m | \u001b[39m7.302    \u001b[39m |\n",
      "| \u001b[39m18       \u001b[39m | \u001b[39m0.7266   \u001b[39m | \u001b[39m0.2559   \u001b[39m | \u001b[39m0.9184   \u001b[39m | \u001b[39m62.8     \u001b[39m | \u001b[39m60.14    \u001b[39m | \u001b[39m149.5    \u001b[39m | \u001b[39m0.3645   \u001b[39m | \u001b[39m28.04    \u001b[39m | \u001b[39m3.863    \u001b[39m | \u001b[39m1.497    \u001b[39m | \u001b[39m3.291    \u001b[39m |\n",
      "| \u001b[39m19       \u001b[39m | \u001b[39m0.8087   \u001b[39m | \u001b[39m0.2812   \u001b[39m | \u001b[39m0.8131   \u001b[39m | \u001b[39m34.34    \u001b[39m | \u001b[39m17.4     \u001b[39m | \u001b[39m156.3    \u001b[39m | \u001b[39m0.1203   \u001b[39m | \u001b[39m26.14    \u001b[39m | \u001b[39m4.537    \u001b[39m | \u001b[39m2.432    \u001b[39m | \u001b[39m7.538    \u001b[39m |\n",
      "| \u001b[39m20       \u001b[39m | \u001b[39m0.8472   \u001b[39m | \u001b[39m0.623    \u001b[39m | \u001b[39m0.06219  \u001b[39m | \u001b[39m19.5     \u001b[39m | \u001b[39m16.82    \u001b[39m | \u001b[39m197.4    \u001b[39m | \u001b[39m0.3332   \u001b[39m | \u001b[39m27.87    \u001b[39m | \u001b[39m3.017    \u001b[39m | \u001b[39m2.428    \u001b[39m | \u001b[39m3.205    \u001b[39m |\n",
      "| \u001b[39m21       \u001b[39m | \u001b[39m0.8498   \u001b[39m | \u001b[39m0.8031   \u001b[39m | \u001b[39m0.6136   \u001b[39m | \u001b[39m50.51    \u001b[39m | \u001b[39m46.49    \u001b[39m | \u001b[39m205.1    \u001b[39m | \u001b[39m0.187    \u001b[39m | \u001b[39m29.51    \u001b[39m | \u001b[39m3.152    \u001b[39m | \u001b[39m1.396    \u001b[39m | \u001b[39m8.984    \u001b[39m |\n",
      "| \u001b[39m22       \u001b[39m | \u001b[39m0.7266   \u001b[39m | \u001b[39m0.6607   \u001b[39m | \u001b[39m0.5187   \u001b[39m | \u001b[39m31.78    \u001b[39m | \u001b[39m53.0     \u001b[39m | \u001b[39m255.7    \u001b[39m | \u001b[39m0.4025   \u001b[39m | \u001b[39m29.36    \u001b[39m | \u001b[39m3.526    \u001b[39m | \u001b[39m1.857    \u001b[39m | \u001b[39m3.926    \u001b[39m |\n",
      "| \u001b[39m23       \u001b[39m | \u001b[39m0.887    \u001b[39m | \u001b[39m0.7875   \u001b[39m | \u001b[39m0.4628   \u001b[39m | \u001b[39m19.13    \u001b[39m | \u001b[39m37.17    \u001b[39m | \u001b[39m188.7    \u001b[39m | \u001b[39m0.3592   \u001b[39m | \u001b[39m27.63    \u001b[39m | \u001b[39m4.814    \u001b[39m | \u001b[39m1.73     \u001b[39m | \u001b[39m6.356    \u001b[39m |\n",
      "| \u001b[39m24       \u001b[39m | \u001b[39m0.8485   \u001b[39m | \u001b[39m0.9531   \u001b[39m | \u001b[39m0.3965   \u001b[39m | \u001b[39m33.4     \u001b[39m | \u001b[39m33.74    \u001b[39m | \u001b[39m187.8    \u001b[39m | \u001b[39m0.2165   \u001b[39m | \u001b[39m29.25    \u001b[39m | \u001b[39m3.26     \u001b[39m | \u001b[39m2.736    \u001b[39m | \u001b[39m2.005    \u001b[39m |\n",
      "| \u001b[39m25       \u001b[39m | \u001b[39m0.8665   \u001b[39m | \u001b[39m0.8951   \u001b[39m | \u001b[39m0.4345   \u001b[39m | \u001b[39m16.56    \u001b[39m | \u001b[39m42.34    \u001b[39m | \u001b[39m172.2    \u001b[39m | \u001b[39m0.1201   \u001b[39m | \u001b[39m24.15    \u001b[39m | \u001b[39m4.186    \u001b[39m | \u001b[39m1.736    \u001b[39m | \u001b[39m3.233    \u001b[39m |\n",
      "| \u001b[39m26       \u001b[39m | \u001b[39m0.8203   \u001b[39m | \u001b[39m0.6326   \u001b[39m | \u001b[39m0.8029   \u001b[39m | \u001b[39m33.29    \u001b[39m | \u001b[39m62.9     \u001b[39m | \u001b[39m216.5    \u001b[39m | \u001b[39m0.2566   \u001b[39m | \u001b[39m12.14    \u001b[39m | \u001b[39m4.796    \u001b[39m | \u001b[39m2.175    \u001b[39m | \u001b[39m5.455    \u001b[39m |\n",
      "| \u001b[39m27       \u001b[39m | \u001b[39m0.8318   \u001b[39m | \u001b[39m0.8008   \u001b[39m | \u001b[39m0.7522   \u001b[39m | \u001b[39m16.78    \u001b[39m | \u001b[39m45.07    \u001b[39m | \u001b[39m252.3    \u001b[39m | \u001b[39m0.4097   \u001b[39m | \u001b[39m11.59    \u001b[39m | \u001b[39m3.663    \u001b[39m | \u001b[39m1.262    \u001b[39m | \u001b[39m9.533    \u001b[39m |\n",
      "| \u001b[39m28       \u001b[39m | \u001b[39m0.869    \u001b[39m | \u001b[39m0.5366   \u001b[39m | \u001b[39m0.5717   \u001b[39m | \u001b[39m20.27    \u001b[39m | \u001b[39m17.0     \u001b[39m | \u001b[39m254.7    \u001b[39m | \u001b[39m0.1537   \u001b[39m | \u001b[39m27.68    \u001b[39m | \u001b[39m4.334    \u001b[39m | \u001b[39m2.086    \u001b[39m | \u001b[39m7.092    \u001b[39m |\n",
      "| \u001b[39m29       \u001b[39m | \u001b[39m0.8755   \u001b[39m | \u001b[39m0.4547   \u001b[39m | \u001b[39m0.02061  \u001b[39m | \u001b[39m16.14    \u001b[39m | \u001b[39m52.66    \u001b[39m | \u001b[39m199.0    \u001b[39m | \u001b[39m0.4397   \u001b[39m | \u001b[39m25.55    \u001b[39m | \u001b[39m4.901    \u001b[39m | \u001b[39m2.635    \u001b[39m | \u001b[39m8.91     \u001b[39m |\n",
      "| \u001b[39m30       \u001b[39m | \u001b[39m0.8549   \u001b[39m | \u001b[39m0.4696   \u001b[39m | \u001b[39m0.258    \u001b[39m | \u001b[39m60.92    \u001b[39m | \u001b[39m16.61    \u001b[39m | \u001b[39m208.7    \u001b[39m | \u001b[39m0.4131   \u001b[39m | \u001b[39m29.53    \u001b[39m | \u001b[39m4.963    \u001b[39m | \u001b[39m1.379    \u001b[39m | \u001b[39m6.057    \u001b[39m |\n",
      "| \u001b[39m31       \u001b[39m | \u001b[39m0.8447   \u001b[39m | \u001b[39m0.78     \u001b[39m | \u001b[39m0.8508   \u001b[39m | \u001b[39m59.49    \u001b[39m | \u001b[39m16.65    \u001b[39m | \u001b[39m118.4    \u001b[39m | \u001b[39m0.2196   \u001b[39m | \u001b[39m29.08    \u001b[39m | \u001b[39m3.975    \u001b[39m | \u001b[39m2.627    \u001b[39m | \u001b[39m6.67     \u001b[39m |\n",
      "| \u001b[39m32       \u001b[39m | \u001b[39m0.6418   \u001b[39m | \u001b[39m0.557    \u001b[39m | \u001b[39m0.5455   \u001b[39m | \u001b[39m63.73    \u001b[39m | \u001b[39m17.58    \u001b[39m | \u001b[39m160.1    \u001b[39m | \u001b[39m0.2091   \u001b[39m | \u001b[39m5.697    \u001b[39m | \u001b[39m4.673    \u001b[39m | \u001b[39m1.753    \u001b[39m | \u001b[39m8.258    \u001b[39m |\n",
      "| \u001b[39m33       \u001b[39m | \u001b[39m0.8293   \u001b[39m | \u001b[39m0.1593   \u001b[39m | \u001b[39m0.0002015\u001b[39m | \u001b[39m42.88    \u001b[39m | \u001b[39m18.61    \u001b[39m | \u001b[39m243.0    \u001b[39m | \u001b[39m0.3894   \u001b[39m | \u001b[39m28.86    \u001b[39m | \u001b[39m4.785    \u001b[39m | \u001b[39m2.439    \u001b[39m | \u001b[39m9.857    \u001b[39m |\n",
      "| \u001b[39m34       \u001b[39m | \u001b[39m0.6315   \u001b[39m | \u001b[39m0.9021   \u001b[39m | \u001b[39m0.6801   \u001b[39m | \u001b[39m56.75    \u001b[39m | \u001b[39m62.52    \u001b[39m | \u001b[39m238.4    \u001b[39m | \u001b[39m0.3156   \u001b[39m | \u001b[39m5.496    \u001b[39m | \u001b[39m3.605    \u001b[39m | \u001b[39m1.058    \u001b[39m | \u001b[39m8.32     \u001b[39m |\n",
      "| \u001b[39m35       \u001b[39m | \u001b[39m0.8408   \u001b[39m | \u001b[39m0.5206   \u001b[39m | \u001b[39m0.1261   \u001b[39m | \u001b[39m17.06    \u001b[39m | \u001b[39m51.58    \u001b[39m | \u001b[39m190.5    \u001b[39m | \u001b[39m0.2746   \u001b[39m | \u001b[39m7.442    \u001b[39m | \u001b[39m4.483    \u001b[39m | \u001b[39m2.765    \u001b[39m | \u001b[39m2.681    \u001b[39m |\n",
      "| \u001b[39m36       \u001b[39m | \u001b[39m0.8806   \u001b[39m | \u001b[39m0.4593   \u001b[39m | \u001b[39m0.4674   \u001b[39m | \u001b[39m16.08    \u001b[39m | \u001b[39m33.41    \u001b[39m | \u001b[39m241.4    \u001b[39m | \u001b[39m0.4361   \u001b[39m | \u001b[39m29.43    \u001b[39m | \u001b[39m4.161    \u001b[39m | \u001b[39m1.885    \u001b[39m | \u001b[39m8.288    \u001b[39m |\n",
      "| \u001b[39m37       \u001b[39m | \u001b[39m0.7394   \u001b[39m | \u001b[39m0.4966   \u001b[39m | \u001b[39m0.7025   \u001b[39m | \u001b[39m40.67    \u001b[39m | \u001b[39m30.39    \u001b[39m | \u001b[39m215.4    \u001b[39m | \u001b[39m0.1081   \u001b[39m | \u001b[39m28.74    \u001b[39m | \u001b[39m4.615    \u001b[39m | \u001b[39m2.71     \u001b[39m | \u001b[39m3.977    \u001b[39m |\n",
      "| \u001b[35m38       \u001b[39m | \u001b[35m0.8986   \u001b[39m | \u001b[35m0.7856   \u001b[39m | \u001b[35m0.9371   \u001b[39m | \u001b[35m23.19    \u001b[39m | \u001b[35m63.29    \u001b[39m | \u001b[35m211.1    \u001b[39m | \u001b[35m0.1682   \u001b[39m | \u001b[35m29.93    \u001b[39m | \u001b[35m3.947    \u001b[39m | \u001b[35m2.387    \u001b[39m | \u001b[35m4.574    \u001b[39m |\n",
      "| \u001b[39m39       \u001b[39m | \u001b[39m0.8947   \u001b[39m | \u001b[39m0.6606   \u001b[39m | \u001b[39m0.2762   \u001b[39m | \u001b[39m16.57    \u001b[39m | \u001b[39m63.32    \u001b[39m | \u001b[39m219.2    \u001b[39m | \u001b[39m0.2231   \u001b[39m | \u001b[39m21.29    \u001b[39m | \u001b[39m3.101    \u001b[39m | \u001b[39m2.019    \u001b[39m | \u001b[39m7.835    \u001b[39m |\n",
      "| \u001b[39m40       \u001b[39m | \u001b[39m0.8216   \u001b[39m | \u001b[39m0.2144   \u001b[39m | \u001b[39m0.6744   \u001b[39m | \u001b[39m63.81    \u001b[39m | \u001b[39m38.11    \u001b[39m | \u001b[39m193.3    \u001b[39m | \u001b[39m0.498    \u001b[39m | \u001b[39m29.63    \u001b[39m | \u001b[39m4.681    \u001b[39m | \u001b[39m1.738    \u001b[39m | \u001b[39m5.067    \u001b[39m |\n",
      "| \u001b[39m41       \u001b[39m | \u001b[39m0.8665   \u001b[39m | \u001b[39m0.358    \u001b[39m | \u001b[39m0.4545   \u001b[39m | \u001b[39m19.51    \u001b[39m | \u001b[39m18.23    \u001b[39m | \u001b[39m115.6    \u001b[39m | \u001b[39m0.2808   \u001b[39m | \u001b[39m29.16    \u001b[39m | \u001b[39m4.712    \u001b[39m | \u001b[39m1.314    \u001b[39m | \u001b[39m9.156    \u001b[39m |\n",
      "| \u001b[39m42       \u001b[39m | \u001b[39m0.8832   \u001b[39m | \u001b[39m0.9562   \u001b[39m | \u001b[39m0.762    \u001b[39m | \u001b[39m16.55    \u001b[39m | \u001b[39m37.38    \u001b[39m | \u001b[39m103.0    \u001b[39m | \u001b[39m0.1763   \u001b[39m | \u001b[39m29.68    \u001b[39m | \u001b[39m4.334    \u001b[39m | \u001b[39m1.049    \u001b[39m | \u001b[39m6.303    \u001b[39m |\n",
      "| \u001b[39m43       \u001b[39m | \u001b[39m0.8832   \u001b[39m | \u001b[39m0.815    \u001b[39m | \u001b[39m0.9118   \u001b[39m | \u001b[39m16.21    \u001b[39m | \u001b[39m20.05    \u001b[39m | \u001b[39m89.48    \u001b[39m | \u001b[39m0.1916   \u001b[39m | \u001b[39m23.28    \u001b[39m | \u001b[39m4.071    \u001b[39m | \u001b[39m2.212    \u001b[39m | \u001b[39m7.642    \u001b[39m |\n",
      "| \u001b[39m44       \u001b[39m | \u001b[39m0.8472   \u001b[39m | \u001b[39m0.7536   \u001b[39m | \u001b[39m0.3984   \u001b[39m | \u001b[39m20.05    \u001b[39m | \u001b[39m23.91    \u001b[39m | \u001b[39m104.8    \u001b[39m | \u001b[39m0.4367   \u001b[39m | \u001b[39m9.305    \u001b[39m | \u001b[39m4.725    \u001b[39m | \u001b[39m1.271    \u001b[39m | \u001b[39m7.929    \u001b[39m |\n",
      "| \u001b[39m45       \u001b[39m | \u001b[39m0.8922   \u001b[39m | \u001b[39m0.306    \u001b[39m | \u001b[39m0.6738   \u001b[39m | \u001b[39m20.8     \u001b[39m | \u001b[39m54.44    \u001b[39m | \u001b[39m120.7    \u001b[39m | \u001b[39m0.3442   \u001b[39m | \u001b[39m29.93    \u001b[39m | \u001b[39m4.663    \u001b[39m | \u001b[39m1.405    \u001b[39m | \u001b[39m8.378    \u001b[39m |\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import classification_report\n",
    "from bayes_opt import BayesianOptimization\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization, Input\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# --- CONFIG FLAGS ---\n",
    "NORMALIZATION = False\n",
    "TRANSFORMATION = False\n",
    "TYPE = \"max\" # \"minmax_band\" or \"zscore_band\" or \"zscore_global\"\n",
    "\n",
    "if TRANSFORMATION:\n",
    "    if NORMALIZATION:\n",
    "        if TYPE == \"zscore_global\":\n",
    "            X_train = np.load(os.path.join(fm_dir, \"X_train_aug_norm_zscore_global.npy\"))\n",
    "            X_test = np.load(os.path.join(fm_dir, \"X_test_aug_norm_zscore_global.npy\"))\n",
    "            y_train = np.load(os.path.join(fm_dir, \"y_train_aug.npy\"))\n",
    "            y_test = np.load(os.path.join(fm_dir, \"y_test_aug.npy\"))\n",
    "        elif TYPE == \"zscore_band\":\n",
    "            X_train = np.load(os.path.join(fm_dir, \"X_train_aug_norm_zscore_band.npy\"))\n",
    "            X_test = np.load(os.path.join(fm_dir, \"X_test_aug_norm_zscore_band.npy\"))\n",
    "            y_train = np.load(os.path.join(fm_dir, \"y_train_aug.npy\"))\n",
    "            y_test = np.load(os.path.join(fm_dir, \"y_test_aug.npy\"))\n",
    "        elif TYPE == \"minmax_band\":\n",
    "            X_train = np.load(os.path.join(fm_dir, \"X_train_aug_norm_minmax.npy\"))\n",
    "            X_test = np.load(os.path.join(fm_dir, \"X_test_aug_norm_minmax.npy\"))\n",
    "            y_train = np.load(os.path.join(fm_dir, \"y_train_aug.npy\"))\n",
    "            y_test = np.load(os.path.join(fm_dir, \"y_test_aug.npy\"))\n",
    "        elif TYPE == \"max\":\n",
    "            X_train = np.load(os.path.join(fm_dir, \"X_train_aug_norm_max.npy\"))\n",
    "            X_test = np.load(os.path.join(fm_dir, \"X_test_aug_norm_max.npy\"))\n",
    "            y_train = np.load(os.path.join(fm_dir, \"y_train_aug.npy\"))\n",
    "            y_test = np.load(os.path.join(fm_dir, \"y_test_aug.npy\"))\n",
    "        elif TYPE == \"l2\":\n",
    "            X_train = np.load(os.path.join(fm_dir, \"X_train_aug_norm_l2.npy\"))\n",
    "            X_test = np.load(os.path.join(fm_dir, \"X_test_aug_norm_l2.npy\"))\n",
    "            y_train = np.load(os.path.join(fm_dir, \"y_train_aug.npy\"))\n",
    "            y_test = np.load(os.path.join(fm_dir, \"y_test_aug.npy\"))\n",
    "else:\n",
    "    if NORMALIZATION:\n",
    "        X_train = np.load(os.path.join(fm_dir, \"X_train_norm.npy\"))\n",
    "        X_test = np.load(os.path.join(fm_dir, \"X_test_norm.npy\"))\n",
    "        y_train = np.load(os.path.join(fm_dir, \"y_train.npy\"))\n",
    "        y_test = np.load(os.path.join(fm_dir, \"y_test.npy\"))\n",
    "        used_scaler = scaler\n",
    "    else :\n",
    "        X_train = np.load(os.path.join(fm_dir, \"X_train.npy\"))\n",
    "        X_test = np.load(os.path.join(fm_dir, \"X_test.npy\"))\n",
    "        y_train = np.load(os.path.join(fm_dir, \"y_train.npy\"))\n",
    "        y_test = np.load(os.path.join(fm_dir, \"y_test.npy\"))\n",
    "        used_scaler = scaler\n",
    "\n",
    "n_classes = len(np.unique(y_train))\n",
    "\n",
    "\n",
    "# --- STEP 2: Reshape for CNN ---\n",
    "def reshape_for_cnn(arr):\n",
    "    if arr.ndim == 2:                         # (n_samples, 400) → (n,20,20,1)\n",
    "        side = int(np.sqrt(arr.shape[1]))\n",
    "        arr = arr.reshape((-1, side, side, 1))\n",
    "    elif arr.ndim == 3:                       # (n,20,20) → ajoute canal\n",
    "        arr = arr[..., np.newaxis]\n",
    "    return arr\n",
    "\n",
    "X_train = reshape_for_cnn(X_train)\n",
    "X_test  = reshape_for_cnn(X_test)\n",
    "\n",
    "# --- STEP 3: Model builder with hyperparams ---\n",
    "def build_cnn(conv_filters, dense_units, dropout_rate, kernel_size,\n",
    "              n_conv_layers, batch_norm, activation):\n",
    "\n",
    "    model = Sequential([Input(shape=X_train.shape[1:])])\n",
    "\n",
    "    for i in range(n_conv_layers):\n",
    "        model.add(Conv2D(conv_filters * (2**i),\n",
    "                         (kernel_size, kernel_size),\n",
    "                         activation=activation))\n",
    "        if batch_norm:\n",
    "            model.add(BatchNormalization())\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(dense_units, activation=activation))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(n_classes, activation='softmax'))\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# --- STEP 4: Cross-validation function for BO ---\n",
    "def cv_objective(conv_filters, dense_units, dropout_rate, epochs, batch_size,\n",
    "                 patience, kernel_size, n_conv_layers, batch_norm, activation):\n",
    "\n",
    "    # cast & mappings\n",
    "    conv_filters   = int(conv_filters)\n",
    "    dense_units    = int(dense_units)\n",
    "    kernel_size    = int(kernel_size)\n",
    "    n_conv_layers  = int(n_conv_layers)\n",
    "    batch_norm     = bool(round(batch_norm))\n",
    "    activation     = 'relu' if round(activation) == 0 else 'tanh'\n",
    "    epochs         = int(epochs)\n",
    "    batch_size     = int(batch_size)\n",
    "    patience       = int(patience)\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "    scores = []\n",
    "\n",
    "    for tr_idx, val_idx in skf.split(X_train, y_train):\n",
    "        X_tr, X_val = X_train[tr_idx], X_train[val_idx]\n",
    "        y_tr, y_val = y_train[tr_idx], y_train[val_idx]\n",
    "\n",
    "        y_tr_cat  = to_categorical(y_tr,  num_classes=n_classes)\n",
    "        y_val_cat = to_categorical(y_val, num_classes=n_classes)\n",
    "\n",
    "        model = build_cnn(conv_filters, dense_units, dropout_rate,\n",
    "                          kernel_size, n_conv_layers, batch_norm, activation)\n",
    "\n",
    "        es = EarlyStopping(patience=patience, restore_best_weights=True, verbose=0)\n",
    "        model.fit(X_tr, y_tr_cat,\n",
    "                  validation_data=(X_val, y_val_cat),\n",
    "                  epochs=epochs, batch_size=batch_size,\n",
    "                  verbose=0, callbacks=[es])\n",
    "\n",
    "        val_pred = np.argmax(model.predict(X_val, verbose=0), axis=1)\n",
    "        scores.append((val_pred == y_val).mean())\n",
    "\n",
    "    return np.mean(scores)\n",
    "\n",
    "# --- STEP 5: Bayesian Optimization space ---\n",
    "pbounds = {\n",
    "    'conv_filters': (16, 64),\n",
    "    'dense_units': (32, 256),\n",
    "    'dropout_rate': (0.1, 0.5),\n",
    "    'epochs': (5, 30),\n",
    "    'batch_size': (16, 64),\n",
    "    'patience': (2, 10),\n",
    "    'kernel_size': (3, 5),\n",
    "    'n_conv_layers': (1, 3),\n",
    "    'batch_norm': (0, 1),      # 0 = False, 1 = True\n",
    "    'activation': (0, 1)       # 0 = relu, 1 = tanh\n",
    "}\n",
    "\n",
    "optimizer = BayesianOptimization(f=cv_objective,\n",
    "                                 pbounds=pbounds,\n",
    "                                 random_state=42)\n",
    "\n",
    "print(\"🔍 Bayesian optimization en cours…\")\n",
    "optimizer.maximize(init_points=5, n_iter=45)\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 6) MEILLEURS PARAMÈTRES TROUVÉS\n",
    "#    ----------------------------------------------------\n",
    "best = optimizer.max['params']\n",
    "best['conv_filters']  = int(best['conv_filters'])\n",
    "best['dense_units']   = int(best['dense_units'])\n",
    "best['kernel_size']   = int(best['kernel_size'])\n",
    "best['n_conv_layers'] = int(best['n_conv_layers'])\n",
    "best['batch_norm']    = bool(round(best['batch_norm']))\n",
    "best['activation']    = 'relu' if round(best['activation']) == 0 else 'tanh'\n",
    "best['epochs']        = int(best['epochs'])\n",
    "best['batch_size']    = int(best['batch_size'])\n",
    "best['patience']      = int(best['patience'])\n",
    "\n",
    "print(\"\\n✅ Best hyper-parameters:\")\n",
    "print(f\"conv_filters = {int(best['conv_filters'])}\")\n",
    "print(f\"dense_units = {int(best['dense_units'])}\")\n",
    "print(f\"dropout_rate = {float(best['dropout_rate']):.2f}\")\n",
    "print(f\"kernel_size = {int(best['kernel_size'])}\")\n",
    "print(f\"n_conv_layers = {int(best['n_conv_layers'])}\")\n",
    "print(f\"batch_norm = {best['batch_norm']}\")\n",
    "print(f\"activation = {best['activation']}\")\n",
    "print(f\"epochs = {int(best['epochs'])}\")\n",
    "print(f\"batch_size = {int(best['batch_size'])}\")\n",
    "print(f\"patience = {int(best['patience'])}\")\n",
    "print(f\"CV Accuracy = {optimizer.max['target']:.4f}\")\n",
    "\n",
    "\"\"\"\n",
    "# ------------------------------------------------------------------\n",
    "# 7) ENTRAÎNEMENT FINAL SUR TOUT LE TRAIN, ÉVALUATION SUR TEST\n",
    "#    ----------------------------------------------------\n",
    "y_train_cat = to_categorical(y_train, num_classes=n_classes)\n",
    "y_test_cat  = to_categorical(y_test,  num_classes=n_classes)\n",
    "\n",
    "final_model = build_cnn(**best)\n",
    "es = EarlyStopping(patience=best['patience'], restore_best_weights=True)\n",
    "final_model.fit(X_train, y_train_cat,\n",
    "                validation_split=0.2,\n",
    "                epochs=best['epochs'],\n",
    "                batch_size=best['batch_size'],\n",
    "                callbacks=[es], verbose=1)\n",
    "\n",
    "y_pred = np.argmax(final_model.predict(X_test), axis=1)\n",
    "print(\"\\n📊 === HOLD-OUT TEST REPORT ===\")\n",
    "print(classification_report(y_test, y_pred, digits=4))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------ DATASET_2 ------------------\n",
    "\n",
    "AUG NORM :\n",
    "\n",
    "conv_filters = 35\n",
    "dense_units = 255\n",
    "dropout_rate = 0.2605200001496385\n",
    "kernel_size = 3\n",
    "n_conv_layers = 1\n",
    "batch_norm = True\n",
    "activation = relu\n",
    "epochs = 29\n",
    "batch_size = 29\n",
    "patience = 6\n",
    "CV Accuracy = 0.9105\n",
    "\n",
    "AUG NONORM\n",
    "\n",
    "conv_filters = 63\n",
    "dense_units = 184\n",
    "dropout_rate = 0.44\n",
    "kernel_size = 4\n",
    "n_conv_layers = 1\n",
    "batch_norm = True\n",
    "activation = relu\n",
    "epochs = 26\n",
    "batch_size = 57\n",
    "patience = 8\n",
    "CV Accuracy = 0.9097\n",
    "\n",
    "NOAUG NORM\n",
    "\n",
    "conv_filters = 45\n",
    "dense_units = 239\n",
    "dropout_rate = 0.34\n",
    "kernel_size = 3\n",
    "n_conv_layers = 1\n",
    "batch_norm = False\n",
    "activation = relu\n",
    "epochs = 23\n",
    "batch_size = 16\n",
    "patience = 8\n",
    "CV Accuracy = 0.8557\n",
    "\n",
    "NOAUG NONORM\n",
    "\n",
    "conv_filters = 48\n",
    "dense_units = 85\n",
    "dropout_rate = 0.21\n",
    "kernel_size = 3\n",
    "n_conv_layers = 1\n",
    "batch_norm = False\n",
    "activation = relu\n",
    "epochs = 29\n",
    "batch_size = 17\n",
    "patience = 6\n",
    "CV Accuracy = 0.8219\n",
    "\n",
    "\n",
    "------------------ DATASET_2_gun_from_1 ------------------\n",
    "\n",
    "AUG NORM MAX \n",
    "\n",
    "conv_filters = 63\n",
    "dense_units = 211\n",
    "dropout_rate = 0.1682\n",
    "kernel_size = 4\n",
    "n_conv_layers = 1\n",
    "batch_norm = True\n",
    "activation = relu\n",
    "epochs = 30\n",
    "batch_size = 23\n",
    "patience = 5\n",
    "CV Accuracy = 0.8986"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
