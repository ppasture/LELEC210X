{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TO RUN\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\"Machine learning tools\"\n",
    "import pickle\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from classification.datasets import Dataset\n",
    "from classification.utils.audio_student import AudioUtil, Feature_vector_DS\n",
    "\n",
    "from classification.utils.plots import (\n",
    "    plot_decision_boundaries,\n",
    "    plot_specgram,\n",
    "    show_confusion_matrix,\n",
    ")\n",
    "from classification.utils.utils import accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Useful functions to select, read and play the dataset sounds are provided in ``classification/utils/audio_student.py``. <br>\n",
    "\n",
    "As for the H1, you will have to fill some short pieces of code, as well as answer some questions. We already created cells for you to answer the questions to ensure you don't forget it ;). <br>\n",
    "You will find the zones to be briefly filled  with a ``### TO COMPLETE`` in the cells below.\n",
    "\n",
    "<font size=6 color=#009999> 2. Training and Evaluating models on audio signals [~1h30-2h] </font> <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chainsaw\n",
      "fire\n",
      "fireworks\n",
      "gun\n"
     ]
    }
   ],
   "source": [
    "### TO RUN\n",
    "dataset = Dataset()\n",
    "classnames = dataset.list_classes()\n",
    "\n",
    "print(\"\\n\".join(classnames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TO RUN\n",
    "fm_dir = \"data/feature_matrices/\"  # where to save the features matrices\n",
    "model_dir = \"data/models/\"  # where to save the models\n",
    "os.makedirs(fm_dir, exist_ok=True)\n",
    "os.makedirs(model_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In H1, it was not made explicit what we choose as input for the classification model, a.k.a. ``feature vector`` (it was shown in the illustration). <br>\n",
    "The objective is, on the transmitter side, to compute a feature vector containing enough information about the audio signal we want to classify, but not too much in order to limit the data which has to be transmitted wirelessly. This is why in H1 we implemented the ``Hz2Mel`` conversion: a very simple compression of the frequency content. <br>\n",
    "The feature vector we will use here simply consists in taking the first 20 columns of the melspectrogram, corresponding to ~1s, then reshaping it as a vector. This means each feature vector contains ``400`` coefficients, with 20 columns of 20 mels each.  <br>\n",
    "\n",
    "Once the feature vector has been recovered on the receiver side, we can apply any computation on it to guess the right class this sound belongs to. Today, we will simply reuse the simple KNN and LDA classifiers and look at what we already get. \n",
    "\n",
    "<font size=3 color=#FF0000> Important :</font> <br>\n",
    "The analyses that follow are given as food for thoughts. They are not given as step by step improvements of the classifier.\n",
    "\n",
    "<font size=5 color=#009999> 2.1. Creation of the dataset </font> <br>\n",
    "\n",
    "``Feature_vector_DS`` is a class defined in ``classification/utils/audio_student.py``. <br>\n",
    "The functions ``__len__`` and ``__getitem__`` are implemented, meaning you can call :\n",
    "- ``len(myds)`` to get the number of sounds in it.\n",
    "- ``myds[classname,j]`` to get the melspectrogram of the ``j``-th sound from class ``classname``. <br>\n",
    "\n",
    "Two other useful functions are provided:\n",
    "- ``get_audiosignal`` returning the temporal audiosignal at the specified index.\n",
    "- ``display`` playing the sound and showing the associated mel-spectrogram at the specified index.\n",
    "\n",
    "<font size=3 color=#FF0000> Important :</font> <br>\n",
    "Before being able to run the cells below, you will have to reuse your functions from H1 to fill the missing lines in ``audio_student.py`` at ``###TO COMPLETE`` locations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TO RUN\n",
    "\n",
    "\"Creation of the dataset\"\n",
    "myds = Feature_vector_DS(dataset, Nft=512, nmel=20, duration=950, shift_pct=0.0)\n",
    "\n",
    "\"Some attributes...\"\n",
    "myds.nmel\n",
    "myds.duration\n",
    "myds.shift_pct\n",
    "myds.sr\n",
    "myds.data_aug\n",
    "myds.ncol\n",
    "\n",
    "\n",
    "idx = 0\n",
    "#myds.display([\"fire\", idx])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the cell above many times, you should notice it is always the beginning of the sound that is taken for creating the feature vector. ``shift_pct`` meaning *shift percentage* allows to roll the audio signal with a random factor upper bounded by this value. Change ``shift_pct`` to ``0.2`` and observe what happens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the feature matrix : (160, 400)\n",
      "Number of labels : 160\n",
      "Remember the convention shown for the toy example, the feature vectors are arranged on the rows.\n"
     ]
    }
   ],
   "source": [
    "### TO RUN\n",
    "\"Random split of 70:30 between training and validation\"\n",
    "train_pct = 0.7\n",
    "\n",
    "featveclen = len(myds[\"fire\", 0, \"\"])  # number of items in a feature vector\n",
    "nitems = len(myds)  # number of sounds in the dataset\n",
    "naudio = dataset.naudio  # number of audio files in each class\n",
    "nclass = dataset.nclass  # number of classes\n",
    "nlearn = round(naudio * train_pct)  # number of sounds among naudio for training\n",
    "\n",
    "data_aug_factor = 1\n",
    "class_ids_aug = np.repeat(classnames, naudio * data_aug_factor)\n",
    "\n",
    "\"Compute the matrixed dataset, this takes some seconds, but you can then reload it by commenting this loop and decommenting the np.load below\"\n",
    "X = np.zeros((data_aug_factor * nclass * naudio, featveclen))\n",
    "for s in range(data_aug_factor):\n",
    "    for class_idx, classname in enumerate(classnames):\n",
    "        for idx in range(naudio):\n",
    "            featvec = myds[classname, idx, \"\"]\n",
    "            X[s * nclass * naudio + class_idx * naudio + idx, :] = featvec\n",
    "np.save(fm_dir + \"feature_matrix_2D.npy\", X)\n",
    "\"\"\"\n",
    "X = np.load(fm_dir+\"feature_matrix_2D.npy\")\n",
    "\"\"\"\n",
    "\"Labels\"\n",
    "y = class_ids_aug.copy()\n",
    "\n",
    "print(f\"Shape of the feature matrix : {X.shape}\")\n",
    "print(f\"Number of labels : {len(y)}\")\n",
    "\n",
    "print(\n",
    "    \"Remember the convention shown for the toy example, the feature vectors are arranged on the rows.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You might notice that ``feature_matrix_2D.npy`` has been saved in ``data/feature_matrices/`` and can now be loaded instead of recomputing it at every run."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=5 color=#009999> 2.2. First audio classification, metrics and dataset splitting </font> <br>\n",
    "\n",
    "For now we have only prepared the dataset, it remains to feed it to the classifiers. <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TO RUN\n",
    "K = 6  # Number of neighbours for the KNN\n",
    "model_knn = KNeighborsClassifier(\n",
    "    n_neighbors=K, weights=\"distance\", algorithm=\"auto\", metric=\"minkowski\"\n",
    ")  # We explicitly write the default parameters of this KNN classifier once so that you know they exist and can be changed\n",
    "\n",
    "model_lda = LDA(\n",
    "    solver=\"svd\",\n",
    "    shrinkage=None,\n",
    "    priors=None,\n",
    "    n_components=None,\n",
    "    store_covariance=False,\n",
    "    tol=0.0001,\n",
    "    covariance_estimator=None,\n",
    ")  # We explicitly write the default parameters of this LDA classifier once so that you know they exist and can be changed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As for the toy example, we keep the ``accuracy`` and ``confusion matrix`` as performance metrics. <br>\n",
    "\n",
    "Note that here we are not especially interested in a model selection hence we only split the dataset in training and testing parts but we don't split the training set in learning/validation parts. The models are trained on the entire training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the training matrix : (112, 400)\n",
      "Number of training labels : 112\n",
      "Accuracy of KNN with fixed train/validation sets : 56.2%\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAASYAAAEpCAYAAAA+ko8PAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA3kElEQVR4nO3dd1QU19sH8O8gvYNAQERQIbZAomIDBAQs2LDEEjV2jYKAgCjGFoOKRoVo9I0tasxPE2JiMGpixAIqNkTFSEdRbIgNVOoC8/7hYeOKZQd29y7wfM7Zc9g7O3eeYfHxzp0793I8z/MghBAlosI6AEIIeR0lJkKI0qHERAhROpSYCCFKhxITIUTpUGIihCgdSkyEEKVDiYkQonQoMRFClA4lJkKI0qHERAhROswTU2lpKesQCCFKhmP9EK+mpia6du0KNzc3uLu7w8nJCVpaWnWqU/TohoyiU24DOvqyDkEhNuiyjkAx/nlhwjoEufO//T+pPse8xXT06FH069cP58+fh4+PD4yMjODi4oIFCxYgNjaWdXiEEAaYt5heVVFRgcTERGzevBm7d+9GVVUVKisrBddDLaaGhVpMDYe0LSZVOcchlczMTMTFxYlfZWVlGDhwINzd3VmHRghhgHlisrS0RElJCdzd3eHu7o558+bBwcEBHMexDo0QwgjzPiZTU1MUFxcjLy8PeXl5ePDgAUpKSliHRQhhiHliunLlCvLy8hAWFoaysjJ8+eWXMDExgZOTExYsWMA6PEIIA0rV+f348WPExcVh//79+Pnnn6nz+z2o87thoc7v/zDvY9q3b5+40zs1NRXGxsZwcXHB2rVr4ebmxjo8QggDzBPTjBkz4OrqiunTp8PNzQ329vasQyKEMMY8MeXn57MOgRCiZJgnpleVlpaivLxcokxfX59RNIQQVpjflSsqKsKsWbNgZmYGHR0dGBkZSbwIIY0P88Q0d+5cHD9+HN9//z00NDSwbds2LF26FM2aNcOuXbtYh0cIYYD5pdyBAwewa9cuuLu7Y9KkSejZsydsbW1hbW2N3bt3Y+zYsaxDJIQoGPMW05MnT9CqVSsAL/uTnjx5AgBwcXHByZMnWYZGCGGEeWJq1aoVcnJyAABt27bFr7/+CuBlS8rQ0JBhZIQQVpgnpkmTJiE5ORkAEBYWho0bN0JTUxNBQUEIDQ1lHB0hhAXmfUxBQUHin728vJCeno6kpCTY2trCwcGBYWSEEFaYJ6bXWVtbw8DAgC7jCGnEmF/KrVq1CtHR0eL3I0eORNOmTWFpaSm+xCOENC7ME9OmTZtgZWUFAIiNjUVsbCz+/vtveHt7Ux8TIY0U80u5vLw8cWI6ePAgRo4ciT59+sDGxgbdunVjHB0hhAXmLSYjIyPcvn0bAHD48GF4eXkBAHier9VcTPJ08cq/8Ju7BL0Gj8VHzt44dvKMxPbYuARMm/0lnL1H4iNnb6RnXmcUqWyN9huF7w6uR0zaPvx6+Rd8tW0xmrdqzjosmVM1awrzVXPR+uyvsL28H9b7v4dGBzvWYclVZ99B8L/9P/RcMo51KBKYJ6Zhw4ZhzJgx6N27Nx4/fgxvb28AwOXLl2Fra8s4OkklJaVoY9sKC0LePEFbSWkpOjl0QNDMyQqOTL7su9vjzx8PINAnCGFj5qOJqioidi+HppYG69BkRkVfF1Z7IsFXVODu9IW4OXA6Hq7aiqpnL1iHJjdmH7dCh7G98Cj1FutQamB+KRcVFQUbGxvcvn0b33zzDXR1X05XeP/+ffj6KtcMjT17dEHPHl3eun1wP08AwN37DxQVkkIs+HyhxPs1wWuxNzkadg52+Pf8NUZRyZbx1BEQ3X+IBwsixWUVdxvW9/gqNW0N9Fk/Eyfm/QDHgCGsw6mBeWJSU1PDnDlzapS/Or6JKBcdfW0AwPOC54wjkR2dXt1RnJAEi6gF0Opij4oHj1D4y0EU7j3MOjS5cFs2ETePX8Ht0ymUmN4mKysLJ06cQH5+PqqqqiS2LV68mFFU5E04jsOMJTNw7UIKbmYo3yVAbalZWcBg9EA83bkPT7b8As2PPoTplzPBl1fg2f6jrMOTKbvB3WFqb4NfByrvvy3miWnr1q2YOXMmTExMYG5uLrGeHMdx701MZWVlKCsrkyhTKSuDhkbD6f9QJrOW+8GmjQ2Ch4WwDkWmOI5DaUoWHn+7EwBQlnYd6nY2MBg9oEElJl0LY7h+9TlixqxEZZmIdThvxTwxLVu2DMuXL8e8efNqtX9ERASWLl0qUbYwNACL5wbKIjzyCr9wX3T37IaQT+fgUd4j1uHIVMWjJyi/nitRVn4jF3p9nBlFJB9mDi2hbWqA0X8vE5epqDaBZbc2cJjYG//XeiL4KvYLJzFPTE+fPsWIESNqvf/8+fMRHBwsUaby/G5dwyKv8Qv3hXM/J8wZMRd5txtep3DJpVSo2UgOgVC3sYToXsOak/726RTs9gqTKPNaOx1Ps+8h6fuDSpGUACVITCNGjMCRI0cwY8aMWu2voaFR47JNVC6f/82Li0uQe+ee+P3dew+QnnkdBvp6sDA3Q+Gz57ifl4/8R48BADm5dwAAJk2NYNLUWC4xKYL/cj/08umFJVOXoqSoBEamL6c8LnpehPLS8vfsXT88/fEPtNgTCePpo/D88Elo2reBwYj+eLBkHevQZEpUVIonGXcky4rLUPr0RY1ylpgnJltbWyxatAjnzp2Dvb091NTUJLYHBAQwiqyma+lZmOz/3yXnN99tAQD4eHth+cIQnDh1DgtX/He7OXTJSgDAzMlj4TdFuQawCTFo/CAAwNq9qyXKVwevRezeWBYhyVzZtUzcC/gaJkGTYOw7FqI7eXi4chOeHzzBOrRGiflKvC1btnzrNo7jcOOG8FV1aSXehoVW4m046s1KvNWzVxJCSDXmj6QQQsjrmLSYgoODER4eDh0dnRp31F4XGRn5zu2EkIaHSWK6fPkyRCKR+Oe3eXWwJSGk8WCSmE6cOPHGnwkhBKA+JkKIEmJ+Vw4ALl68iF9//RW5ubkoL5ccsLdv3z5GURFCWGHeYvrll1/g5OSEtLQ0/PHHHxCJREhJScHx48dhYGDAOjxCCAPME9OKFSsQFRWFAwcOQF1dHevWrUN6ejpGjhyJFi1asA6PEMIA88R0/fp1DBgwAACgrq6OoqIicByHoKAgbNmyhXF0hBAWmCcmIyMjPH/+ciZES0tLXLv2cqrWgoICFBcXswyNEMII885vV1dXxMbGwt7eHiNGjEBgYCCOHz+O2NhYeHp6sg6PEMIA88S0YcMGlJaWAgAWLFgANTU1nDlzBsOHD8fChQvfszchpCFinpiMjf+bp0hFRQVhYWHv+DQhpDFgnpgAoKqqCtnZ2W9cjMDV1ZVRVIQQVpgnpnPnzmHMmDG4desWXp8aiuM4pVuNlxAif8wT04wZM+Do6IhDhw7BwsKCHtwlhLBPTFlZWfjtt9+UbjlwQgg7zMcxdevWDdnZ2azDIIQoESYtpqtXr4p/9vf3R0hICPLy8t64GIGDg4OiwyOEMMYkMX3yySfgOE6is3vy5Mnin6u3Uec3IY0Tk8RECxAQQt6FSWKytrYW/xwREYEPPvhAosUEANu3b8fDhw9rvXQ4IaT+Yr6unI2NDfbs2QMnJyeJ8vPnz2P06NG1al2pqlvKKjylVhjWk3UICjF0RwHrEIiMHLl9WKrPMb8rl5eXBwsLixrlpqamuH//PoOICCGsMU9MVlZWSEhIqFGekJCAZs2aMYiIEMIa8wGW06ZNw+zZsyESieDh4QEAOHbsGObOnYuQkBDG0RFCWGCemEJDQ/H48WP4+vqKFyLQ1NTEvHnzMH/+fMbREUJYYN75Xe3FixdIS0uDlpYW7OzsoKGhUeu6qPO7YaHO74ZD2s5v5i2marq6uujSpQvrMAghSoB55zchhLyOEhMhROlIdSn36kO370MP3RJC6kqqxPSmh25fRQ/dEkJkSarERA/dEkIUSarE9OpDt4QQIm+16vz+6aef4OzsjGbNmuHWrVsAgG+//Rb79++XaXCEkMZJcGL6/vvvERwcjP79+6OgoEDcp2RoaIhvv/1W1vERQhohwYnpu+++w9atW7FgwQI0adJEXO7o6Ih///1XpsERQhonwYkpJycHHTt2rFGuoaGBoqIimQRFCGncBCemli1b4sqVKzXKDx8+jHbt2skiJkJIIyf4Wbng4GD4+fmhtLQUPM/jwoUL+PnnnxEREYFt27bJI0ZCSCMjODFNnToVWlpaWLhwIYqLizFmzBg0a9YM69atw+jRo+URIyGkkanV7AJjx47F2LFjUVxcjBcvXsDMzEzWcRFCGrFaT3uSn5+PjIwMAC8fSTE1Na1TIOXl5cjJyUHr1q2hqqo0s7EQQhgQ3Pn9/PlzfP7552jWrBnc3Nzg5uaGZs2aYdy4cSgsLBQcQHFxMaZMmQJtbW106NABubm5AF6u0Lty5UrB9RFC6j/BiWnq1Kk4f/48Dh06hIKCAhQUFODgwYO4ePEivvjiC8EBzJ8/H8nJyYiLi4Ompqa43MvLC9HR0YLrI4TUf4KvmQ4ePIh//vkHLi4u4rK+ffti69at6Nevn+AAYmJiEB0dje7du4PjOHF5hw4dcP36dcH1sTBzxgSEBM+Eubkprl5NReDsRUi8eIV1WLLBcVDrNQKqH7uA0zUE//wpKi7HQxS/j3VkMjXabxScvZ1h1bo5ykvLkZqUim0rtuPOjTusQ5Op+nKegltMTZs2hYGBQY1yAwMDGBkZCQ7g4cOHb+w8LyoqkkhUymrEiMFYs3oJwpdFoku3fki+moq/Du2GqWlT1qHJhFpPH6h18UL5oR0o+S4E5Uf2QM1lEFS7Cf9PSJnZd7fHnz8eQKBPEMLGzEcTVVVE7F4OTa3azz2vjOrLeQpOTAsXLkRwcDDy8vLEZXl5eQgNDcWiRYsEB+Do6IhDhw6J31cno23btqFHjx6C61O0oMBp2PbDHvy461ekpWXB1y8MxcUlmDSxYQydULH6EBXpSajMvAy+4CEqU8+jMvsqmjRvzTo0mVrw+ULE7o3FrcxbuJGWgzXBa/FB8w9g52DHOjSZqi/nKdWlXMeOHSVaL1lZWWjRogVatGgBAMjNzYWGhgYePnwouJ9pxYoV8Pb2RmpqKioqKrBu3TqkpqbizJkziI+PF1SXoqmpqaFTJwes/GaDuIzneRw7fhrdu3dmGJnsVN3OhGpnT3BNLcA/vg+VD1qgiXUblB3+iXVocqWjrw0AeF7wnHEk8qWs5ylVYhoyZIjcAnBxcUFycjIiIiJgb2+PI0eOoFOnTjh79izs7e3fu39ZWRnKysokyqpn05Q3ExNjqKqqIv/BI4ny/PyHaNumYbQoRKf2Axpa0PJfC/BVAKcC0bFoVF6tuXpyQ8FxHGYsmYFrF1JwM+MW63DkRpnPU6rEtGTJErkcXCQS4YsvvsCiRYuwdevWWtURERGBpUuXSpRxKrrgmujLIsRGr0mH7lB1cEHZb9+hKv8OmljYQN17/MtO8CsnWYcnF7OW+8GmjQ2ChzXslaCV+TyZrpKipqaG33//vU51zJ8/H4WFhRIvTkVPRhG+26NHT1BRUQGzD0wkys3MTJH34KFCYpA39b7jIDq1H5XXzoLPv42K5FMQnf0Laj19WIcmF37hvuju2Q1zR83Fo7xH79+hnlL28xScmCorK7FmzRp07doV5ubmMDY2lngJNWTIEMTExAjer5qGhgb09fUlXoq6mycSiXDp0lV49Ppv6ATHcfDo5YJz55IUEoO8cWrqwOuLUFS9vKRraPzCfeHczwmho+Yh7/YD1uHITX04T8HjmJYuXYpt27YhJCQECxcuxIIFC3Dz5k3ExMRg8eLFggOws7PD119/jYSEBHTu3Bk6OjoS2wMCAgTXqUhR67Zixw9RSLp0FYmJlxHgPw06OlrY+WPDGBxakXEJaq5DwBc+QlX+HahY2EDNaQBEl+JYhyZT/sv90MunF5ZMXYqSohIYmb4c+lL0vAjlpeWMo5Od+nKeHP+2NZneonXr1li/fj0GDBgAPT09XLlyRVx27tw57NmzR1AALVu2fHtwHIcbN24Iqg8AVNUtBe9TF74zJ4oHWCYnp2B20GJcSLws9+MWhvWU+zGgrgl1z5Fo0q4LOB2Dl31L/yZAFPc7oKCluobuKJD7MY7cPvzG8tXBaxG7N1bux1cU1uf5tuO/TnBi0tHRQVpaGlq0aAELCwscOnQInTp1wo0bN9CxY8daPS8na4pOTKwoJDEpAUUkJqIY0iYmwR0FzZs3x/379wG8bD0dOXIEAJCYmAgNDeUaPUoIqZ8E9zENHToUx44dQ7du3eDv749x48bhhx9+QG5uLoKCgqSqIzg4GOHh4dDR0UFwcPA7PxsZGSk0REJIPSf4Uu51Z8+exdmzZ2FnZ4dBgwZJtY+xsTEyMzNhYmKCXr16vT04jsPx48cFx0SXcg0LXco1HNJeytV5RrYePXoIfqatoKAAVVVVAIBbt24hMTERTZs2jIdeCSF1J1Vi+vPPP6WucPDgwe/9jJGREXJycmBmZoabN2+KkxQhhAAyflaO4zjxyrzvMnz4cLi5ucHCwgIcx8HR0VFi8cxX1Wa4ACGkfpMqMcm6RbNlyxYMGzYM2dnZCAgIwLRp06Cnp5jHSAghyo/ZrP/Vs10mJSUhMDCQEhMhRIz5ciQ7duxgHQIhRMk0vCcxCSH1HiUmQojSocRECFE6UvUxPXv2TOoK9fVp5khCSN1IlZgMDQ2lnnxNmnFMhBDyLlIlphMnToh/vnnzJsLCwjBx4kTxoyhnz57Fjz/+iIiICPlESQhpVKRKTG5ubuKfv/76a0RGRuKzzz4Tlw0ePBj29vbYsmULJkyYIPsoCSGNiuDO77Nnz8LR0bFGuaOjIy5cuCCToAghjZvgxGRlZfXGpZa2bdsGKysrmQRFCGncBI/8joqKwvDhw/H333+jW7duAIALFy4gKyurzksxEUIIUIsWU//+/ZGZmYlBgwbhyZMnePLkCQYNGoTMzEz0799fHjESQhqZWj0rZ2VlhRUrVsg6FkIIAVDLkd+nTp3CuHHj4OTkhLt37wIAfvrpJ5w+fVqmwRFCGifBien3339H3759oaWlhUuXLqGsrAwAUFhYSK0oQohMCF6MoGPHjggKCsL48eOhp6eH5ORktGrVCpcvX4a3tzfy8vLqHFRBQQEMDQ1rvX9rk051jqE+uPVMOZd3ljWPD+xZh6AQxx/8yzoEuasovyvV5wS3mDIyMuDq6lqj3MDAAAUFBUKrw6pVqxAd/d9y2iNHjkTTpk1haWmJ5ORkwfURQuo/wYnJ3Nwc2dnZNcpPnz6NVq1aCQ5g06ZN4vFPsbGxiI2Nxd9//w1vb2+EhoYKro8QUv8Jvis3bdo0BAYGYvv27eA4Dvfu3cPZs2cxZ84cLFq0SHAAeXl54sR08OBBjBw5En369IGNjY14nBQhpHERnJjCwsJQVVUFT09PFBcXw9XVFRoaGpgzZw78/f0FB2BkZITbt2/DysoKhw8fxrJlywAAPM/TTAWENFKCExPHcViwYAFCQ0ORnZ2NFy9eoH379tDV1a1VAMOGDcOYMWNgZ2eHx48fw9vbGwBw+fJl2Nra1qpOQkj9JriPafLkyXj+/DnU1dXRvn17dO3aFbq6uigqKsLkyZMFBxAVFYVZs2ahffv2iI2NFSe4+/fvw9fXV3B9hJD6T/BwgSZNmuD+/fswMzOTKH/06BHMzc1RUVEhKIBnz569ddbL7OzsWrWaaLhAw0LDBRoOmQ8XePbsGQoLC8HzPJ4/f45nz56JX0+fPsVff/1VI1lJY8CAAeJBmq/KyMiAu7u74PoIIfWf1H1M1dPrchyHDz/8sMZ2juOwdOlSwQHo6upi6NCh+PPPP6Gq+jKctLQ0eHh4YOTIkYLrI4TUf1InphMnToDneXh4eOD333+HsbGxeJu6ujqsra3RrFkzwQHs27cPXl5eGDt2LH755RekpKTA09MTY8eORWRkpOD6CCH1n+A+plu3bqFFixZSL04gjYKCAri7u8POzg4nT57E+PHjsXr16lrXR31MDQv1MTUc0vYxCR4ucPz4cejq6mLEiBES5Xv37kVxcbFUc36/vhyUiooKoqOj0bt3bwwfPhyLFi0Sf4aWgyKk8RHcYvrwww+xefNm9OrVS6I8Pj4e06dPR0ZGxnvrUFFReWOLqzoUjuPA8zw4jqvVIEtqMTUs1GJqOOTWYsrNzUXLli1rlFtbWyM3N1eqOl5dDooQQl4nODGZmZnh6tWrsLGxkShPTk5G06ZNpaqjejmoiooKrFixApMnT0bz5s2FhkIIaaAEj/z+7LPPEBAQgBMnTqCyshKVlZU4fvw4AgMDMXr0aEF1qaqqYvXq1YIHZRJCGjbBLabw8HDcvHkTnp6e4nFHVVVVGD9+fK1msPTw8EB8fHyNFhghpPESnJjU1dURHR2N8PBwJCcnQ0tLC/b29rC2tq5VAN7e3ggLC8O///6Lzp07Q0dHR2L74MGDa1UvIaT+EnxXTtZUVN5+NUl35d6N7so1LHRX7j9StZiCg4MRHh4OHR0dBAcHv/OzQkdrV1VVCfo8IaThkyoxXb58GSKRSPzz28hyNDghpPGSKjG9Ou5IHmOQ4uPjsWbNGqSlpQEA2rdvj9DQUPTs2VPmxyKEKL9aLXgpS//73//g5eUFbW1tBAQEICAgAFpaWvD09MSePXtYh0cIYUCqzu9hw4ZJXeG+ffsEBdCuXTtMnz4dQUFBEuWRkZHYunWruBUlhKI6v7v06IRps8bjo4/b4QNzU8z4PBixf8cp5NiAYju/Z86YgJDgmTA3N8XVq6kInL0IiRevKOTYiuj8Hu03Cs7ezrBq3RzlpeVITUrFthXbcefGHbkfu5oiO79ZfZ8ynSjOwMBA/NLX18exY8dw8eJF8fakpCQcO3YMBgYGggO9ceMGBg0aVKN88ODByMnJEVyfImlrayL9Wia+mruSdShyNWLEYKxZvQThyyLRpVs/JF9NxV+HdsPUVLqR/vWBfXd7/PnjAQT6BCFszHw0UVVFxO7l0NTSYB2azNWH71PwcIF58+bhyZMn2LRpE5o0aQIAqKyshK+vL/T19QVPV2Jra4vQ0FB88cUXEuWbNm3C2rVrkZWVJag+gM1wgeuPLjXYFtOZ0weQeDEZgbMXAnh5k+PmjURs/L8d+Gb1Rrkfn8VwAQNjA+xNjkbIp3Pw7/lrCjmmolpMLL9PuT3Eu337dpw+fVqclICX84AHBwfDyclJcGIKCQlBQEAArly5AicnJwBAQkICdu7ciXXr1gkNj8iYmpoaOnVywMpvNojLeJ7HseOn0b17Z4aRyZeOvjYA4HnBc8aRyFZ9+T4FJ6aKigqkp6ejTZs2EuXp6em1GpM0c+ZMmJubY+3atfj1118BvOx3io6Oho+Pz3v3LysrqzFnOM9XgeOY9+s3CCYmxlBVVUX+g0cS5fn5D9G2TWtGUckXx3GYsWQGrl1Iwc2MW6zDkan68n0KTkyTJk3ClClTcP36dXTt2hUAcP78eaxcuRKTJk2qVRBDhw7F0KFDa7VvREREjbnGDbXMYaxtUav6CJm13A82bWwQPCyEdSiNluDEtGbNGnEL5/79+wAACwsLhIaGIiRE+Be5ePFi9OrVCz169ICmpqbg/efPn19jNPonLV0F10Pe7NGjJ6ioqIDZByYS5WZmpsh78JBRVPLjF+6L7p7dEPLpHDzKe/T+HeqZ+vJ9Cr7eUVFRwdy5c3H37l0UFBSgoKAAd+/exdy5cyX6naR19uxZDBo0CIaGhujZsycWLlyIo0ePoqSkRKr9NTQ0oK+vL/GiyzjZEYlEuHTpKjx6uYjLOI6DRy8XnDuXxDAy2fML94VzPyeEjpqHvNsN8znE+vJ9Cm4xAS/7meLi4nD9+nWMGTMGAHDv3j3o6+sLXio8NjYWFRUVOH/+PE6ePIn4+HisX78eZWVl6NKlC06fPl2bEBVCW0cL1i2txO+bW1ui3UcfouDpM9y/m8cwMtmKWrcVO36IQtKlq0hMvIwA/2nQ0dHCzh+jWYcmM/7L/dDLpxeWTF2KkqISGJkaAQCKnhehvLSccXSyVR++T8GJ6datW+jXrx9yc3NRVlaG3r17Q09PD6tWrUJZWRk2bdokPAhVVTg7O8PU1BTGxsbQ09NDTEwM0tPTBdelSPaftMee/VvF7xcue3kp+/vPf2Ku/1eMopK9vXv/hKmJMb5aPAfm5qZITk7BgIHjkJ/fcC51Bo1/OZZu7V7Ju8qrg9cidm8si5Dkpj58n4LHMQ0ZMgR6enr44Ycf0LRpUyQnJ6NVq1aIi4vDtGnTBI872rJlC+Li4hAfH4+ysjL07NkT7u7ucHd3h4ODQ60eDKZpTxoWmvak4ZDbOKZTp07hzJkzUFdXlyi3sbHB3bvSHfRVM2bMgKmpKUJCQuDr6yv4UpAQ0vAI7iWuqqp64+Rtd+7cgZ6enuAA9u3bJ16F19TUFE5OTvjyyy9x5MgRFBcXC66PEFL/CW4x9enTB99++y22bNkC4GWP/osXL7BkyRL0799fcABDhgzBkCFDAACFhYU4deoU9u7di4EDB0JFRQWlpaWC6ySE1G+1GsfUr18/tG/fHqWlpRgzZgyysrJgYmKCn3/+uVZBPH78GPHx8YiLi0NcXBxSUlJgZGRE8zER0kgJTkxWVlZITk5GdHQ0kpOT8eLFC0yZMgVjx46FlpaW4ADs7e2RlpYGIyMjuLq6Ytq0aXBzc4ODg4PgugghDYOgxCQSidC2bVscPHgQY8eOxdixY+scwIwZM+Dm5oaPPvqoznURQhoGQYlJTU1N5n0+fn5+AIDy8nLk5OSgdevW4vXqCCGNk+C7cn5+fli1apXMVs8tKSnBlClToK2tjQ4dOiA3NxcA4O/vj5UrG/YEbISQNxPcNElMTMSxY8dw5MgR2Nvb11igUujUumFhYUhOTkZcXBz69esnLvfy8sJXX32FsLAwoSESQuo5wYnJ0NAQw4cPl1kAMTExiI6ORvfu3SVGeXfo0AHXr1+X2XEIIfWH4MS0Y8cOmQbw8OFDmJmZ1SgvKiqideoIaaSk7mOqqqrCqlWr4OzsjC5duiAsLEzqqUnexdHREYcOHRK/r05G27ZtQ48ePepcPyGk/pG6xbR8+XJ89dVX8PLygpaWFtatW4f8/Hxs3769TgGsWLEC3t7eSE1NRUVFBdatW4fU1FScOXMG8fHxdaqbEFI/Sd1i2rVrF/7v//4P//zzD2JiYnDgwAHs3r27VvN8v8rFxQXJycmoqKiAvb09jhw5AjMzM5w9exadOyvP5OiEEMWRusWUm5sr8Sycl5cXOI7DvXv30Lx581odXCQS4YsvvsCiRYuwdevW9+9ACGkUpG4xVVRU1JiTW01NDSKRqNYHV1NTw++//17r/QkhDZPULSae5zFx4kRoaPy3MmlpaSlmzJghMZZJ6DimIUOGICYmpsYS4YSQxkvqxDRhwoQaZePGjatzAHZ2dvj666+RkJCAzp071xiwGRAQUOdjEELqF8FT68pay5Yt37qN4zjcuHFDcJ00tW7DQlPrNhxym1pX1nJycliHQAhRMrQAGyFE6TBpMQUHByM8PBw6Ojo1VtF9XWRkpIKiIoQoCyaJaefOnfjyyy+ho6ODy5cvv/Vz9KwcIY0Tk8RUUFAgHjF+69YtJCYmomnTpjKrnzqFSX2U2pq+z2pM+piMjIzEnd43b96s82MthJCGhUmLafjw4XBzc4OFhQU4joOjoyOaNGnyxs/WZrgAIaR+Y5KYtmzZgmHDhiE7OxsBAQGYNm1arRbLJIQ0TMzGMVVPo5uUlITAwEBKTIQQMeYDLGU9IyYhpP6jAZaEEKVDiYkQonQoMRFClA4lJkKI0qHERAhROpSYCCFKhxITIUTpUGIihCgdSkyEEKVDiYkQonQoMRFClA4lJkKI0qHERAhROsxnFwCAqqoqZGdnIz8/v8Zslq6uroyiIoSwwjwxnTt3DmPGjMGtW7fw+tqbHMehsrKSUWSEEFaYJ6YZM2bA0dERhw4dEk+1Swhp3JgnpqysLPz222+wtbVlHQohREkw7/zu1q0bsrOzWYdBCFEizFtM/v7+CAkJQV5eHuzt7aGmpiax3cHBgVFk0ps5YwJCgmfC3NwUV6+mInD2IiRevMI6LJkZ7TcKzt7OsGrdHOWl5UhNSsW2Fdtx58Yd1qHJTGM4x2qqZk1hEjIFOq6O4DQ1IMq9h7wvI1GWksU6NDGOf73HWcFUVGo22jiOA8/zte78VlW3lEVoUhkxYjB2bv8Wvn5huJB4GQH+U/Hp8IFo/5ErHj58LNdjK2rBy+U/LUPcn/HITM5EkyYqmDRvEmzaWGOax3SUlpQpJAZ5U4Zz3KAr/2Oo6OvCet9GFJ9PRuEvB1HxpBDq1pYQ3b4P0e37cj/+h2mHpfoc88R069atd263trYWXKciE9OZ0weQeDEZgbMXAniZVG/eSMTG/9uBb1ZvlOuxWa3Ea2BsgL3J0Qj5dA7+PX+NSQzyxuIcFZGYTIInQbNjB9z5fI78D/YG0iYm5pdytUk8ykJNTQ2dOjlg5TcbxGU8z+PY8dPo3r0zw8jkS0dfGwDwvOA540jkp6Geo06v7ihOSIJF1AJodbFHxYNHKPzlIAr3SpcwFIV5Ytq1a9c7t48fP/6d28vKylBWJtnUrr4MlDcTE2Ooqqoi/8EjifL8/Ido26a13I/PAsdxmLFkBq5dSMHNjHe3duurhnyOalYWMBg9EE937sOTLb9A86MPYfrlTPDlFXi2/yjr8MSYJ6bAwECJ9yKRCMXFxVBXV4e2tvZ7E1NERASWLl0qUcap6IJroi/zWAkwa7kfbNrYIHhYCOtQ5KYhnyPHcShNycLjb3cCAMrSrkPdzgYGowcoVWJiPlzg6dOnEq8XL14gIyMDLi4u+Pnnn9+7//z581FYWCjx4lQUs6rvo0dPUFFRAbMPTCTKzcxMkffgoUJiUCS/cF909+yGuaPm4lHeo/fvUA819HOsePQE5ddzJcrKb+RCzcKUUURvxjwxvYmdnR1WrlxZozX1JhoaGtDX15d4KWr0uEgkwqVLV+HRy0VcxnEcPHq54Ny5JIXEoCh+4b5w7ueE0FHzkHf7Aetw5KIxnGPJpVSo2TSXKFO3sYToXj6jiN5MKRMTAKiqquLevXusw3ivqHVbMXXKGHz++Qi0bWuLjRtWQkdHCzt/jGYdmsz4L/eD51APRPivQklRCYxMjWBkagR1TXXWoclMYzhHAHj64x/Q+rgtjKePgloLC+gNcIfBiP4o2HOAdWgSmA8X+PPPPyXe8zyP+/fvY8OGDbCyssLff/8tuE5FDhcAAN+ZE8UDLJOTUzA7aDEuJF6W+3EVNVzgyO0337FZHbwWsXtjFRKDvCnDOSpiuAAA6Lh3hUnQJKhZW0J0Jw8FP+5T2F25ejOO6fUBlhzHwdTUFB4eHli7di0sLCwE16noxMQKq3FMRD4UlZhYqjfjmF6ff4kQQpgnpuDg4DeWcxwHTU1N2NrawsfHB8bGxgqOjBDCCvNLuV69euHSpUuorKxEmzZtAACZmZlo0qQJ2rZti4yMDHAch9OnT6N9+/ZS1UmXcqQ+oku5/zC/K+fj4wMvLy/cu3cPSUlJSEpKwp07d9C7d2989tlnuHv3LlxdXREUFMQ6VEKIgjBvMVlaWiI2NrZGayglJQV9+vTB3bt3cenSJfTp0wePHkk34I1aTKQ+ohbTf5i3mAoLC5GfX3Nw18OHD/Hs2TMAgKGhIcrLyxUdGiGEEeaJycfHB5MnT8Yff/yBO3fu4M6dO/jjjz8wZcoUDBkyBABw4cIFfPjhh2wDJYQoDPO7cps3b0ZQUBBGjx6NiooKAC9HfU+YMAFRUVEAgLZt22Lbtm0swySEKBDzPqZqL168wI0bNwAArVq1gq5u7S+4qY+J1EfUx/Qf5i2marq6uvVifm9CiPwx72MihJDXUWIihCgdSkyEEKVDiYkQonQoMRFClA4lJkKI0qHERAhROpSYCCFKhxITIUTpUGIihCgdSkyEEKVDiYkQonQoMRFClA9P6qy0tJRfsmQJX1payjoUuaLzbDiU/RyVZj6m+uzZs2cwMDBAYWEh9PX1WYcjN3SeDYeynyNdyhFClA4lJkKI0qHERAhROpSYZEBDQwNLliyBhoYG61Dkis6z4VD2c6TOb0KI0qEWEyFE6VBiIoQoHUpMhBCl02gS082bN8FxHK5cuVKnetzd3TF79myZxKRMeJ7H9OnTYWxsDI7jYGhoyPw8lTEmacXFxYHjOBQUFLAOpV5SmgUv64t9+/ZBTU2NdRgyd/jwYezcuRNxcXFo1aoVVFRUoKWlRTERJigxCWRsbMw6BLm4fv06LCws4OTkJNXny8vLoa6u3uhikoZIJGIdQr3X4C7lqqqq8M0338DW1hYaGhpo0aIFli9fLt5+48YN9OrVC9ra2vj4449x9uxZ8bbHjx/js88+g6WlJbS1tWFvb4+ff/5Zov7XL+VsbGywYsUKTJ48GXp6emjRogW2bNki3l5eXo5Zs2bBwsICmpqasLa2RkREhHh7ZGQk7O3toaOjAysrK/j6+uLFixcAXl7KmJqa4rfffhN//pNPPoGFhYX4/enTp6GhoYHi4uJa/84mTpwIf39/5ObmguM42NjYvPE8w8PDMX78eOjr62P69Oni4/fs2RNaWlqwsrJCQEAAioqKah2LvGPasGEDPvroI3EdMTEx4DgOmzZtEpd5eXlh4cKF4vfff/89WrduDXV1dbRp0wY//fSTRKwcx+H777/H4MGDoaOjI/H3Vq24uBje3t5wdnZGQUHBe/8uauv58+cYO3YsdHR0YGFhgaioKInfG8dxiImJkdjH0NAQO3fuBPBfl8e+ffve+u9EIRg+QCwXc+fO5Y2MjPidO3fy2dnZ/KlTp/itW7fyOTk5PAC+bdu2/MGDB/mMjAz+008/5a2trXmRSMTzPM/fuXOHX716NX/58mX++vXr/Pr16/kmTZrw58+fF9fv5ubGBwYGit9bW1vzxsbG/MaNG/msrCw+IiKCV1FR4dPT03me5/nVq1fzVlZW/MmTJ/mbN2/yp06d4vfs2SPePyoqij9+/Difk5PDHzt2jG/Tpg0/c+ZM8fZhw4bxfn5+PM/z/JMnT3h1dXXewMCAT0tL43me55ctW8Y7OzvX6XdWUFDAf/3113zz5s35+/fv8/n5+W88T319fX7NmjV8dna2+KWjo8NHRUXxmZmZfEJCAt+xY0d+4sSJdYpHnjFdvXqV5ziOz8/P53me52fPns2bmJjwo0aN4nme58vLy3ltbW0+NjaW53me37dvH6+mpsZv3LiRz8jI4NeuXcs3adKEP378uDgOALyZmRm/fft2/vr16/ytW7f4EydO8AD4p0+f8k+fPuWdnJz4Pn368EVFRTzPv//voramTp3KW1tb80ePHuX//fdffujQobyenp749waA/+OPPyT2MTAw4Hfs2MHzPC/VvxNFaFCJ6dmzZ7yGhga/devWGtuqf+Hbtm0Tl6WkpPAAxP/I32TAgAF8SEiI+P2b/nGMGzdO/L6qqoo3MzPjv//+e57ned7f35/38PDgq6qqpDqHvXv38k2bNhW/X79+Pd+hQwee53k+JiaG79atG+/j4yOu38vLi//yyy+lqvtdoqKieGtra/H7N53nkCFDJPaZMmUKP336dImyU6dO8SoqKnxJSYlSxlRVVcU3bdqU37t3L8/zPP/JJ5/wERERvLm5Oc/zPH/69GleTU1NnECcnJz4adOmSdQ3YsQIvn///uL3APjZs2dLfKY6MaWlpfEODg788OHD+bKyMvF2oX8X0nj27BmvpqYmPjeef5ngtbW1BScmof9OZK1BXcqlpaWhrKwMnp6eb/2Mg4OD+OfqS6L8/HwAQGVlJcLDw2Fvbw9jY2Po6urin3/+QW5u7juP+2qdHMfB3NxcXOfEiRNx5coVtGnTBgEBAThy5IjEvkePHoWnpycsLS2hp6eHzz//HI8fPxZfmrm5uSE1NRUPHz5EfHw83N3d4e7ujri4OIhEIpw5cwbu7u7S/5LqwNHRUeJ9cnIydu7cCV1dXfGrb9++qKqqQk5OjlLGxHEcXF1dERcXh4KCAqSmpsLX1xdlZWVIT09HfHw8unTpAm1tbQAv/6acnZ0ljuHs7Iy0tLR3xlGtd+/esLW1RXR0tET/1/v+Lmrjxo0bEIlE6Nq1q7jMwMAAbdq0EVzXu/6dKEKDSkzS3LF59Y4ax3EAXvZLAcDq1auxbt06zJs3DydOnMCVK1fQt29flJeXS11ndb3VdXbq1Ak5OTkIDw9HSUkJRo4ciU8//RTAy+v5gQMHwsHBAb///juSkpKwceNGABAfszpJxsfHSySm+Ph4JCYmQiQSSd05XFc6OjoS71+8eIEvvvgCV65cEb+Sk5ORlZWF1q1bK21M1Yn91KlT6NixI/T19cXJKj4+Hm5ubnWOo9qAAQNw8uRJpKamSpS/6+9CnjiOA//aU2hv6qx/178TRWhQd+Xs7OygpaWFY8eOYerUqYL3T0hIgI+PD8aNGwfg5ReRmZmJ9u3b1ykufX19jBo1CqNGjcKnn36Kfv364cmTJ0hKSkJVVRXWrl0LFZWX/0f8+uuvEvtyHIeePXti//79SElJgYuLC7S1tVFWVobNmzfD0dHxrf8o5K1Tp05ITU2Fra0tk+O/iTQxubm5Yfbs2di7d6+4tenu7o6jR48iISEBISEh4s+2a9cOCQkJmDBhgrgsISFB6r+JlStXQldXF56enoiLi5PY721/F7W989uqVSuoqakhMTERLVq0AAAUFhYiMzMTrq6uAABTU1Pcv39fvE9WVladbpzIS4NKTJqampg3bx7mzp0LdXV1ODs74+HDh0hJSXnn5V01Ozs7/Pbbbzhz5gyMjIwQGRmJBw8e1CkxRUZGwsLCAh07doSKigr27t0Lc3NzGBoawtbWFiKRCN999x0GDRqEhIQEibtD1dzd3RESEgJHR0fo6uoCAFxdXbF7926EhobWOra6mjdvHrp3745Zs2Zh6tSp0NHRQWpqKmJjY7FhwwaljcnBwQFGRkbYs2cPDh48CODl73jOnDngOE7i0i00NBQjR45Ex44d4eXlhQMHDmDfvn04evSo1DGtWbMGlZWV8PDwQFxcHNq2bfvOv4va0tPTw4QJExAaGgpjY2OYmZlhyZIlUFFREbd6PDw8sGHDBvTo0QOVlZWYN2+eUo7La1CXcgCwaNEihISEYPHixWjXrh1GjRol9bXxwoUL0alTJ/Tt2xfu7u4wNzfHkCFD6hSPnp4evvnmGzg6OqJLly64efMm/vrrL6ioqODjjz9GZGQkVq1ahY8++gi7d+9+4y1jNzc3VFZWSvQlubu71yhTNAcHB8THxyMzMxM9e/ZEx44dsXjxYjRr1kypY6puhXIcBxcXF/F++vr6NVqgQ4YMwbp167BmzRp06NABmzdvxo4dOwT/3qOiojBy5Eh4eHggMzPznX8XdREZGYkePXpg4MCB8PLygrOzM9q1awdNTU0AwNq1a2FlZYWePXtizJgxmDNnjrg/TZnQtCeENGBFRUWwtLTE2rVrMWXKFNbhSK1BXcoR0thdvnwZ6enp6Nq1KwoLC/H1118DAHx8fBhHJgwlJkIamDVr1iAjIwPq6uro3LkzTp06BRMTE9ZhCUKXcoQQpdPgOr8JIfUfJSZCiNKhxEQIUTqUmAghSocSEyFE6VBiIvWCjY0Nvv32W6k/v3Pnzjo93lHtTROrEfmjxETeiuO4d76++uor1iGSBooGWJK3evUp9OjoaCxevBgZGRnisuoHioGX0wBXVlZCVZX+pEjdUYuJvJW5ubn4ZWBgIJ4Ez9zcHOnp6dDT08Pff/+Nzp07Q0NDA6dPn8bEiRNrPPg8e/ZsiYdeq6qqEBERgZYtW0JLSwsff/yxxLzm0njXXOmviomJgZ2dHTQ1NdG3b1/cvn1bYvv+/fvRqVMnaGpqolWrVli6dCkqKioExUJkjxITqZOwsDCsXLkSaWlpErMevktERAR27dqFTZs2ISUlBUFBQRg3bhzi4+OlPq6KigrWr1+PlJQU/Pjjjzh+/Djmzp0r8Zni4mIsX74cu3btQkJCAgoKCjB69Gjx9lOnTmH8+PEIDAxEamoqNm/ejJ07d75xMQGiYAqbxJfUazt27OANDAzE76vntI6JiZH43IQJE3gfHx+JssDAQN7NzY3neZ4vLS3ltbW1+TNnzkh8ZsqUKfxnn3321uNbW1vzUVFRb93++lzpO3bs4AHw586dE5elpaXxAMSLS3h6evIrVqyQqOenn37iLSwsxO/xhjmyifxRhwCpk7fNdf022dnZKC4uRu/evSXKy8vL0bFjR6nrOXr0KCIiIpCeno5nz56hoqICpaWlKC4uFs8vpKqqii5duoj3adu2LQwNDZGWloauXbsiOTkZCQkJEi2kysrKGvUQxaPEROrk9Wl9VVRU3jmndHU/0KFDh2BpaSnxOQ0NDamOWT1X+syZM7F8+XIYGxvj9OnTmDJlCsrLy6VOKC9evMDSpUsxbNiwGtuqJ1YjbFBiIjJlamqKa9euSZRduXJFPH1r+/btoaGhgdzc3FpN+g9AqrnSAaCiogIXL14UrxqSkZGBgoICtGvXDsDL+cEzMjKUas5y8hIlJiJTHh4eWL16NXbt2oUePXrgf//7H65duya+TNPT08OcOXMQFBSEqqoquLi4oLCwEAkJCdDX15eY9P9tpJ0rXU1NDf7+/li/fj1UVVUxa9YsdO/eXZyoFi9ejIEDB6JFixb49NNPoaKiguTkZFy7dg3Lli2T7S+GCEJ35YhM9e3bF4sWLcLcuXPRpUsXPH/+HOPHj5f4THh4OBYtWoSIiAi0a9cO/fr1w6FDh9CyZUupjiHtXOna2tqYN28exowZA2dnZ+jq6iI6Oloi1oMHD+LIkSPo0qULunfvjqioKFhbW9ftl0DqjCaKI4QoHWoxEUKUDiUmQojSocRECFE6lJgIIUqHEhMhROlQYiKEKB1KTIQQpUOJiRCidCgxEUKUDiUmQojSocRECFE6/w+lSoe1d46qWAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 300x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of LDA with fixed train/validation sets : 62.5%\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 300x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### TO RUN\n",
    "\"Shuffle then split the dataset into training and testing subsets\"\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, stratify=y\n",
    ")  # random_state=1\n",
    "print(f\"Shape of the training matrix : {X_train.shape}\")\n",
    "print(f\"Number of training labels : {len(y_train)}\")\n",
    "\n",
    "model_knn.fit(X_train, y_train)\n",
    "model_lda.fit(X_train, y_train)\n",
    "\n",
    "prediction_knn = model_knn.predict(X_test)\n",
    "prediction_lda = model_lda.predict(X_test)\n",
    "accuracy_knn = accuracy(prediction_knn, y_test)\n",
    "accuracy_lda = accuracy(prediction_lda, y_test)\n",
    "\n",
    "print(f\"Accuracy of KNN with fixed train/validation sets : {100 * accuracy_knn:.1f}%\")\n",
    "show_confusion_matrix(prediction_knn, y_test, classnames)\n",
    "print(f\"Accuracy of LDA with fixed train/validation sets : {100 * accuracy_lda:.1f}%\")\n",
    "show_confusion_matrix(prediction_lda, y_test, classnames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Questions**: \n",
    "- What would be the expected accuracy if the label predictions were picked at random?\n",
    "- What do you observe in this confusion matrix? Run again the cell above, i.e., Reapply the ``train_test_split`` and tell if your observations are robust."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TO COMPLETE\n",
    "# Answer the questions above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Play with the ``classname`` and the index ``idx`` to pick feature vectors in the dataset ``myds``, listen to the audio associated to the feature vector, and check if you would have been able to predict the right class by your own. Then compare with the prediction given by your classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m classname \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfire\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m#myds.display([classname, idx])\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m thisfv \u001b[38;5;241m=\u001b[39m \u001b[43mmyds\u001b[49m\u001b[43m[\u001b[49m\u001b[43mclassname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# this artefact is necessary because the 'predict' function expects a matrix_like input.\u001b[39;00m\n\u001b[1;32m      8\u001b[0m mat \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((\u001b[38;5;241m2\u001b[39m, \u001b[38;5;28mlen\u001b[39m(thisfv)))\n",
      "File \u001b[0;32m~/master_projet_elec/LELEC210X/classification/src/classification/utils/audio_student.py:380\u001b[0m, in \u001b[0;36mFeature_vector_DS.__getitem__\u001b[0;34m(self, cls_index)\u001b[0m\n\u001b[1;32m    374\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, cls_index: Tuple[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mstr\u001b[39m]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[ndarray, \u001b[38;5;28mint\u001b[39m]:\n\u001b[1;32m    375\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    376\u001b[0m \u001b[38;5;124;03m    Get i'th item in dataset.\u001b[39;00m\n\u001b[1;32m    377\u001b[0m \n\u001b[1;32m    378\u001b[0m \u001b[38;5;124;03m    :param cls_index: Class name and index.\u001b[39;00m\n\u001b[1;32m    379\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 380\u001b[0m     aud \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_audiosignal\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcls_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    381\u001b[0m     sgram \u001b[38;5;241m=\u001b[39m AudioUtil\u001b[38;5;241m.\u001b[39mmelspectrogram(aud, Nmel\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnmel, Nft\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mNft)\n\u001b[1;32m    382\u001b[0m     aug \u001b[38;5;241m=\u001b[39m cls_index[\u001b[38;5;241m2\u001b[39m]\n",
      "File \u001b[0;32m~/master_projet_elec/LELEC210X/classification/src/classification/utils/audio_student.py:348\u001b[0m, in \u001b[0;36mFeature_vector_DS.get_audiosignal\u001b[0;34m(self, cls_index)\u001b[0m\n\u001b[1;32m    342\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_audiosignal\u001b[39m(\u001b[38;5;28mself\u001b[39m, cls_index: Tuple[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mstr\u001b[39m]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[ndarray, \u001b[38;5;28mint\u001b[39m]:\n\u001b[1;32m    343\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    344\u001b[0m \u001b[38;5;124;03m    Get temporal signal of i'th item in dataset.\u001b[39;00m\n\u001b[1;32m    345\u001b[0m \n\u001b[1;32m    346\u001b[0m \u001b[38;5;124;03m    :param cls_index: Class name and index.\u001b[39;00m\n\u001b[1;32m    347\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 348\u001b[0m     aug \u001b[38;5;241m=\u001b[39m \u001b[43mcls_index\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m    349\u001b[0m     cls_index \u001b[38;5;241m=\u001b[39m cls_index[:\u001b[38;5;241m2\u001b[39m]\n\u001b[1;32m    350\u001b[0m     audio_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[cls_index]\n",
      "\u001b[0;31mIndexError\u001b[0m: tuple index out of range"
     ]
    }
   ],
   "source": [
    "### TO RUN\n",
    "idx = 0\n",
    "classname = \"fire\"\n",
    "#myds.display([classname, idx])\n",
    "thisfv = myds[classname, idx].reshape(-1)\n",
    "\n",
    "# this artefact is necessary because the 'predict' function expects a matrix_like input.\n",
    "mat = np.zeros((2, len(thisfv)))\n",
    "mat[0] = thisfv\n",
    "\n",
    "prediction_knn = model_knn.predict(mat)\n",
    "prediction_lda = model_lda.predict(mat)\n",
    "\n",
    "print(\"Class predicted by KNN:\", prediction_knn[0])\n",
    "print(\"Class predicted by LDA:\", prediction_lda[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Furthermore, when training a model and comparing different settings, there is a risk that we will end up choosing optimal parameters that only render good result on our specific case of training and validation set, but ``do not generalize well for additional data``. This is called ``overfitting on the validation set``. To alleviate this, we can perform ``cross-validation (CV)``. A basic approach named ``K-fold CV`` involves partitioning the dataset in ``K`` \"folds\" (subsets) and repetitvely do the following procedure:\n",
    "\n",
    "- Train the model using `K-1` folds as the training data.\n",
    "- Test the model using the last fold as the validation data.\n",
    "\n",
    "The overall performance on each fold is then averaged to obtain the final performance metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TO RUN\n",
    "n_splits = 5\n",
    "kf = StratifiedKFold(n_splits=n_splits, shuffle=True)\n",
    "\n",
    "accuracy_knn = np.zeros((n_splits,))\n",
    "accuracy_lda = np.zeros((n_splits,))\n",
    "for k, idx in enumerate(kf.split(X_train, y_train)):\n",
    "    (idx_learn, idx_val) = idx\n",
    "    model_knn.fit(X_train[idx_learn], y_train[idx_learn])\n",
    "    prediction_knn = model_knn.predict(X_train[idx_val])\n",
    "    accuracy_knn[k] = accuracy(prediction_knn, y_train[idx_val])\n",
    "\n",
    "    model_lda.fit(X_train[idx_learn], y_train[idx_learn])\n",
    "    prediction_lda = model_lda.predict(X_train[idx_val])\n",
    "    accuracy_lda[k] = accuracy(prediction_lda, y_train[idx_val])\n",
    "\n",
    "print(f\"Mean accuracy of KNN with 5-Fold CV: {100 * accuracy_knn.mean():.1f}%\")\n",
    "print(\n",
    "    f\"Std deviation in accuracy of KNN with 5-Fold CV: {100 * accuracy_knn.std():.1f}%\"\n",
    ")\n",
    "\n",
    "print(f\"Mean accuracy of LDA with 5-Fold CV: {100 * accuracy_lda.mean():.1f}%\")\n",
    "print(\n",
    "    f\"Std deviation in accuracy of LDA with 5-Fold CV: {100 * accuracy_lda.std():.1f}%\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=5 color=#009999> 2.3. Scale mismatch and countermeasure </font> <br>\n",
    "\n",
    "In real conditions, you will most probably have a different scale between the feature vectors used for training (in simulation) and the ones you feed in your model to make predictions.\n",
    "This scale mismatch between model training and prediction is difficult to prevent because it depends on multiple factors such as the audio source power, its distance to the microphone, the telecommunication distance. <br>\n",
    "\n",
    "Below, we illustrate the link between the volume of the audio and its distance to the origin of the feature space. At different emission distances, the exact same sound would be heard at a different volume and the associated feature vector would be located at another position in the *feature space*. Eventually, this would result in a completely different classification, which is undesirable.\n",
    "\n",
    "<center> <img src=\"figs/norms.png\" alt=\"\" width=\"350\"/> </center>\n",
    "\n",
    "### Questions:\n",
    "\n",
    "- How could you avoid this dependency on the volume of the sound?\n",
    "- What is represented in the hatched centered area? How would you classify feature vectors in this area?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TO COMPLETE\n",
    "# Answer the questions above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Play with the ``dB_mismatch`` variable here below and observe its effect on the confusion matrix.\n",
    "\n",
    "On which part of the dataset are we computing this confusion matrix?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TO RUN\n",
    "dB_mismatch = 0  # Play with this value\n",
    "X_val_scaled = X_train[idx_val] * 10 ** (-dB_mismatch / 20)\n",
    "\n",
    "model_knn = KNeighborsClassifier(n_neighbors=10)\n",
    "model_knn.fit(X_train[idx_learn], y_train[idx_learn])\n",
    "prediction_knn = model_knn.predict(X_val_scaled)\n",
    "show_confusion_matrix(prediction_knn, y_train[idx_val], classnames)\n",
    "accuracy_knn = accuracy(prediction_knn, y_train[idx_val])\n",
    "print(f\"Accuracy of KNN: {100 * accuracy_knn:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The simplest countermeasure we can think of is to normalise the feature vector (i.e. unitize its norm) prior to use, both for training and testing. Remember how this normalization could be visualized in ``hands_on_classif1_toy_student.ipynb`` <br>\n",
    "Play again with the ``dB_mismatch`` variable here below and observe its effect on the confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TO RUN\n",
    "dB_mismatch = 0  # Play with this value\n",
    "\n",
    "X_learn_normalised = X_train[idx_learn] / np.linalg.norm(\n",
    "    X_train[idx_learn], axis=1, keepdims=True\n",
    ")\n",
    "model_knn = KNeighborsClassifier(n_neighbors=10, weights=\"distance\")\n",
    "model_knn.fit(X_learn_normalised, y_train[idx_learn])\n",
    "\n",
    "X_val_scaled = X_train[idx_val] * 10 ** (-dB_mismatch / 20)\n",
    "X_val_normalised = X_val_scaled / np.linalg.norm(X_val_scaled, axis=1, keepdims=True)\n",
    "\n",
    "prediction_knn = model_knn.predict(X_val_normalised)\n",
    "show_confusion_matrix(prediction_knn, y_train[idx_val], classnames)\n",
    "accuracy_knn = accuracy(prediction_knn, y_train[idx_val])\n",
    "print(f\"Accuracy of KNN: {100 * accuracy_knn:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question**: \n",
    "- What will happen with this normalisation countermeasure when there is no sound around the microphone? Is this desirable? How could you deal with it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TO COMPLETE\n",
    "# Answer the questions above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=5 color=#009999> 2.4. Dimensionality reduction </font> <br>\n",
    "\n",
    "It is sometimes good practice to reduce the dimensionality of a signal in order to get the main components of their distribution. A motivation is that usual norms behave counter-inuitively in high dimension. It also further reduces the memory cost of the feature vector. To reduce the dimensionality, we will use the ``Principal component analysis (PCA)`` proposed by sklearn. See the [associated Wikipedia page](https://en.wikipedia.org/wiki/Principal_component_analysis). Recall: the PCA consists in reducing the dimensionality of data vectors encoded in $\\boldsymbol X \\in \\mathbb R^{d\\times N}$ to only $p \\ll d$ dimensions as\n",
    "\n",
    "$$\n",
    "    \\boldsymbol Y = \\boldsymbol V_p^\\top \\boldsymbol X \\in \\mathbb R^{p\\times N},\n",
    "$$\n",
    "\n",
    "where the SVD of the covariance matrix writes as $\\hat{\\boldsymbol\\Sigma}_{\\boldsymbol X} = \\frac{1}{d} \\boldsymbol{XX}^\\top = \\boldsymbol{U\\Sigma V}^\\top$, and $\\boldsymbol V_p$ is the subselection of the first $p$ columns of $\\boldsymbol V$. \n",
    "\n",
    "For our application, reducing the dimensionality of the data can be helpful for compressing the packet size to be transmitted wirelessly. Indeed, once learned during training, $\\boldsymbol V_p$ can be hardcoded on the transmitter side.\n",
    "\n",
    "Starting with a PCA to 2D for visualization, see how hard it is to separate the classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TO RUN\n",
    "n = 2  # Number of principal components kept\n",
    "pca = PCA(n_components=n, whiten=True)\n",
    "X_learn_reduced = pca.fit_transform(X_train[idx_learn])\n",
    "X_val_reduced = pca.transform(X_train[idx_val])\n",
    "\n",
    "print(f\"Shape of the reduced training matrix : {X_learn_reduced.shape}\")\n",
    "\n",
    "y_train_num = np.zeros(y_train.shape)\n",
    "for i, classname in enumerate(classnames):\n",
    "    y_train_num[y_train == classname] = i\n",
    "\n",
    "K = 10\n",
    "model_knn = KNeighborsClassifier(n_neighbors=K)\n",
    "model_knn.fit(X_learn_reduced, y_train_num[idx_learn])\n",
    "prediction_knn = model_knn.predict(X_val_reduced)\n",
    "accuracy_knn = accuracy(prediction_knn, y_train_num[idx_val])\n",
    "\n",
    "model_lda = LDA()\n",
    "model_lda.fit(X_learn_reduced, y_train_num[idx_learn])\n",
    "prediction_lda = model_lda.predict(X_val_reduced)\n",
    "accuracy_lda = accuracy(prediction_lda, y_train_num[idx_val])\n",
    "\n",
    "fig = plt.figure()\n",
    "axs = [fig.add_axes([0.0, 0.0, 0.4, 0.9]), fig.add_axes([0.6, 0.0, 0.4, 0.9])]\n",
    "plot_decision_boundaries(\n",
    "    X_learn_reduced,\n",
    "    y_train_num[idx_learn],\n",
    "    ax=axs[0],\n",
    "    model=model_knn,\n",
    "    legend=classnames,\n",
    "    title=\"KNN\",\n",
    ")\n",
    "plot_decision_boundaries(\n",
    "    X_learn_reduced,\n",
    "    y_train_num[idx_learn],\n",
    "    ax=axs[1],\n",
    "    model=model_lda,\n",
    "    legend=classnames,\n",
    "    title=\"LDA\",\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question**: \n",
    "- From the decision boundaries shown here above, can you explain why the ``handsaw`` class is less often chosen than the other classes for the ``KNN`` classifier?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TO COMPLETE\n",
    "# Answer the questions above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TO RUN\n",
    "n = 5  # Number of principal components kept\n",
    "pca = PCA(n_components=n, whiten=True)\n",
    "X_learn_reduced = pca.fit_transform(X_train[idx_learn])\n",
    "X_val_reduced = pca.transform(X_train[idx_val])\n",
    "\n",
    "print(f\"Shape of the reduced learning matrix : {X_learn_reduced.shape}\")\n",
    "\n",
    "K = 10\n",
    "model_knn = KNeighborsClassifier(n_neighbors=K, weights=\"distance\")\n",
    "model_knn.fit(X_learn_reduced, y_train[idx_learn])\n",
    "prediction_knn = model_knn.predict(X_val_reduced)\n",
    "accuracy_knn = accuracy(prediction_knn, y_train[idx_val])\n",
    "\n",
    "model_lda = LDA()\n",
    "model_lda.fit(X_learn_reduced, y_train[idx_learn])\n",
    "prediction_lda = model_lda.predict(X_val_reduced)\n",
    "accuracy_lda = accuracy(prediction_lda, y_train[idx_val])\n",
    "\n",
    "print(f\"Accuracy of the KNN : {100 * accuracy_knn:.1f}%\")\n",
    "show_confusion_matrix(prediction_knn, y_train[idx_val], classnames)\n",
    "print(f\"Accuracy of the LDA : {100 * accuracy_lda:.1f}%\")\n",
    "show_confusion_matrix(prediction_lda, y_train[idx_val], classnames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=5 color=#009999> 2.5. Analysis of the hyperparameters </font> <br>\n",
    "\n",
    "Finally, we can inspect the influence of ``hyperparameters`` as we did for the toy example. <br>\n",
    "Let us start by analyzing the influence of the number of neighbours $K$ in the KNN. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TO RUN\n",
    "Ks = np.arange(6, 15, 1)\n",
    "accuracies_knn = np.zeros((len(Ks), n_splits))\n",
    "for i, K in enumerate(Ks):\n",
    "    model_knn = KNeighborsClassifier(n_neighbors=K, weights=\"distance\")\n",
    "    for k, idx in enumerate(kf.split(X_train, y_train)):\n",
    "        (idx_learn, idx_val) = idx\n",
    "        model_knn.fit(X_train[idx_learn], y_train[idx_learn])\n",
    "        prediction_knn = model_knn.predict(X_train[idx_val])\n",
    "        accuracies_knn[i, k] = accuracy(prediction_knn, y_train[idx_val])\n",
    "means_knn = accuracies_knn.mean(axis=1)\n",
    "stds_knn = accuracies_knn.std(axis=1)\n",
    "\n",
    "\"Plot\"\n",
    "plt.figure(figsize=(6, 3))\n",
    "plt.plot(Ks, means_knn, \".-b\", label=\"KNN\")\n",
    "plt.fill_between(Ks, means_knn - stds_knn, means_knn + stds_knn, alpha=0.2, color=\"b\")\n",
    "plt.ylim(0, 1)\n",
    "plt.xlabel(\"K\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we consider both ``K`` and the number of principal components ``n``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TO RUN\n",
    "Ks = np.arange(1, 10)\n",
    "n_comps = np.arange(2, 15)  # number of principal components kept for the PCA\n",
    "accuracies_knn = np.zeros((len(Ks), len(n_comps)))\n",
    "accuracies_lda = np.zeros(len(n_comps))\n",
    "\n",
    "for j, n in enumerate(n_comps):\n",
    "    for idx_learn, idx_val in kf.split(X_train, y_train):\n",
    "        pca = PCA(n_components=n, whiten=True)\n",
    "        X_learn_reduced = pca.fit_transform(X_train[idx_learn])\n",
    "        X_val_reduced = pca.transform(X_train[idx_val])\n",
    "        for i, K in enumerate(Ks):\n",
    "            model_knn = KNeighborsClassifier(n_neighbors=K)\n",
    "            model_knn.fit(X_train[idx_learn], y_train[idx_learn])\n",
    "            prediction_knn = model_knn.predict(X_train[idx_val])\n",
    "            accuracies_knn[i, j] += accuracy(prediction_knn, y_train[idx_val])\n",
    "\n",
    "        model_lda = LDA()\n",
    "        model_lda.fit(X_train[idx_learn], y_train[idx_learn])\n",
    "        prediction_lda = model_lda.predict(X_train[idx_val])\n",
    "        accuracies_lda[j] += accuracy(prediction_lda, y_train[idx_val])\n",
    "\n",
    "accuracies_knn /= n_splits\n",
    "accuracies_lda /= n_splits\n",
    "\n",
    "fig = plt.figure(figsize=(10, 4))\n",
    "axs = [fig.add_axes([0.0, 0.0, 0.4, 0.9]), fig.add_axes([0.6, 0.0, 0.4, 0.9])]\n",
    "\n",
    "im0 = axs[0].imshow(100 * accuracies_knn, cmap=\"jet\", origin=\"lower\")\n",
    "cbar = fig.colorbar(im0, ax=axs[0])\n",
    "cbar.set_label(\"Accuracy (%)\")\n",
    "axs[0].set_xlabel(\"n_PCA\")\n",
    "axs[0].set_ylabel(\"K\")\n",
    "axs[0].set_xticks(list(np.arange(len(n_comps))))\n",
    "axs[0].set_xticklabels(list(n_comps))\n",
    "axs[0].set_yticks(list(np.arange(len(Ks))))\n",
    "axs[0].set_yticklabels(list(Ks))\n",
    "axs[0].set_title(\"KNN\")\n",
    "\n",
    "axs[1].plot(accuracies_lda * 100)\n",
    "axs[1].set_xlabel(\"n_PCA\")\n",
    "axs[1].set_ylabel(\"Accuracy (%)\")\n",
    "axs[1].set_title(\"LDA\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question**: \n",
    "- Do you observe some dependency of the accuracy on these parameters? If so, which one(s)? If not, discuss what it tells about the considered model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TO COMPLETE\n",
    "# Answer the question above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=5 color=#009999> 2.6. Augmenting the data </font> <br>\n",
    "\n",
    "In order to make our classifier more robust to some common transformations of the audio signal such as ``time shift``, ``AWGN``, or a ``transfer function``, an idea consists in feeding the classifier with such transformations. A popular approach is to create new feature vectors based on transformed versions of the sounds from the original dataset, this is called ``data augmentation``. Data augmentation is also often used when there is few data to train a model. <br>\n",
    "\n",
    "The functions to augment your data are written in ``utils/audio_student.py``, we already implemented ``time_shift``, ``echo`` and ``spectro_aug_timefreq_masking`` for you. Try to implement ``scaling``, ``add_noise``, ``filter``, ``add_bg`` and even more data augmentation techniques if you want, and check their working in the cell below. <br>\n",
    "\n",
    "<u>Tip</u>: to avoid restarting the notebook kernel for each modification, you can temporarily insert the ``AudioUtil`` class in a new cell and make your tests until it is working as expected. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TO RUN\n",
    "myds.data_aug = None  # Ensure\n",
    "\n",
    "cls_index = [\"birds\", 4]\n",
    "\n",
    "sound = dataset.__getitem__(cls_index)\n",
    "name = dataset.__getname__(cls_index)\n",
    "audio = AudioUtil.open(sound)\n",
    "\n",
    "#AudioUtil.play(audio)\n",
    "audio2 = AudioUtil.resample(audio, 11025)\n",
    "audio2 = AudioUtil.pad_trunc(audio2, 5000)\n",
    "\n",
    "audio3 = AudioUtil.time_shift(audio2, 0.4)\n",
    "audio4 = AudioUtil.scaling(audio2)\n",
    "audio5 = AudioUtil.add_noise(audio2, sigma=1e-2)\n",
    "audio6 = AudioUtil.echo(audio2, 3)\n",
    "audio7 = AudioUtil.add_bg(audio2, dataset)\n",
    "\n",
    "melspec = AudioUtil.melspectrogram(audio2, fs2=11025)\n",
    "melspec2 = AudioUtil.spectro_aug_timefreq_masking(melspec, max_mask_pct=0.1)\n",
    "\n",
    "\"Plot\"\n",
    "fig = plt.figure(figsize=(15, 4))\n",
    "ax1 = fig.add_axes([0.05, 0.05, 0.28, 0.9])\n",
    "ax2 = fig.add_axes([0.38, 0.05, 0.28, 0.9])\n",
    "ax3 = fig.add_axes([0.7, 0.05, 0.28, 0.9])\n",
    "\n",
    "ax1.plot(audio2[0], label=\"Original\")\n",
    "ax1.plot(audio3[0] + 1, label=\"Time shifted\")\n",
    "ax1.plot(audio4[0] + 2, label=\"Rescaled\")\n",
    "ax1.plot(audio5[0] + 3, label=\"Noisy\")\n",
    "ax1.plot(audio6[0] + 4, label=\"With echos\")\n",
    "ax1.plot(audio7[0] + 5, label=\"With background sound\")\n",
    "ax1.legend()\n",
    "\n",
    "plot_specgram(melspec, ax2, is_mel=True, title=name, tf=len(audio2[0]) / audio2[1])\n",
    "ax2.set_title(\"Melspectrogram\")\n",
    "plot_specgram(melspec2, ax3, is_mel=True, title=name, tf=len(audio2[0]) / audio2[1])\n",
    "ax3.set_title(\"Corrupted melspectrogram\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now create a new augmented dataset and observe if the classification results improve. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ORIGINAL MODEL NO AUGMENTATION\n",
    "myds.mod_data_aug([\"original\"])\n",
    "y_aug = np.repeat(classnames, dataset.naudio * myds.data_aug_factor)  # Labels\n",
    "\n",
    "\"Compute the matrixed dataset, this takes some seconds, but you can then reload it by commenting this loop and decommenting the np.load below\"\n",
    "X_aug = np.zeros((myds.data_aug_factor * nclass * naudio, featveclen))\n",
    "for s in range(myds.data_aug_factor):\n",
    "    for idx in range(dataset.naudio):\n",
    "        for class_idx, classname in enumerate(classnames):\n",
    "            featvec = myds[classname, idx, \"\"]\n",
    "            X_aug[s * nclass * naudio + class_idx * naudio + idx, :] = featvec\n",
    "            \n",
    "X_aug = X_aug[200:]\n",
    "y_aug = y_aug[200:]\n",
    "np.save(fm_dir + \"original_feature_matrix_2D_aug.npy\", X_aug)\n",
    "np.save(fm_dir + \"original_labels_aug.npy\", y_aug)\n",
    "\n",
    "\n",
    "print(f\"Shape of the feature matrix : {X_aug.shape}\")\n",
    "print(f\"Number of labels : {len(y_aug)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score\n",
    "from classification.utils.utils import accuracy\n",
    "from collections import defaultdict\n",
    "\n",
    "# Load dataset\n",
    "X = np.load(fm_dir + \"original_feature_matrix_2D_aug.npy\")\n",
    "X = X / np.linalg.norm(X, axis=1, keepdims=True)  # Normalization\n",
    "y = np.load(fm_dir + \"original_labels_aug.npy\", allow_pickle=True)\n",
    "\n",
    "# Number of iterations\n",
    "n_iterations = 100\n",
    "\n",
    "# Storage for metrics\n",
    "overall_accuracies = []\n",
    "mean_cv_accuracies = []\n",
    "\n",
    "# Per-class metrics storage\n",
    "classes = np.unique(y)\n",
    "n_classes = len(classes)\n",
    "class_precisions = np.zeros((n_iterations, n_classes))\n",
    "class_recalls = np.zeros((n_iterations, n_classes))\n",
    "class_accuracies = np.zeros((n_iterations, n_classes))\n",
    "\n",
    "for iteration in range(n_iterations):\n",
    "    # Train-test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.3, stratify=y\n",
    "    )  # random_state is not set for randomness across iterations\n",
    "    \n",
    "    # Train the Random Forest model\n",
    "    model = RandomForestClassifier(\n",
    "        n_estimators=200,\n",
    "        max_depth=20,\n",
    "        min_samples_split=5,\n",
    "        min_samples_leaf=2,\n",
    "        random_state=42\n",
    "    )\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Evaluate model\n",
    "    predict = model.predict(X_test)\n",
    "    \n",
    "    # Compute overall accuracy\n",
    "    overall_accuracy = accuracy(predict, y_test)\n",
    "    overall_accuracies.append(overall_accuracy)\n",
    "    \n",
    "    # Cross-validation accuracy\n",
    "    cv_scores = cross_val_score(model, X_train, y_train, cv=10, scoring='accuracy')\n",
    "    mean_cv_accuracies.append(np.mean(cv_scores))\n",
    "    \n",
    "    # Compute metrics for each class\n",
    "    precision_per_class = precision_score(y_test, predict, average=None, labels=classes)\n",
    "    recall_per_class = recall_score(y_test, predict, average=None, labels=classes)\n",
    "    \n",
    "    conf_matrix = confusion_matrix(y_test, predict, labels=classes)\n",
    "    test_accuracy_per_class = []\n",
    "    for i, cls in enumerate(classes):\n",
    "        class_accuracy = conf_matrix[i, i] / conf_matrix[i, :].sum()\n",
    "        test_accuracy_per_class.append(class_accuracy)\n",
    "    \n",
    "    # Store per-class metrics\n",
    "    class_precisions[iteration] = precision_per_class\n",
    "    class_recalls[iteration] = recall_per_class\n",
    "    class_accuracies[iteration] = test_accuracy_per_class\n",
    "\n",
    "    print(f\"Iteration {iteration + 1}/{n_iterations}: Overall Test Accuracy = {overall_accuracy:.4f}\")\n",
    "\n",
    "# Compute final averages and standard deviations\n",
    "mean_overall_accuracy = np.mean(overall_accuracies)\n",
    "std_overall_accuracy = np.std(overall_accuracies)\n",
    "\n",
    "mean_cv_accuracy = np.mean(mean_cv_accuracies)\n",
    "std_cv_accuracy = np.std(mean_cv_accuracies)\n",
    "\n",
    "mean_class_precisions = np.mean(class_precisions, axis=0)\n",
    "std_class_precisions = np.std(class_precisions, axis=0)\n",
    "\n",
    "mean_class_recalls = np.mean(class_recalls, axis=0)\n",
    "std_class_recalls = np.std(class_recalls, axis=0)\n",
    "\n",
    "mean_class_accuracies = np.mean(class_accuracies, axis=0)\n",
    "std_class_accuracies = np.std(class_accuracies, axis=0)\n",
    "\n",
    "# Print results\n",
    "print(\"\\nFinal Results after 100 iterations:\")\n",
    "print(f\"Overall Test Accuracy: {mean_overall_accuracy:.4f} ± {std_overall_accuracy:.4f}\")\n",
    "print(f\"Mean CV Accuracy: {mean_cv_accuracy:.4f} ± {std_cv_accuracy:.4f}\")\n",
    "\n",
    "print(\"\\nPer-Class Metrics (Mean ± Std over 100 iterations):\")\n",
    "for i, cls in enumerate(classes):\n",
    "    print(f\"Class {cls}:\")\n",
    "    print(f\"  Precision: {mean_class_precisions[i]:.4f} ± {std_class_precisions[i]:.4f}\")\n",
    "    print(f\"  Recall: {mean_class_recalls[i]:.4f} ± {std_class_recalls[i]:.4f}\")\n",
    "    print(f\"  Accuracy: {mean_class_accuracies[i]:.4f} ± {std_class_accuracies[i]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Questions**:\n",
    "- Can you see an improvement of the classification result compared to the non augmented dataset? Try to interpret your answer by thinking about the distribution of points in a data space (as with the toy example), what does it imply to augment the data in terms of distribution of points in the data space?\n",
    "- With the ``add_bg`` augmentation technique, where are the additive background signals coming from? It is a good thing?\n",
    "- What transformations are most likely to be realistic in your application? What is the most efficient way to integrate these alterations in your classification task? ``Hint``: it does not require augmenting your data in Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TO COMPLETE\n",
    "# Answer the question above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=5 color=#009999> 2.7. Getting it all together </font> <br>\n",
    "\n",
    "Now that some aspects to be considered during the model training and analysis have been presented, it remains to train and save a final model that will be used for further predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example for WITH DATA AUGMENTATION\n",
    "myds.mod_data_aug([\"\"])  # No data augmentation\n",
    "augmented_audios = []\n",
    "for i in range(len(classnames)):\n",
    "    for index in range(40):\n",
    "        class_sound = [classnames[i], index]\n",
    "        sound = dataset.__getitem__(cls_index)\n",
    "        audio = AudioUtil.open(sound)\n",
    "        audio_resampled = AudioUtil.resample(audio, 11025)\n",
    "        audio_padded = AudioUtil.pad_trunc(audio_resampled, 5000)\n",
    "        audio_noisy = AudioUtil.add_noise(audio_padded, sigma=0.1)\n",
    "        augmented_audios.append(audio_noisy)\n",
    "\n",
    "print(len(augmented_audios))\n",
    "print(augmented_audios[0])\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(augmented_audios[0][0])\n",
    "plt.title(\"Waveform of the First Augmented Audio\")\n",
    "plt.xlabel(\"Samples\")\n",
    "plt.ylabel(\"Amplitude\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOT THE FEATURE VECTORS AFTER TRANSFORMATION\n",
    "\n",
    "myds.mod_data_aug([\"add_bg\", \"add_echo\", \"15\", \"20\"])\n",
    "X_aug = np.zeros((myds.data_aug_factor * nclass * naudio, featveclen))\n",
    "y_aug = np.empty((myds.data_aug_factor * nclass * naudio), dtype=object)\n",
    "# Génération des vecteurs de caractéristiques et des étiquettes\n",
    "for s in range(myds.data_aug_factor):\n",
    "    for idx in range(dataset.naudio):\n",
    "        for class_idx, classname in enumerate(classnames):\n",
    "            featvec = myds[classname, idx]\n",
    "            X_aug[s * nclass * naudio + class_idx * naudio + idx, :] = featvec\n",
    "            y_aug[s * nclass * naudio + class_idx * naudio + idx] = classname\n",
    "y_aug = np.array(y_aug)\n",
    "\n",
    "def plot_augmented_waveforms_from_X_aug(X_aug, y_aug, start_idx, classe):\n",
    "    \"\"\"\n",
    "    Plots the waveforms of a specific sound for each augmentation type from X_aug.\n",
    "\n",
    "    :param X_aug: Matrix containing feature vectors for all augmented sounds.\n",
    "    :param y_aug: Labels corresponding to the feature matrix.\n",
    "    :param classnames: List of class names in the dataset.\n",
    "    :param class_to_plot: Name of the class to visualize.\n",
    "    :param naudio: Number of original sounds per class.\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(15, 7))\n",
    "\n",
    "    # Find the index of the class to plot\n",
    "\n",
    "\n",
    "    # Retrieve the original and augmented sounds for the given class\n",
    "\n",
    "    sounds = [\n",
    "        X_aug[start_idx],           # Original\n",
    "        X_aug[start_idx + 200], # Time Shifted\n",
    "        X_aug[start_idx + 2 * 200], # Scaled\n",
    "        X_aug[start_idx + 3 * 200], # Noisy\n",
    "        X_aug[start_idx + 4 * 200], # Echoed\n",
    "    ]\n",
    "\n",
    "    labels = [\"Original\", \"1\", \"2\", \"3\", \"4\"]\n",
    "\n",
    "    # Normalize and plot each sound\n",
    "    for i, (sound, label) in enumerate(zip(sounds, labels)):\n",
    "        normalized_sound = sound / np.max(np.abs(sound))  # Normalize to max amplitude of 1\n",
    "        ax.plot(normalized_sound + i * 2, label=label)  # Offset each plot vertically\n",
    "\n",
    "    ax.set_title(f\"Temporal Signals for Class '{classe}'\")\n",
    "    ax.set_xlabel(\"Sample Index\")\n",
    "    ax.set_ylabel(\"Amplitude\")\n",
    "    ax.legend(loc=\"upper right\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Specify the class you want to visualize\n",
    "index = 0\n",
    "classe = y_aug[index]\n",
    "plot_augmented_waveforms_from_X_aug(X_aug, y_aug, index, classe)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# celles qui marchent : \"noise\", \"add_bg\", \"scaling\", \"time_shift\", \"aug_sgram\"\n",
    "# celles qui marchent pas : \"filter\", \"echo\"\n",
    "list_augmentation = [\"original\", \"noise\", \"add_bg\", \"time_shift\", \"aug_sgram\", \"echo\", \"toremove\"]\n",
    "myds.mod_data_aug(list_augmentation)\n",
    "\n",
    "nclass = dataset.nclass\n",
    "naudio = dataset.naudio\n",
    "featveclen = len(myds[\"fire\", 0, \"original\"])\n",
    "\n",
    "\n",
    "\n",
    "X_aug = np.zeros((myds.data_aug_factor * nclass * naudio, featveclen))\n",
    "y_aug = np.empty((myds.data_aug_factor * nclass * naudio), dtype=object)\n",
    "# Génération des vecteurs de caractéristiques et des étiquettes\n",
    "for s in range(len(list_augmentation)):\n",
    "    aug = list_augmentation[s]\n",
    "    for idx in range(dataset.naudio):\n",
    "        for class_idx, classname in enumerate(classnames):\n",
    "            featvec = myds[classname, idx, aug]\n",
    "            X_aug[s * nclass * naudio + class_idx * naudio + idx, :] = featvec\n",
    "            y_aug[s * nclass * naudio + class_idx * naudio + idx] = classname\n",
    "y_aug = np.array(y_aug)\n",
    "# remove last\n",
    "X_aug = X_aug[:-400]\n",
    "y_aug = y_aug[:-400]\n",
    "# Sauvegarde des matrices de caractéristiques\n",
    "np.save(fm_dir + \"augmented_feature_matrix_2D_final.npy\", X_aug)\n",
    "np.save(fm_dir + \"augmented_labels_2D_final.npy\", y_aug)\n",
    "\n",
    "print(f\"Shape of the feature matrix : {X_aug.shape}\")\n",
    "print(f\"Number of labels : {len(y_aug)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_aug = np.load(fm_dir + \"feature_matrix_2D_final.npy\")\n",
    "y_aug = np.load(fm_dir + \"labels_2D_final.npy\",allow_pickle=True)\n",
    "\n",
    "X1 = X_aug[31]\n",
    "X2 = X_aug[831]\n",
    "\n",
    "difference = X1 - X2\n",
    "print(f\"Norm of the difference between X_aug[220] and X_aug[420]: {np.linalg.norm(difference)}\")\n",
    "\n",
    "# Plot X_aug[0], X_aug[200], and their difference\n",
    "plt.figure(figsize=(12, 9))\n",
    "\n",
    "\n",
    "# Plot the difference\n",
    "plt.subplot(3, 1, 1)\n",
    "plt.plot(difference, label=\"Difference (X_aug[0] - X_aug[200])\", color='green')\n",
    "plt.title(\"Difference Between X_aug[0] and X_aug[200]\")\n",
    "plt.xlabel(\"Feature Index\")\n",
    "plt.ylabel(\"Value\")\n",
    "plt.legend()\n",
    "\n",
    "# Plot X_aug[0]\n",
    "plt.subplot(3, 1, 2)\n",
    "plt.plot(X1, label=\"X_aug[0] (Original Sound)\")\n",
    "plt.title(\"Feature Vector for X_aug[0]\")\n",
    "plt.xlabel(\"Feature Index\")\n",
    "plt.ylabel(\"Value\")\n",
    "plt.legend()\n",
    "\n",
    "# Plot X_aug[200]\n",
    "plt.subplot(3, 1, 3)\n",
    "plt.plot(X2, label=\"X_aug[200] (Augmented Sound)\", color='orange')\n",
    "plt.title(\"Feature Vector for X_aug[200]\")\n",
    "plt.xlabel(\"Feature Index\")\n",
    "plt.ylabel(\"Value\")\n",
    "plt.legend()\n",
    "\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FINAL MODEL SAVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score\n",
    "from classification.utils.utils import accuracy\n",
    "from collections import defaultdict\n",
    "\n",
    "# Directories\n",
    "fm_dir = \"data/feature_matrices/\"\n",
    "model_dir = \"data/models/\"\n",
    "os.makedirs(fm_dir, exist_ok=True)\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "# Load dataset\n",
    "X_augmented = np.load(fm_dir + \"augmented_feature_matrix_2D_final.npy\")\n",
    "X_augmented = X_augmented / np.linalg.norm(X_augmented, axis=1, keepdims=True)  # Normalization\n",
    "y_augmented = np.load(fm_dir + \"augmented_labels_2D_final.npy\", allow_pickle=True)\n",
    "\n",
    "X_original = X_augmented[:200]\n",
    "y_original = y_augmented[:200]\n",
    "\n",
    "start_idx = 200\n",
    "augmentation_factor = len(X_augmented) // len(X_original)  # Number of transformations\n",
    "\n",
    "# Parameters\n",
    "n_per_class_test = 28  # 70% of 40 sounds per class\n",
    "\n",
    "# Store results\n",
    "results = defaultdict(list)\n",
    "\n",
    "train_indices, test_indices = [], []\n",
    "for cls in np.unique(y_original):\n",
    "    class_indices = np.where(y_original == cls)[0]\n",
    "    selected_indices = np.random.choice(class_indices, size=n_per_class_test, replace=False)\n",
    "    remaining_indices = np.setdiff1d(class_indices, selected_indices)\n",
    "    train_indices.extend(selected_indices)\n",
    "    test_indices.extend(remaining_indices)\n",
    "\n",
    "train_indices = np.array(train_indices)\n",
    "test_indices = np.array(test_indices)\n",
    "\n",
    "# Prepare train and test sets\n",
    "X_train = X_original[train_indices]\n",
    "y_train = y_original[train_indices]\n",
    "X_test = X_original[test_indices]\n",
    "y_test = y_original[test_indices]\n",
    "\n",
    "for i in range(1, augmentation_factor):  # Skip the original (already included)\n",
    "    augmented_train_indices = start_idx + train_indices + (i - 1) * len(X_original)\n",
    "    X_train = np.vstack([X_train, X_augmented[augmented_train_indices]])\n",
    "    y_train = np.concatenate([y_train, y_augmented[augmented_train_indices]])\n",
    "\n",
    "    augmented_test_indices = start_idx + test_indices + (i - 1) * len(X_original)\n",
    "    X_test = np.vstack([X_test, X_augmented[augmented_test_indices]])\n",
    "    y_test = np.concatenate([y_test, y_augmented[augmented_test_indices]])\n",
    "\n",
    "\"\"\"\n",
    "# Dimension reduction\n",
    "rf_dim_reducer = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_dim_reducer.fit(X_train, y_train)\n",
    "importances = rf_dim_reducer.feature_importances_\n",
    "top_features_idx = np.argsort(importances)[::-1][:200]\n",
    "X_train = X_train[:, top_features_idx]\n",
    "X_test = X_test[:, top_features_idx]\n",
    "\"\"\"\n",
    "    \n",
    "# Train the Random Forest model\n",
    "model = RandomForestClassifier(\n",
    "    n_estimators=400,\n",
    "    max_depth=20,\n",
    "    min_samples_split=5,\n",
    "    min_samples_leaf=2,\n",
    "    random_state=42\n",
    ")\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate model\n",
    "predict = model.predict(X_test)\n",
    "\n",
    "# Compute metrics for each class\n",
    "classes = np.unique(y_test)\n",
    "precision_per_class = precision_score(y_test, predict, average=None, labels=classes)\n",
    "recall_per_class = recall_score(y_test, predict, average=None, labels=classes)\n",
    "\n",
    "test_accuracy_per_class = []\n",
    "conf_matrix = confusion_matrix(y_test, predict, labels=classes)\n",
    "\n",
    "for i, cls in enumerate(classes):\n",
    "    # Calculate accuracy for each class\n",
    "    class_accuracy = conf_matrix[i, i] / conf_matrix[i, :].sum()\n",
    "    test_accuracy_per_class.append(class_accuracy)\n",
    "\n",
    "# Cross-validation accuracy\n",
    "cv_scores = cross_val_score(model, X_train, y_train, cv=10, scoring='accuracy')\n",
    "mean_cv_accuracy = np.mean(cv_scores)\n",
    "\n",
    "show_confusion_matrix(predict, y_test, classnames)\n",
    "plt.savefig(\"confusion_matrix.svg\", format=\"svg\")\n",
    "\n",
    "# Print results\n",
    "print(\"\\nOverall Metrics:\")\n",
    "print(f\"Test Accuracy (Overall): {accuracy(predict, y_test):.4f}\")\n",
    "print(f\"Mean CV Accuracy: {mean_cv_accuracy:.4f}\")\n",
    "\n",
    "print(\"\\nPer-Class Metrics:\")\n",
    "for i, cls in enumerate(classes):\n",
    "    print(f\"Class {cls}:\")\n",
    "    print(f\"  Precision: {precision_per_class[i]:.4f}\")\n",
    "    print(f\"  Recall: {recall_per_class[i]:.4f}\")\n",
    "    print(f\"  Accuracy: {test_accuracy_per_class[i]:.4f}\")\n",
    "\n",
    "\n",
    "# SAVE THE MODEL\n",
    "filename = \"final_model.pickle\"\n",
    "pickle.dump(model, open(model_dir + filename, \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from classification.utils.utils import accuracy\n",
    "from collections import defaultdict\n",
    "\n",
    "# Directories\n",
    "fm_dir = \"data/feature_matrices/\"\n",
    "model_dir = \"data/models/\"\n",
    "os.makedirs(fm_dir, exist_ok=True)\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "# Load dataset\n",
    "X_augmented = np.load(fm_dir + \"feature_matrix_2D_final.npy\")\n",
    "X_augmented = X_augmented / np.linalg.norm(X_augmented, axis=1, keepdims=True)  # Normalization\n",
    "y_augmented = np.load(fm_dir + \"labels_2D_final.npy\", allow_pickle=True)\n",
    "\n",
    "X_original = X_augmented[:200]\n",
    "y_original = y_augmented[:200]\n",
    "\n",
    "# Parameters\n",
    "n_iterations = 50\n",
    "n_per_class_test = 28  # 70% of 40 sounds per class\n",
    "\n",
    "# Store results\n",
    "results = defaultdict(list)\n",
    "\n",
    "for iteration in range(n_iterations):\n",
    "    train_indices, test_indices = [], []\n",
    "    for cls in np.unique(y_original):\n",
    "        class_indices = np.where(y_original == cls)[0]\n",
    "        selected_indices = np.random.choice(class_indices, size=n_per_class_test, replace=False)\n",
    "        remaining_indices = np.setdiff1d(class_indices, selected_indices)\n",
    "        train_indices.extend(selected_indices)\n",
    "        test_indices.extend(remaining_indices)\n",
    "\n",
    "    train_indices = np.array(train_indices)\n",
    "    test_indices = np.array(test_indices)\n",
    "\n",
    "    # Prepare train and test sets\n",
    "    X_train = X_original[train_indices]\n",
    "    y_train = y_original[train_indices]\n",
    "    X_test = X_original[test_indices]\n",
    "    y_test = y_original[test_indices]\n",
    "\n",
    "    start_idx = 200\n",
    "    augmentation_factor = len(X_augmented) // len(X_original)  # Number of transformations\n",
    "\n",
    "    for i in range(1, augmentation_factor):  # Skip the original (already included)\n",
    "        augmented_test_indices = start_idx + test_indices + (i - 1) * len(X_original)\n",
    "        X_test = np.vstack([X_test, X_augmented[augmented_test_indices]])\n",
    "        y_test = np.concatenate([y_test, y_augmented[augmented_test_indices]])\n",
    "\n",
    "    # Train the Random Forest model\n",
    "    model = RandomForestClassifier(\n",
    "        n_estimators=400,\n",
    "        max_depth=20,\n",
    "        min_samples_split=5,\n",
    "        min_samples_leaf=2,\n",
    "        random_state=42\n",
    "    )\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Evaluate model\n",
    "    predict = model.predict(X_test)\n",
    "    test_accuracy = accuracy(predict, y_test)\n",
    "    cv_scores = cross_val_score(model, X_train, y_train, cv=10, scoring='accuracy')\n",
    "    mean_cv_accuracy = np.mean(cv_scores)\n",
    "\n",
    "    # Store results\n",
    "    results[\"test_accuracy\"].append(test_accuracy)\n",
    "    results[\"cv_accuracy\"].append(mean_cv_accuracy)\n",
    "\n",
    "# Calculate mean and std of results\n",
    "mean_test_accuracy = np.mean(results[\"test_accuracy\"])\n",
    "std_test_accuracy = np.std(results[\"test_accuracy\"])\n",
    "mean_cv_accuracy = np.mean(results[\"cv_accuracy\"])\n",
    "std_cv_accuracy = np.std(results[\"cv_accuracy\"])\n",
    "\n",
    "# Print results\n",
    "print(\"Mean Results over 10 iterations:\")\n",
    "print(f\"Mean Test Accuracy: {mean_test_accuracy:.4f} ± {std_test_accuracy:.4f}\")\n",
    "print(f\"Mean CV Accuracy: {mean_cv_accuracy:.4f} ± {std_cv_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=5 color=#009999> 2.8. Debriefing </font> <br>\n",
    "**Questions** : \n",
    "\n",
    "1) from what we have done in this notebook, can you already identify some weaknesses in the feature vector computation and classification pipeline? You can make a list here below, and eventually write some short ideas for improvement. This will help you later :)\n",
    "2) Do you remember what is the time duration of a feature vector? What happens if no sound is produced during the acquisition time of a feature vector?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MEAN ACCURACY ON 100 ITERATIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from classification.utils.utils import accuracy\n",
    "from collections import defaultdict\n",
    "\n",
    "# celles qui marchent : \"noise\", \"add_bg\", \"scaling\", \"time_shift\", \"aug_sgram\"\n",
    "# celles qui marchent pas : \"filter\", \"echo\"\n",
    "list_augmentation = [\"original\", \"noise\", \"add_bg\", \"time_shift\", \"aug_sgram\", \"echo\", \"toremove\"]\n",
    "myds.mod_data_aug(list_augmentation)\n",
    "\n",
    "nclass = dataset.nclass\n",
    "naudio = dataset.naudio\n",
    "featveclen = len(myds[\"fire\", 0, \"original\"])\n",
    "\n",
    "\n",
    "\n",
    "X_aug = np.zeros((myds.data_aug_factor * nclass * naudio, featveclen))\n",
    "y_aug = np.empty((myds.data_aug_factor * nclass * naudio), dtype=object)\n",
    "# Génération des vecteurs de caractéristiques et des étiquettes\n",
    "for s in range(len(list_augmentation)):\n",
    "    aug = list_augmentation[s]\n",
    "    for idx in range(dataset.naudio):\n",
    "        for class_idx, classname in enumerate(classnames):\n",
    "            featvec = myds[classname, idx, aug]\n",
    "            X_aug[s * nclass * naudio + class_idx * naudio + idx, :] = featvec\n",
    "            y_aug[s * nclass * naudio + class_idx * naudio + idx] = classname\n",
    "y_aug = np.array(y_aug)\n",
    "# remove last\n",
    "X_aug = X_aug[:-400]\n",
    "y_aug = y_aug[:-400]\n",
    "# Sauvegarde des matrices de caractéristiques\n",
    "np.save(fm_dir + \"feature_matrix_2D_final.npy\", X_aug)\n",
    "np.save(fm_dir + \"labels_2D_final.npy\", y_aug)\n",
    "\n",
    "print(f\"Shape of the feature matrix : {X_aug.shape}\")\n",
    "print(f\"Number of labels : {len(y_aug)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Augmented trained set ||||| original test set\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import numpy as np\n",
    "\n",
    "# Load augmented data and normalize\n",
    "X_augmented = np.load(fm_dir + \"feature_matrix_2D_final.npy\")\n",
    "X_augmented = X_augmented / np.linalg.norm(X_augmented, axis=1, keepdims=True)  # Normalization\n",
    "y_augmented = np.load(fm_dir + \"labels_2D_final.npy\", allow_pickle=True)\n",
    "\n",
    "\n",
    "X_original = X_augmented[:200]\n",
    "y_original = y_augmented[:200]\n",
    "\n",
    "# Utility function for accuracy\n",
    "def accuracy(pred, true):\n",
    "    return accuracy_score(true, pred)\n",
    "\n",
    "# Initialize metrics storage\n",
    "overall_accuracies = []\n",
    "overall_precisions = []\n",
    "overall_recalls = []\n",
    "\n",
    "n_iterations = 20\n",
    "n_per_class_test = 26\n",
    "\n",
    "# Store per-class metrics\n",
    "classes = np.unique(y_augmented)\n",
    "n_classes = len(classes)\n",
    "class_precisions = np.zeros((n_iterations, n_classes))\n",
    "class_recalls = np.zeros((n_iterations, n_classes))\n",
    "class_accuracies = np.zeros((n_iterations, n_classes))\n",
    "\n",
    "\n",
    "for iteration in range(n_iterations):\n",
    "    # Randomly split train/test data\n",
    "    train_indices, test_indices = [], []\n",
    "    for cls in np.unique(y_original):\n",
    "        class_indices = np.where(y_original == cls)[0]\n",
    "        selected_indices = np.random.choice(class_indices, size=n_per_class_test, replace=False)\n",
    "        remaining_indices = np.setdiff1d(class_indices, selected_indices)\n",
    "\n",
    "        train_indices.extend(selected_indices)\n",
    "        test_indices.extend(remaining_indices)\n",
    "\n",
    "    train_indices = np.array(train_indices)\n",
    "    test_indices = np.array(test_indices)\n",
    "\n",
    "    X_train = X_augmented[train_indices]\n",
    "    y_train = y_augmented[train_indices]\n",
    "\n",
    "    X_test = X_augmented[test_indices]\n",
    "    y_test = y_augmented[test_indices]\n",
    "\n",
    "    start_idx = 200\n",
    "    augmentation_factor = len(X_augmented) // len(X_original)\n",
    "    for i in range(1, augmentation_factor):\n",
    "        augmented_train_indices = start_idx + train_indices + (i - 1) * len(X_original)\n",
    "        X_train = np.vstack([X_train, X_augmented[augmented_train_indices]])\n",
    "        y_train = np.concatenate([y_train, y_augmented[augmented_train_indices]])\n",
    "\n",
    "\n",
    "    # Train the Random Forest classifier\n",
    "    model = RandomForestClassifier(\n",
    "        n_estimators=200,\n",
    "        max_depth=20,\n",
    "        min_samples_split=5,\n",
    "        min_samples_leaf=2,\n",
    "        random_state=42\n",
    "    )\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Evaluate the model\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Overall metrics\n",
    "    overall_accuracy = accuracy(y_pred, y_test)\n",
    "    overall_precision = precision_score(y_test, y_pred, average='macro')\n",
    "    overall_recall = recall_score(y_test, y_pred, average='macro')\n",
    "\n",
    "    # Per-class metrics\n",
    "    precision_per_class = precision_score(y_test, y_pred, average=None, labels=classes)\n",
    "    recall_per_class = recall_score(y_test, y_pred, average=None, labels=classes)\n",
    "    cm = confusion_matrix(y_test, y_pred, labels=classes)\n",
    "    accuracy_per_class = np.diag(cm) / np.sum(cm, axis=1)\n",
    "\n",
    "    # Store metrics\n",
    "    overall_accuracies.append(overall_accuracy)\n",
    "    overall_precisions.append(overall_precision)\n",
    "    overall_recalls.append(overall_recall)\n",
    "\n",
    "    class_precisions[iteration] = precision_per_class\n",
    "    class_recalls[iteration] = recall_per_class\n",
    "    class_accuracies[iteration] = accuracy_per_class\n",
    "\n",
    "    # Print progress\n",
    "    print(f\"Iteration {iteration + 1}/{n_iterations}: Test Accuracy = {overall_accuracy:.4f}\")\n",
    "\n",
    "# Compute final overall metrics\n",
    "mean_overall_accuracy = np.mean(overall_accuracies)\n",
    "std_overall_accuracy = np.std(overall_accuracies)\n",
    "\n",
    "mean_overall_precision = np.mean(overall_precisions)\n",
    "std_overall_precision = np.std(overall_precisions)\n",
    "\n",
    "mean_overall_recall = np.mean(overall_recalls)\n",
    "std_overall_recall = np.std(overall_recalls)\n",
    "\n",
    "# Compute final per-class metrics\n",
    "mean_class_precisions = np.mean(class_precisions, axis=0)\n",
    "std_class_precisions = np.std(class_precisions, axis=0)\n",
    "\n",
    "mean_class_recalls = np.mean(class_recalls, axis=0)\n",
    "std_class_recalls = np.std(class_recalls, axis=0)\n",
    "\n",
    "mean_class_accuracies = np.mean(class_accuracies, axis=0)\n",
    "std_class_accuracies = np.std(class_accuracies, axis=0)\n",
    "\n",
    "# Print final results\n",
    "print(\"\\nFinal Results after 20 iterations:\")\n",
    "print(f\"Overall Accuracy: {mean_overall_accuracy:.4f} ± {std_overall_accuracy:.4f}\")\n",
    "print(f\"Overall Precision: {mean_overall_precision:.4f} ± {std_overall_precision:.4f}\")\n",
    "print(f\"Overall Recall: {mean_overall_recall:.4f} ± {std_overall_recall:.4f}\")\n",
    "\n",
    "print(\"\\nPer-Class Metrics:\")\n",
    "for i, cls in enumerate(classes):\n",
    "    print(f\"Class {cls}:\")\n",
    "    print(f\"  Precision: {mean_class_precisions[i]:.4f} ± {std_class_precisions[i]:.4f}\")\n",
    "    print(f\"  Recall: {mean_class_recalls[i]:.4f} ± {std_class_recalls[i]:.4f}\")\n",
    "    print(f\"  Accuracy: {mean_class_accuracies[i]:.4f} ± {std_class_accuracies[i]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Augmented trained set ||||| augmented test set\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import precision_score, recall_score, confusion_matrix\n",
    "\n",
    "def accuracy(y_pred, y_true):\n",
    "    return np.mean(y_pred == y_true)\n",
    "\n",
    "# Assuming y_original, n_per_class_test, X_original, etc. are defined\n",
    "# Also assuming that the classes in y_original are consistent with y_augmented\n",
    "\n",
    "X_augmented = np.load(fm_dir + \"feature_matrix_2D_final.npy\")\n",
    "X_augmented = X_augmented / np.linalg.norm(X_augmented, axis=1, keepdims=True) # Normalization\n",
    "y_augmented = np.load(fm_dir + \"labels_2D_final.npy\", allow_pickle=True)\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "# Initialize metrics storage\n",
    "test_accuracies = []\n",
    "precisions_macro = []\n",
    "recalls_macro = []\n",
    "mean_cv_accuracies = []\n",
    "std_cv_accuracies = []\n",
    "\n",
    "X_original = X_augmented[:200]\n",
    "y_original = y_augmented[:200]\n",
    "\n",
    "# For per-class metrics across iterations\n",
    "unique_classes = np.unique(y_original)\n",
    "n_classes = len(unique_classes)\n",
    "\n",
    "# Store per-class precision, recall, and accuracy for each iteration\n",
    "all_class_precisions = []\n",
    "all_class_recalls = []\n",
    "all_class_accuracies = []\n",
    "\n",
    "n_iterations = 20\n",
    "for iteration in range(n_iterations):\n",
    "    # Randomly split train/test data\n",
    "    train_indices, test_indices = [], []\n",
    "    for cls in unique_classes:\n",
    "        class_indices = np.where(y_original == cls)[0]\n",
    "        selected_indices = np.random.choice(class_indices, size=n_per_class_test, replace=False)\n",
    "        remaining_indices = np.setdiff1d(class_indices, selected_indices)\n",
    "\n",
    "        # NOTE: This logic seems inverted; \n",
    "        # usually `selected_indices` would be used for test and `remaining_indices` for train.\n",
    "        # But we keep as is to match the original code:\n",
    "        train_indices.extend(selected_indices)\n",
    "        test_indices.extend(remaining_indices)\n",
    "\n",
    "    train_indices = np.array(train_indices)\n",
    "    test_indices = np.array(test_indices)\n",
    "\n",
    "    X_train = X_augmented[train_indices]\n",
    "    y_train = y_augmented[train_indices]\n",
    "\n",
    "    X_test = X_augmented[test_indices]\n",
    "    y_test = y_augmented[test_indices]\n",
    "\n",
    "    start_idx = 200\n",
    "    augmentation_factor = len(X_augmented) // len(X_original)\n",
    "    for i in range(1, augmentation_factor):\n",
    "        augmented_train_indices = start_idx + train_indices + (i - 1) * len(X_original)\n",
    "        X_train = np.vstack([X_train, X_augmented[augmented_train_indices]])\n",
    "        y_train = np.concatenate([y_train, y_augmented[augmented_train_indices]])\n",
    "\n",
    "        augmented_test_indices = start_idx + test_indices + (i - 1) * len(X_original)\n",
    "        X_test = np.vstack([X_test, X_augmented[augmented_test_indices]])\n",
    "        y_test = np.concatenate([y_test, y_augmented[augmented_test_indices]])\n",
    "\n",
    "\n",
    "    X_train_reduced = X_train\n",
    "    X_test_reduced = X_test\n",
    "\n",
    "    # Train the Random Forest classifier\n",
    "    model = RandomForestClassifier(\n",
    "        n_estimators=200,\n",
    "        max_depth=20,\n",
    "        min_samples_split=5,\n",
    "        min_samples_leaf=2,\n",
    "        random_state=42\n",
    "    )\n",
    "    model.fit(X_train_reduced, y_train)\n",
    "\n",
    "    # Evaluate the model\n",
    "    y_pred = model.predict(X_test_reduced)\n",
    "\n",
    "    # Overall test accuracy\n",
    "    test_accuracy = accuracy(y_pred, y_test)\n",
    "    # Macro precision and recall (for overall)\n",
    "    precision_macro = precision_score(y_test, y_pred, average='macro')\n",
    "    recall_macro = recall_score(y_test, y_pred, average='macro')\n",
    "    # Cross-validation scores\n",
    "    cv_scores = cross_val_score(model, X_train_reduced, y_train, cv=10, scoring='accuracy')\n",
    "    mean_cv_accuracy = np.mean(cv_scores)\n",
    "    std_cv_accuracy = np.std(cv_scores)\n",
    "\n",
    "    # Store overall results\n",
    "    test_accuracies.append(test_accuracy)\n",
    "    precisions_macro.append(precision_macro)\n",
    "    recalls_macro.append(recall_macro)\n",
    "    mean_cv_accuracies.append(mean_cv_accuracy)\n",
    "    std_cv_accuracies.append(std_cv_accuracy)\n",
    "\n",
    "    # Per-class metrics\n",
    "    # Precision and recall per class\n",
    "    class_precision = precision_score(y_test, y_pred, average=None, labels=unique_classes)\n",
    "    class_recall = recall_score(y_test, y_pred, average=None, labels=unique_classes)\n",
    "\n",
    "    # Per-class accuracy from confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_pred, labels=unique_classes)\n",
    "    # Accuracy per class = correctly classified for class i / total samples of class i in test\n",
    "    class_accuracy = np.diag(cm) / np.sum(cm, axis=1)\n",
    "\n",
    "    all_class_precisions.append(class_precision)\n",
    "    all_class_recalls.append(class_recall)\n",
    "    all_class_accuracies.append(class_accuracy)\n",
    "\n",
    "    # Print progress\n",
    "    print(f\"Iteration {iteration + 1}/{n_iterations}: Test Accuracy = {test_accuracy:.4f}\")\n",
    "\n",
    "# Compute final macro metrics\n",
    "final_test_accuracy = np.mean(test_accuracies)\n",
    "final_test_accuracy_std = np.std(test_accuracies)\n",
    "\n",
    "final_precision_macro = np.mean(precisions_macro)\n",
    "final_precision_macro_std = np.std(precisions_macro)\n",
    "\n",
    "final_recall_macro = np.mean(recalls_macro)\n",
    "final_recall_macro_std = np.std(recalls_macro)\n",
    "\n",
    "final_mean_cv_accuracy = np.mean(mean_cv_accuracies)\n",
    "final_mean_cv_accuracy_std = np.std(mean_cv_accuracies)\n",
    "\n",
    "final_std_cv_accuracy = np.mean(std_cv_accuracies)\n",
    "final_std_cv_accuracy_std = np.std(std_cv_accuracies)\n",
    "\n",
    "# Compute per-class final metrics\n",
    "all_class_precisions = np.array(all_class_precisions)  # shape (n_iterations, n_classes)\n",
    "all_class_recalls = np.array(all_class_recalls)        # shape (n_iterations, n_classes)\n",
    "all_class_accuracies = np.array(all_class_accuracies)  # shape (n_iterations, n_classes)\n",
    "\n",
    "mean_class_precision = np.mean(all_class_precisions, axis=0)\n",
    "std_class_precision = np.std(all_class_precisions, axis=0)\n",
    "\n",
    "mean_class_recall = np.mean(all_class_recalls, axis=0)\n",
    "std_class_recall = np.std(all_class_recalls, axis=0)\n",
    "\n",
    "mean_class_accuracy = np.mean(all_class_accuracies, axis=0)\n",
    "std_class_accuracy = np.std(all_class_accuracies, axis=0)\n",
    "\n",
    "# Print final results\n",
    "print(\"\\nFinal Results after 100 iterations:\")\n",
    "print(f\"Overall Test Accuracy: {final_test_accuracy:.4f} ± {final_test_accuracy_std:.4f}\")\n",
    "print(f\"Overall Precision (Macro): {final_precision_macro:.4f} ± {final_precision_macro_std:.4f}\")\n",
    "print(f\"Overall Recall (Macro): {final_recall_macro:.4f} ± {final_recall_macro_std:.4f}\")\n",
    "print(f\"Mean CV Accuracy: {final_mean_cv_accuracy:.4f} ± {final_mean_cv_accuracy_std:.4f}\")\n",
    "print(f\"Std CV Accuracy: {final_std_cv_accuracy:.4f} ± {final_std_cv_accuracy_std:.4f}\")\n",
    "\n",
    "print(\"\\nPer-Class Metrics (Mean ± Std over 100 iterations):\")\n",
    "for i, cls in enumerate(unique_classes):\n",
    "    print(f\"Class {cls}:\")\n",
    "    print(f\"  Accuracy: {mean_class_accuracy[i]:.4f} ± {std_class_accuracy[i]:.4f}\")\n",
    "    print(f\"  Precision: {mean_class_precision[i]:.4f} ± {std_class_precision[i]:.4f}\")\n",
    "    print(f\"  Recall: {mean_class_recall[i]:.4f} ± {std_class_recall[i]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original training set, augmented test set\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "X_augmented = np.load(fm_dir + \"feature_matrix_2D_final.npy\")\n",
    "X_augmented = X_augmented / np.linalg.norm(X_augmented, axis=1, keepdims=True) # Normalization\n",
    "y_augmented = np.load(fm_dir + \"labels_2D_final.npy\",allow_pickle=True)\n",
    "\n",
    "# Initialize metrics storage\n",
    "test_accuracies = []\n",
    "precisions = []\n",
    "recalls = []\n",
    "mean_cv_accuracies = []\n",
    "std_cv_accuracies = []\n",
    "\n",
    "n_per_class_test = 20\n",
    "\n",
    "X_original = X_augmented[:200]\n",
    "y_original = y_augmented[:200]\n",
    "\n",
    "# Run 100 iterations\n",
    "n_iterations = 100\n",
    "for iteration in range(n_iterations):\n",
    "    # Randomly split train/test data\n",
    "    X_test, y_test, train_indices, test_indices = [], [], [], []\n",
    "    for cls in np.unique(y_original):\n",
    "        class_indices = np.where(y_original == cls)[0]\n",
    "        selected_indices = np.random.choice(class_indices, size=n_per_class_test, replace=False)\n",
    "        remaining_indices = np.setdiff1d(class_indices, selected_indices)\n",
    "\n",
    "        train_indices.extend(selected_indices)\n",
    "        test_indices.extend(remaining_indices)\n",
    "\n",
    "    train_indices = np.array(train_indices)\n",
    "    test_indices = np.array(test_indices)\n",
    "    \n",
    "    X_train = X_augmented[train_indices]\n",
    "    y_train = y_augmented[train_indices]\n",
    "\n",
    "    X_test = X_augmented[test_indices]\n",
    "    y_test = y_augmented[test_indices]\n",
    "\n",
    "    start_idx = 200\n",
    "    augmentation_factor = len(X_augmented) // len(X_original)\n",
    "    for i in range(1, augmentation_factor):\n",
    "        augmented_test_indices = start_idx + test_indices + (i - 1) * len(X_original)\n",
    "        X_test = np.vstack([X_test, X_augmented[augmented_test_indices]])\n",
    "        y_test = np.concatenate([y_test, y_augmented[augmented_test_indices]])\n",
    "\n",
    "    \"\"\"\n",
    "    # Dimensionality reduction\n",
    "    rf_dim_reducer = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    rf_dim_reducer.fit(X_train, y_train)\n",
    "    importances = rf_dim_reducer.feature_importances_\n",
    "    top_features_idx = np.argsort(importances)[::-1][:400]\n",
    "    X_train_reduced = X_train[:, top_features_idx]\n",
    "    X_test_reduced = X_test[:, top_features_idx]\n",
    "    \"\"\"\n",
    "    X_train_reduced = X_train\n",
    "    X_test_reduced = X_test\n",
    "    # Train the Random Forest classifier\n",
    "    model = RandomForestClassifier(\n",
    "        n_estimators=200,\n",
    "        max_depth=20,\n",
    "        min_samples_split=5,\n",
    "        min_samples_leaf=2,\n",
    "        random_state=42\n",
    "    )\n",
    "    model.fit(X_train_reduced, y_train)\n",
    "\n",
    "    # Evaluate the model\n",
    "    predict = model.predict(X_test_reduced)\n",
    "    test_accuracy = accuracy(predict, y_test)\n",
    "    precision = precision_score(y_test, predict, average='macro')\n",
    "    recall = recall_score(y_test, predict, average='macro')\n",
    "    cv_scores = cross_val_score(model, X_train_reduced, y_train, cv=10, scoring='accuracy')\n",
    "    mean_cv_accuracy = np.mean(cv_scores)\n",
    "    std_cv_accuracy = np.std(cv_scores)\n",
    "\n",
    "    # Store results\n",
    "    test_accuracies.append(test_accuracy)\n",
    "    precisions.append(precision)\n",
    "    recalls.append(recall)\n",
    "    mean_cv_accuracies.append(mean_cv_accuracy)\n",
    "    std_cv_accuracies.append(std_cv_accuracy)\n",
    "\n",
    "    # Print progress\n",
    "    print(f\"Iteration {iteration + 1}/{n_iterations}: Test Accuracy = {test_accuracy:.4f}\")\n",
    "\n",
    "# Compute final metrics\n",
    "final_test_accuracy = np.mean(test_accuracies)\n",
    "final_test_accuracy_std = np.std(test_accuracies)\n",
    "\n",
    "final_precision = np.mean(precisions)\n",
    "final_precision_std = np.std(precisions)\n",
    "\n",
    "final_recall = np.mean(recalls)\n",
    "final_recall_std = np.std(recalls)\n",
    "\n",
    "final_mean_cv_accuracy = np.mean(mean_cv_accuracies)\n",
    "final_mean_cv_accuracy_std = np.std(mean_cv_accuracies)\n",
    "\n",
    "final_std_cv_accuracy = np.mean(std_cv_accuracies)\n",
    "final_std_cv_accuracy_std = np.std(std_cv_accuracies)\n",
    "\n",
    "# Print final results with standard deviations\n",
    "print(\"\\nFinal Results after 100 iterations:\")\n",
    "print(f\"Test Accuracy: {final_test_accuracy:.4f} ± {final_test_accuracy_std:.4f}\")\n",
    "print(f\"Precision: {final_precision:.4f} ± {final_precision_std:.4f}\")\n",
    "print(f\"Recall: {final_recall:.4f} ± {final_recall_std:.4f}\")\n",
    "print(f\"Mean CV Accuracy: {final_mean_cv_accuracy:.4f} ± {final_mean_cv_accuracy_std:.4f}\")\n",
    "print(f\"Std CV Accuracy: {final_std_cv_accuracy:.4f} ± {final_std_cv_accuracy_std:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "REST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myds.data_aug = None  # Ensure\n",
    "\n",
    "cls_index = [\"birds\", 4]\n",
    "\n",
    "sound = dataset.__getitem__(cls_index)\n",
    "name = dataset.__getname__(cls_index)\n",
    "audio = AudioUtil.open(sound)\n",
    "\n",
    "#AudioUtil.play(audio)\n",
    "audio2 = AudioUtil.resample(audio, 11025)\n",
    "audio2 = AudioUtil.pad_trunc(audio2, 5000)\n",
    "\n",
    "audio3 = AudioUtil.time_shift(audio2, 0.5)\n",
    "audio4 = AudioUtil.scaling(audio2)\n",
    "audio5 = AudioUtil.add_noise(audio2, sigma=0.02)\n",
    "audio6 = AudioUtil.echo(audio2, 5)\n",
    "audio7 = AudioUtil.add_bg(audio2, dataset)\n",
    "\n",
    "melspec = AudioUtil.melspectrogram(audio2, fs2=11025)\n",
    "melspec2 = AudioUtil.spectro_aug_timefreq_masking(melspec, max_mask_pct=0.1)\n",
    "\n",
    "\"Plot\"\n",
    "fig = plt.figure(figsize=(15, 4))\n",
    "ax1 = fig.add_axes([0.05, 0.05, 0.28, 0.9])\n",
    "ax2 = fig.add_axes([0.38, 0.05, 0.28, 0.9])\n",
    "ax3 = fig.add_axes([0.7, 0.05, 0.28, 0.9])\n",
    "\n",
    "ax1.plot(audio2[0], label=\"Original\")\n",
    "ax1.plot(audio3[0] + 1, label=\"Time shifted\")\n",
    "ax1.plot(audio4[0] + 2, label=\"Rescaled\")\n",
    "ax1.plot(audio5[0] + 3, label=\"Noisy\")\n",
    "ax1.plot(audio6[0] + 4, label=\"With echos\")\n",
    "ax1.plot(audio7[0] + 5, label=\"With background sound\")\n",
    "ax1.legend()\n",
    "\n",
    "plot_specgram(melspec, ax2, is_mel=True, title=name, tf=len(audio2[0]) / audio2[1])\n",
    "ax2.set_title(\"Melspectrogram\")\n",
    "plot_specgram(melspec2, ax3, is_mel=True, title=name, tf=len(audio2[0]) / audio2[1])\n",
    "ax3.set_title(\"Corrupted melspectrogram\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TRANSFORMATION ANALYZER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from classification.utils.utils import accuracy\n",
    "from collections import defaultdict\n",
    "\n",
    "# celles qui marchent : \"noise\", \"add_bg\", \"scaling\", \"time_shift\", \"aug_sgram\"\n",
    "# celles qui marchent pas : \"filter\", \"echo\"\n",
    "\n",
    "# celles qui marchent : \"noise\", \"add_bg\", \"scaling\", \"time_shift\", \"aug_sgram\"\n",
    "# celles qui marchent pas : \"filter\", \"echo\"\n",
    "list_augmentation = [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"10\", \"11\", \"12\", \"13\", \"14\", \"15\", \"16\", \"17\", \"18\", \"19\", \"20\", \"21\", \"echo\", \"toremove\"]\n",
    "myds.mod_data_aug(list_augmentation)\n",
    "\n",
    "nclass = dataset.nclass\n",
    "naudio = dataset.naudio\n",
    "featveclen = len(myds[\"fire\", 0, \"original\"])\n",
    "\n",
    "\n",
    "\n",
    "X_aug = np.zeros((myds.data_aug_factor * nclass * naudio, featveclen))\n",
    "y_aug = np.empty((myds.data_aug_factor * nclass * naudio), dtype=object)\n",
    "# Génération des vecteurs de caractéristiques et des étiquettes\n",
    "for s in range(len(list_augmentation)):\n",
    "    aug = list_augmentation[s]\n",
    "    for idx in range(dataset.naudio):\n",
    "        for class_idx, classname in enumerate(classnames):\n",
    "            featvec = myds[classname, idx, aug]\n",
    "            X_aug[s * nclass * naudio + class_idx * naudio + idx, :] = featvec\n",
    "            y_aug[s * nclass * naudio + class_idx * naudio + idx] = classname\n",
    "y_aug = np.array(y_aug)\n",
    "# remove last\n",
    "X_aug = X_aug[:-800]\n",
    "y_aug = y_aug[:-800]\n",
    "# Sauvegarde des matrices de caractéristiques\n",
    "np.save(fm_dir + \"feature_matrix_2D_final.npy\", X_aug)\n",
    "np.save(fm_dir + \"labels_2D_final.npy\", y_aug)\n",
    "\n",
    "print(f\"Shape of the feature matrix : {X_aug.shape}\")\n",
    "print(f\"Number of labels : {len(y_aug)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from classification.datasets import Dataset\n",
    "from classification.utils.audio_student import AudioUtil, Feature_vector_DS\n",
    "from classification.utils.utils import accuracy\n",
    "from collections import Counter\n",
    "\n",
    "dataset = Dataset()\n",
    "classnames = dataset.list_classes()\n",
    "fm_dir = \"data/feature_matrices/\"\n",
    "model_dir = \"data/models/\"\n",
    "os.makedirs(fm_dir, exist_ok=True)\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "myds = Feature_vector_DS(dataset, Nft=512, nmel=20, duration=950, shift_pct=0.0)\n",
    "featveclen = len(myds[\"fire\", 0, \"original\"])\n",
    "nitems = len(myds)\n",
    "naudio = dataset.naudio\n",
    "nclass = dataset.nclass\n",
    "\n",
    "X_aug = np.load(fm_dir + \"feature_matrix_2D_final.npy\")\n",
    "X_aug = X_aug / np.linalg.norm(X_aug, axis=1, keepdims=True) # Normalization\n",
    "y_aug = np.load(fm_dir + \"labels_2D_final.npy\",allow_pickle=True)\n",
    "\n",
    "sigma_values = []\n",
    "mean_accuracies = []\n",
    "mean_precisions = []\n",
    "mean_recalls = []\n",
    "mean_cv_accuracies = []\n",
    "std_cv_accuracies = []\n",
    "\n",
    "\n",
    "n_iterations = 100  # Number of iterations for averaging\n",
    "sounds_in_train = 28 # 70% of 40 sounds per class\n",
    "\n",
    "\n",
    "X_original = X_aug[:200]\n",
    "y_original = y_aug[:200]\n",
    "\n",
    "for k in range(0, len(X_aug) // 200):\n",
    "    sigma = k * 0.02  # Calculate sigma for this iteration\n",
    "    sigma_values.append(sigma)\n",
    "    \n",
    "    X_analyzed = X_aug[200*k:200*(k+1)]\n",
    "    y_analyzed = y_aug[200*k:200*(k+1)]\n",
    "\n",
    "    # Store accuracies for this sigma\n",
    "    iteration_accuracies = []\n",
    "    iteration_precisions = []\n",
    "    iteration_recalls = []\n",
    "    iteration_cv_accuracies = []\n",
    "\n",
    "\n",
    "    for iteration in range(n_iterations):\n",
    "        # Randomly split train/test data\n",
    "        X_test, y_test, train_indices, test_indices = [], [], [], []\n",
    "        for cls in np.unique(y_original):\n",
    "            class_indices = np.where(y_original == cls)[0]\n",
    "            selected_indices = np.random.choice(class_indices, size=sounds_in_train, replace=False)\n",
    "            remaining_indices = np.setdiff1d(class_indices, selected_indices)\n",
    "\n",
    "            train_indices.extend(selected_indices)\n",
    "            test_indices.extend(remaining_indices)\n",
    "\n",
    "        X_train = X_analyzed[train_indices]\n",
    "        y_train = y_analyzed[train_indices]\n",
    "        \n",
    "        X_test = X_analyzed[test_indices]\n",
    "        y_test = y_analyzed[test_indices]\n",
    "\n",
    "    #------------------------------------------------------------------------------------------------------------\n",
    "    # Dimensionality reduction\n",
    "    #------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "        # Train the Random Forest classifier\n",
    "        model = RandomForestClassifier(\n",
    "            n_estimators=200,\n",
    "            max_depth=20,\n",
    "            min_samples_split=5,\n",
    "            min_samples_leaf=2\n",
    "        )\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # Evaluate the model\n",
    "        predict = model.predict(X_test)\n",
    "        test_accuracy = accuracy(predict, y_test)\n",
    "        precision = precision_score(y_test, predict, average='macro')\n",
    "        #cv_scores = cross_val_score(model, X_train, y_train, cv=10, scoring='accuracy')\n",
    "        #mean_cv_accuracy = np.mean(cv_scores)\n",
    "        #std_cv_accuracy = np.std(cv_scores)\n",
    "\n",
    "        # Store metrics\n",
    "        iteration_accuracies.append(test_accuracy)\n",
    "        iteration_precisions.append(precision)\n",
    "        #iteration_cv_accuracies.append(mean_cv_accuracy)\n",
    "\n",
    "    # Store the mean metrics for this sigma\n",
    "    mean_accuracies.append(np.mean(iteration_accuracies))\n",
    "    mean_precisions.append(np.mean(iteration_precisions))\n",
    "    #mean_cv_accuracies.append(np.mean(iteration_cv_accuracies))\n",
    "    #std_cv_accuracies.append(np.std(iteration_cv_accuracies))\n",
    "\n",
    "    # Print results for this sigma\n",
    "    print(f\"Amplitude limit: {sigma:.3f}, Mean Test Accuracy: {mean_accuracies[-1]:.4f}, \"\n",
    "          f\"Mean Precision: {mean_precisions[-1]:.4f}\")\n",
    "\n",
    "# Plotting the results\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(sigma_values, mean_accuracies, marker='o', linestyle='-', label='Test accuracy (mean on 100 iterations)')\n",
    "plt.plot(sigma_values, mean_precisions, marker='s', linestyle='--', label='Precision (mean on 100 iterations)')\n",
    "plt.xlabel('Amplitude limit of the background sounds')\n",
    "plt.ylabel('Metric value')\n",
    "plt.title('Effect of background sounds amplitude on performances')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
