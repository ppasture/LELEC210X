{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\"Machine learning tools\"\n",
    "import pickle\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "\n",
    "\n",
    "from classification.datasets import Dataset\n",
    "from classification.utils.audio_student import AudioUtil, Feature_vector_DS\n",
    "\n",
    "from classification.utils.plots import (\n",
    "    plot_decision_boundaries,\n",
    "    plot_specgram,\n",
    "    show_confusion_matrix,\n",
    ")\n",
    "from classification.utils.utils import accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chainsaw\n",
      "fire\n",
      "fireworks\n",
      "gunshot\n"
     ]
    }
   ],
   "source": [
    "### TO RUN\n",
    "dataset = Dataset()\n",
    "classnames = dataset.list_classes()\n",
    "\n",
    "print(\"\\n\".join(classnames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TO RUN\n",
    "fm_dir = \"data/feature_matrices/\"  # where to save the features matrices\n",
    "new_dataset_dir = \"src/classification/datasets/new_dataset/melvecs/\"\n",
    "model_dir = \"data/models/cnn\"  # where to save the models\n",
    "os.makedirs(fm_dir, exist_ok=True)\n",
    "os.makedirs(model_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TO RUN\n",
    "\n",
    "\"Creation of the dataset\"\n",
    "myds = Feature_vector_DS(dataset, Nft=512, nmel=20, duration=950, shift_pct=0.0)\n",
    "\n",
    "\"Some attributes...\"\n",
    "myds.nmel\n",
    "myds.duration\n",
    "myds.shift_pct\n",
    "myds.sr\n",
    "myds.data_aug\n",
    "myds.ncol\n",
    "\n",
    "idx = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the basic feature matrix : (268, 400)\n",
      "Number of labels : (268,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "train_pct = 0.7\n",
    "data_aug_factor = 1\n",
    "featveclen = len(myds[\"fire\", 0, \"\", \"\"])  # Same for all classes\n",
    "classnames = [\"chainsaw\", \"fire\", \"fireworks\", \"gunshot\"]  # Or wherever you store class names\n",
    "nclass = len(classnames)\n",
    "\n",
    "# Determine number of samples per class\n",
    "naudio_per_class = {\"chainsaw\" : 76, \"fire\" : 76, \"fireworks\" : 76, \"gunshot\" : 40}\n",
    "\n",
    "\n",
    "# Allocate feature matrix\n",
    "total_samples_basic = sum(naudio_per_class[c] for c in classnames)\n",
    "X_basic = np.zeros((total_samples_basic, featveclen))\n",
    "y_basic = np.zeros((total_samples_basic), dtype=object)\n",
    "total_samples_basic\n",
    "# Fill feature matrix\n",
    "idx = 0\n",
    "for class_idx, classname in enumerate(classnames):\n",
    "    for i in range(naudio_per_class[classname]):\n",
    "        featvec = myds[classname, i, \"\", \"\"]\n",
    "        X_basic[idx, :] = featvec\n",
    "        y_basic[idx] = classname\n",
    "        idx += 1\n",
    "\n",
    "# Save features and labels\n",
    "np.save(fm_dir + \"X_basic.npy\", X_basic)\n",
    "np.save(fm_dir + \"y_basic.npy\", y_basic)\n",
    "\n",
    "print(f\"Shape of the basic feature matrix : {X_basic.shape}\")\n",
    "print(f\"Number of labels : {y_basic.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now create a new augmented dataset and observe if the classification results improve. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of transformations :  3\n",
      "Shape of the feature matrix : (804, 400)\n",
      "Number of labels : (804,)\n",
      "------------------------------------------------------------\n",
      "Transformations: ['original', 'noise', 'shifting']. Labels aligned dynamically with class sizes.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "### AUGMENTED DATASET\n",
    "list_augmentation = [\"original\", \"noise\", \"shifting\"]\n",
    "myds.mod_data_aug(list_augmentation)\n",
    "print(\"Number of transformations : \", myds.data_aug_factor)\n",
    "\n",
    "\n",
    "# Calcul total des échantillons\n",
    "total_aug_samples = sum(naudio_per_class[c] for c in classnames) * len(list_augmentation)\n",
    "X_basic_aug = np.zeros((total_aug_samples, featveclen))\n",
    "y_basic_aug = np.zeros((total_aug_samples), dtype=object)\n",
    "\n",
    "# Remplissage des features\n",
    "idx = 0\n",
    "for aug in list_augmentation:\n",
    "    for classname in classnames:\n",
    "        for i in range(naudio_per_class[classname]):\n",
    "            featvec = myds[classname, i, aug, \"\"]\n",
    "            X_basic_aug[idx, :] = featvec\n",
    "            y_basic_aug[idx] = classname\n",
    "            idx += 1\n",
    "\n",
    "# Sauvegarde\n",
    "np.save(fm_dir + \"X_basic_aug.npy\", X_basic_aug)\n",
    "np.save(fm_dir + \"y_basic_aug.npy\", y_basic_aug)\n",
    "\n",
    "print(f\"Shape of the feature matrix : {X_basic_aug.shape}\")\n",
    "print(f\"Number of labels : {y_basic_aug.shape}\")\n",
    "print(f\"------------------------------------------------------------\")\n",
    "print(f\"Transformations: {list_augmentation}. Labels aligned dynamically with class sizes.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "RUN = False\n",
    "\n",
    "if RUN:\n",
    "    import os\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "    from classification.utils.plots import plot_specgram_textlabel\n",
    "\n",
    "    # Charger les données\n",
    "    X = np.load(os.path.join(fm_dir, \"X_basic_aug.npy\"), allow_pickle=True)\n",
    "    y = np.load(os.path.join(fm_dir, \"y_basic_aug.npy\"), allow_pickle=True)\n",
    "\n",
    "    # Dossier où sauvegarder les images\n",
    "    save_dir = os.path.join(\"src/classification/soundfiles_melspec_augmentation\")\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "    # Nombre d'exemples de base (avant augmentation)\n",
    "    length_X_basic = int(len(X) / len(list_augmentation))\n",
    "\n",
    "    # Boucle de sauvegarde\n",
    "    for i in range(length_X_basic):\n",
    "        for j, aug_name in enumerate(list_augmentation):\n",
    "            idx = i + j * length_X_basic\n",
    "            melspec = X[idx]\n",
    "            class_of_spec = y[idx]\n",
    "\n",
    "            fig, ax = plt.subplots()\n",
    "            plot_specgram_textlabel(\n",
    "                melspec.reshape((20, 20)),\n",
    "                ax=ax,\n",
    "                is_mel=True,\n",
    "                title=f\"MEL Spectrogram #{i} - {aug_name}\",\n",
    "                xlabel=\"Mel vector\",\n",
    "                textlabel=f\"{class_of_spec} (aug: {aug_name})\",\n",
    "            )\n",
    "            plt.tight_layout()\n",
    "            save_path = os.path.join(save_dir, f\"melspec_{i}_{aug_name}.png\")\n",
    "            fig.savefig(save_path)\n",
    "            plt.close(fig)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FINAL MODEL SAVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-14 14:55:16.135761: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-04-14 14:55:16.142262: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-04-14 14:55:16.183204: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-04-14 14:55:16.221662: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1744635316.268964   31564 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1744635316.289175   31564 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1744635316.407980   31564 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1744635316.408058   31564 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1744635316.408063   31564 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1744635316.408065   31564 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-04-14 14:55:16.436220: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The number of filters must be evenly divisible by the number of groups. Received: groups=1, filters=21.56.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 94\u001b[0m\n\u001b[1;32m     92\u001b[0m     X_train_cnn \u001b[38;5;241m=\u001b[39m reshape_for_cnn(X_train)\n\u001b[1;32m     93\u001b[0m     X_test_cnn \u001b[38;5;241m=\u001b[39m reshape_for_cnn(X_test)\n\u001b[0;32m---> 94\u001b[0m     model_B \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_and_save_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_cnn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcnn_nopca_noaug_nonorm\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test_cnn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m D:\n\u001b[1;32m     97\u001b[0m     X_train_aug_cnn \u001b[38;5;241m=\u001b[39m reshape_for_cnn(X_train_aug)\n",
      "Cell \u001b[0;32mIn[9], line 75\u001b[0m, in \u001b[0;36mtrain_and_save_model\u001b[0;34m(X_train, y_train, filename, X_val, y_val)\u001b[0m\n\u001b[1;32m     72\u001b[0m y_train_cat \u001b[38;5;241m=\u001b[39m to_categorical(y_train, num_classes\u001b[38;5;241m=\u001b[39mn_classes)\n\u001b[1;32m     73\u001b[0m y_val_cat \u001b[38;5;241m=\u001b[39m to_categorical(y_val, num_classes\u001b[38;5;241m=\u001b[39mn_classes) \u001b[38;5;28;01mif\u001b[39;00m y_val \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m---> 75\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mbuild_cnn\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_classes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     76\u001b[0m es \u001b[38;5;241m=\u001b[39m EarlyStopping(patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, restore_best_weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     78\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(X_train, y_train_cat, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m,\n\u001b[1;32m     79\u001b[0m           validation_data\u001b[38;5;241m=\u001b[39m(X_val, y_val_cat) \u001b[38;5;28;01mif\u001b[39;00m y_val \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     80\u001b[0m           callbacks\u001b[38;5;241m=\u001b[39m[es], verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "Cell \u001b[0;32mIn[9], line 56\u001b[0m, in \u001b[0;36mbuild_cnn\u001b[0;34m(input_shape, n_classes)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbuild_cnn\u001b[39m(input_shape, n_classes):\n\u001b[1;32m     54\u001b[0m     model \u001b[38;5;241m=\u001b[39m Sequential([\n\u001b[1;32m     55\u001b[0m         Input(shape\u001b[38;5;241m=\u001b[39minput_shape),\n\u001b[0;32m---> 56\u001b[0m         \u001b[43mConv2D\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconv_filters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactivation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrelu\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m,\n\u001b[1;32m     57\u001b[0m         BatchNormalization(),\n\u001b[1;32m     58\u001b[0m         MaxPooling2D(\u001b[38;5;241m2\u001b[39m),\n\u001b[1;32m     59\u001b[0m         Conv2D(conv_filters \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m, (\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m3\u001b[39m), activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[1;32m     60\u001b[0m         BatchNormalization(),\n\u001b[1;32m     61\u001b[0m         MaxPooling2D(\u001b[38;5;241m2\u001b[39m),\n\u001b[1;32m     62\u001b[0m         Flatten(),\n\u001b[1;32m     63\u001b[0m         Dense(dense_units, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[1;32m     64\u001b[0m         Dropout(dropout_rate),\n\u001b[1;32m     65\u001b[0m         Dense(n_classes, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msoftmax\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     66\u001b[0m     ])\n\u001b[1;32m     67\u001b[0m     model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m, loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "File \u001b[0;32m~/master_projet_elec/LELEC210X/.venv/lib/python3.9/site-packages/keras/src/layers/convolutional/conv2d.py:118\u001b[0m, in \u001b[0;36mConv2D.__init__\u001b[0;34m(self, filters, kernel_size, strides, padding, data_format, dilation_rate, groups, activation, use_bias, kernel_initializer, bias_initializer, kernel_regularizer, bias_regularizer, activity_regularizer, kernel_constraint, bias_constraint, **kwargs)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m     99\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    100\u001b[0m     filters,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    117\u001b[0m ):\n\u001b[0;32m--> 118\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    119\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrank\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    120\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    121\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkernel_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkernel_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    122\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstrides\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstrides\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    123\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpadding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    124\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    125\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdilation_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdilation_rate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    126\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgroups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    127\u001b[0m \u001b[43m        \u001b[49m\u001b[43mactivation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mactivation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    128\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_bias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    129\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkernel_initializer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkernel_initializer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    130\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbias_initializer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbias_initializer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    131\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkernel_regularizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkernel_regularizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    132\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbias_regularizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbias_regularizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    133\u001b[0m \u001b[43m        \u001b[49m\u001b[43mactivity_regularizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mactivity_regularizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    134\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkernel_constraint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkernel_constraint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    135\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbias_constraint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbias_constraint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    136\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    137\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/master_projet_elec/LELEC210X/.venv/lib/python3.9/site-packages/keras/src/layers/convolutional/base_conv.py:144\u001b[0m, in \u001b[0;36mBaseConv.__init__\u001b[0;34m(self, rank, filters, kernel_size, strides, padding, data_format, dilation_rate, groups, activation, use_bias, kernel_initializer, bias_initializer, kernel_regularizer, bias_regularizer, activity_regularizer, kernel_constraint, bias_constraint, lora_rank, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    139\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe number of groups must be a positive integer. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    140\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReceived: groups=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    141\u001b[0m     )\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilters \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilters \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 144\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    145\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe number of filters must be evenly divisible by the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    146\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumber of groups. Received: groups=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    147\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfilters=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilters\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    148\u001b[0m     )\n\u001b[1;32m    150\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkernel_size):\n\u001b[1;32m    151\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    152\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe argument `kernel_size` cannot contain 0. Received \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    153\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkernel_size=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkernel_size\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    154\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: The number of filters must be evenly divisible by the number of groups. Received: groups=1, filters=21.56."
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization, Input\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# ========== PARAMETERS ==========\n",
    "conv_filters = 22 \n",
    "dense_units = 228\n",
    "dropout_rate = 0.3401\n",
    "\n",
    "TEST_SET = True\n",
    "A = True  # PCA NOAUG NONORM (Ignored for CNN)\n",
    "B = True  # NOPCA NOAUG NONORM\n",
    "C = True  # PCA AUG NONORM (Ignored for CNN)\n",
    "D = True  # NOPCA AUG NONORM\n",
    "E = True  # NOPCA NOAUG NONORM\n",
    "F = True  # PCA NOAUG NORM (Ignored for CNN)\n",
    "G = True  # PCA AUG NORM (Ignored for CNN)\n",
    "H = True  # NOPCA AUG NORM\n",
    "\n",
    "# ========== LOAD DATA ==========\n",
    "X_basic_aug = np.load(os.path.join(fm_dir, \"X_basic_aug.npy\"))\n",
    "y_basic_aug = np.load(os.path.join(fm_dir, \"y_basic_aug.npy\"), allow_pickle=True)\n",
    "X_basic = np.load(os.path.join(fm_dir, \"X_basic.npy\"))\n",
    "y_basic = np.load(os.path.join(fm_dir, \"y_basic.npy\"), allow_pickle=True)\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y_basic = label_encoder.fit_transform(y_basic)\n",
    "y_basic_aug = label_encoder.transform(y_basic_aug)\n",
    "n_classes = len(np.unique(y_basic))\n",
    "\n",
    "if TEST_SET:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_basic, y_basic, test_size=0.3, random_state=42)\n",
    "    X_train_aug, X_test_aug, y_train_aug, y_test_aug = train_test_split(X_basic_aug, y_basic_aug, test_size=0.3, random_state=42)\n",
    "else:\n",
    "    X_train, y_train = X_basic, y_basic\n",
    "    X_train_aug, y_train_aug = X_basic_aug, y_basic_aug\n",
    "\n",
    "# ========== HELPERS ==========\n",
    "def reshape_for_cnn(X):\n",
    "    if len(X.shape) == 2:\n",
    "        side = int(np.sqrt(X.shape[1]))\n",
    "        return X.reshape((-1, side, side, 1))\n",
    "    return X\n",
    "\n",
    "def build_cnn(input_shape, n_classes):\n",
    "    model = Sequential([\n",
    "        Input(shape=input_shape),\n",
    "        Conv2D(conv_filters, (3, 3), activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D(2),\n",
    "        Conv2D(conv_filters * 2, (3, 3), activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D(2),\n",
    "        Flatten(),\n",
    "        Dense(dense_units, activation='relu'),\n",
    "        Dropout(dropout_rate),\n",
    "        Dense(n_classes, activation='softmax')\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def train_and_save_model(X_train, y_train, filename, X_val=None, y_val=None):\n",
    "    input_shape = X_train.shape[1:]\n",
    "    y_train_cat = to_categorical(y_train, num_classes=n_classes)\n",
    "    y_val_cat = to_categorical(y_val, num_classes=n_classes) if y_val is not None else None\n",
    "\n",
    "    model = build_cnn(input_shape, n_classes)\n",
    "    es = EarlyStopping(patience=5, restore_best_weights=True)\n",
    "\n",
    "    model.fit(X_train, y_train_cat, epochs=20, batch_size=32,\n",
    "              validation_data=(X_val, y_val_cat) if y_val is not None else None,\n",
    "              callbacks=[es], verbose=0)\n",
    "\n",
    "    model.save(os.path.join(model_dir, filename + \".h5\"))\n",
    "    return model\n",
    "\n",
    "def evaluate_model(model, X_test, y_test, description):\n",
    "    y_pred = np.argmax(model.predict(X_test), axis=1)\n",
    "    print(f\"\\n=== {description} ===\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "# ========== SCENARIOS ==========\n",
    "if B:\n",
    "    X_train_cnn = reshape_for_cnn(X_train)\n",
    "    X_test_cnn = reshape_for_cnn(X_test)\n",
    "    model_B = train_and_save_model(X_train_cnn, y_train, \"cnn_nopca_noaug_nonorm\", X_test_cnn, y_test)\n",
    "\n",
    "if D:\n",
    "    X_train_aug_cnn = reshape_for_cnn(X_train_aug)\n",
    "    X_test_aug_cnn = reshape_for_cnn(X_test_aug)\n",
    "    model_D = train_and_save_model(X_train_aug_cnn, y_train_aug, \"cnn_nopca_aug_nonorm\", X_test_aug_cnn, y_test_aug)\n",
    "\n",
    "if E:\n",
    "    X_train_cnn = reshape_for_cnn(X_train)\n",
    "    X_test_cnn = reshape_for_cnn(X_test)\n",
    "    model_E = train_and_save_model(X_train_cnn, y_train, \"cnn_nopca_noaug_nonorm\", X_test_cnn, y_test)\n",
    "\n",
    "if H:\n",
    "    X_train_aug_norm = np.array([x / np.linalg.norm(x) if np.linalg.norm(x) != 0 else x for x in X_train_aug])\n",
    "    X_test_aug_norm = np.array([x / np.linalg.norm(x) if np.linalg.norm(x) != 0 else x for x in X_test_aug])\n",
    "    X_train_aug_norm_cnn = reshape_for_cnn(X_train_aug_norm)\n",
    "    X_test_aug_norm_cnn = reshape_for_cnn(X_test_aug_norm)\n",
    "    model_H = train_and_save_model(X_train_aug_norm_cnn, y_train_aug, \"cnn_nopca_aug_norm\", X_test_aug_norm_cnn, y_test_aug)\n",
    "\n",
    "# ========== EVALUATION ==========\n",
    "if TEST_SET:\n",
    "    if B: evaluate_model(model_B, X_test_cnn, y_test, \"Scenario B: CNN NOPCA NOAUG NONORM\")\n",
    "    if D: evaluate_model(model_D, X_test_aug_cnn, y_test_aug, \"Scenario D: CNN NOPCA AUG NONORM\")\n",
    "    if E: evaluate_model(model_E, X_test_cnn, y_test, \"Scenario E: CNN NOPCA NOAUG NONORM\")\n",
    "    if H: evaluate_model(model_H, X_test_aug_norm_cnn, y_test_aug, \"Scenario H: CNN NOPCA AUG NORM\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HYPERPARAMETER TUNING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Bayesian Optimization for CNN...\n",
      "|   iter    |  target   | conv_f... | dense_... | dropou... |\n",
      "-------------------------------------------------------------\n",
      "| \u001b[39m1        \u001b[39m | \u001b[39m0.8818   \u001b[39m | \u001b[39m57.95    \u001b[39m | \u001b[39m245.0    \u001b[39m | \u001b[39m0.3928   \u001b[39m |\n",
      "| \u001b[39m2        \u001b[39m | \u001b[39m0.8607   \u001b[39m | \u001b[39m83.05    \u001b[39m | \u001b[39m66.95    \u001b[39m | \u001b[39m0.1624   \u001b[39m |\n",
      "| \u001b[35m3        \u001b[39m | \u001b[35m0.9042   \u001b[39m | \u001b[35m22.51    \u001b[39m | \u001b[35m226.0    \u001b[39m | \u001b[35m0.3404   \u001b[39m |\n",
      "| \u001b[39m4        \u001b[39m | \u001b[39m0.8943   \u001b[39m | \u001b[39m23.17    \u001b[39m | \u001b[39m225.2    \u001b[39m | \u001b[39m0.4846   \u001b[39m |\n",
      "| \u001b[35m5        \u001b[39m | \u001b[35m0.9129   \u001b[39m | \u001b[35m21.56    \u001b[39m | \u001b[35m228.2    \u001b[39m | \u001b[35m0.3401   \u001b[39m |\n",
      "| \u001b[39m6        \u001b[39m | \u001b[39m0.8918   \u001b[39m | \u001b[39m17.51    \u001b[39m | \u001b[39m226.9    \u001b[39m | \u001b[39m0.4111   \u001b[39m |\n",
      "| \u001b[39m7        \u001b[39m | \u001b[39m0.8781   \u001b[39m | \u001b[39m25.17    \u001b[39m | \u001b[39m231.6    \u001b[39m | \u001b[39m0.198    \u001b[39m |\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold, train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report\n",
    "from bayes_opt import BayesianOptimization\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization, Input\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# --- CONFIG FLAGS ---\n",
    "NORMALIZATION = False\n",
    "TRANSFORMATION = True\n",
    "\n",
    "# --- STEP 1: Load/Select Data ---\n",
    "if TRANSFORMATION:\n",
    "    try:\n",
    "        X = X_basic_aug\n",
    "        y = y_basic_aug\n",
    "    except NameError:\n",
    "        raise ValueError(\"X_basic_aug and y_basic_aug must be defined before running this script.\")\n",
    "else:\n",
    "    try:\n",
    "        X = X_basic\n",
    "        y = y_basic\n",
    "    except NameError:\n",
    "        raise ValueError(\"X_basic and y_basic must be defined before running this script.\")\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(y)\n",
    "n_classes = len(np.unique(y))\n",
    "\n",
    "if NORMALIZATION:\n",
    "    X = np.array([x / np.linalg.norm(x) if np.linalg.norm(x) != 0 else x for x in X])\n",
    "\n",
    "# Reshape to 2D square for CNN\n",
    "def reshape_for_cnn(X):\n",
    "    if len(X.shape) == 2:\n",
    "        side = int(np.sqrt(X.shape[1]))\n",
    "        return X.reshape((-1, side, side, 1))\n",
    "    return X\n",
    "\n",
    "X = reshape_for_cnn(X)\n",
    "\n",
    "# --- STEP 2: Define Objective Function ---\n",
    "def build_cnn_model(conv_filters=32, dense_units=64, dropout_rate=0.3, learning_rate=0.001):\n",
    "    model = Sequential([\n",
    "        Input(shape=X.shape[1:]),\n",
    "        Conv2D(conv_filters, (3, 3), activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D(2),\n",
    "        Flatten(),\n",
    "        Dense(dense_units, activation='relu'),\n",
    "        Dropout(dropout_rate),\n",
    "        Dense(n_classes, activation='softmax')\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def cnn_cv(conv_filters, dense_units, dropout_rate):\n",
    "    conv_filters = int(conv_filters)\n",
    "    dense_units = int(dense_units)\n",
    "    dropout_rate = float(dropout_rate)\n",
    "\n",
    "    acc_scores = []\n",
    "    skf = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "\n",
    "    for train_idx, val_idx in skf.split(X, y):\n",
    "        X_train_cv, X_val_cv = X[train_idx], X[val_idx]\n",
    "        y_train_cv, y_val_cv = y[train_idx], y[val_idx]\n",
    "\n",
    "        y_train_cv_cat = to_categorical(y_train_cv, num_classes=n_classes)\n",
    "        y_val_cv_cat = to_categorical(y_val_cv, num_classes=n_classes)\n",
    "\n",
    "        model = build_cnn_model(conv_filters, dense_units, dropout_rate, learning_rate=0.001)\n",
    "        model.fit(X_train_cv, y_train_cv_cat, epochs=10, batch_size=32, verbose=0, validation_data=(X_val_cv, y_val_cv_cat))\n",
    "\n",
    "        val_pred = np.argmax(model.predict(X_val_cv, verbose=0), axis=1)\n",
    "        acc = np.mean(val_pred == y_val_cv)\n",
    "        acc_scores.append(acc)\n",
    "\n",
    "    return np.mean(acc_scores)\n",
    "\n",
    "# --- STEP 3: Set Up Bayesian Optimizer ---\n",
    "pbounds = {\n",
    "    'conv_filters': (16, 128),\n",
    "    'dense_units': (32, 256),\n",
    "    'dropout_rate': (0.1, 0.5)\n",
    "}\n",
    "\n",
    "optimizer = BayesianOptimization(\n",
    "    f=cnn_cv,\n",
    "    pbounds=pbounds,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# --- STEP 4: Run Optimization ---\n",
    "init_points = 3\n",
    "n_iter = 10\n",
    "\n",
    "print(\"Starting Bayesian Optimization for CNN...\")\n",
    "best_score_so_far = -1.0\n",
    "optimizer.maximize(init_points=init_points, n_iter=n_iter)\n",
    "\n",
    "for i, res in enumerate(optimizer.res):\n",
    "    score = res['target']\n",
    "    print(f\"Iteration {i+1}, CV Accuracy: {score:.4f}, Parameters: {res['params']}\")\n",
    "\n",
    "# --- STEP 5: Best Hyperparameters ---\n",
    "best_params = optimizer.max['params']\n",
    "conv_filters = int(best_params['conv_filters'])\n",
    "dense_units = int(best_params['dense_units'])\n",
    "dropout_rate = float(best_params['dropout_rate'])\n",
    "\n",
    "print(\"\\n=== BEST HYPERPARAMETERS FOUND ===\")\n",
    "print(f\"conv_filters = {conv_filters}\")\n",
    "print(f\"dense_units = {dense_units}\")\n",
    "print(f\"dropout_rate = {dropout_rate:.2f}\")\n",
    "print(f\"CV Accuracy = {optimizer.max['target']:.4f}\")\n",
    "\n",
    "# --- STEP 6: Final Evaluation ---\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y, random_state=999)\n",
    "y_train_cat = to_categorical(y_train, num_classes=n_classes)\n",
    "y_test_cat = to_categorical(y_test, num_classes=n_classes)\n",
    "\n",
    "final_model = build_cnn_model(conv_filters, dense_units, dropout_rate, learning_rate=0.001)\n",
    "es = EarlyStopping(patience=5, restore_best_weights=True)\n",
    "final_model.fit(X_train, y_train_cat, validation_split=0.2, epochs=30, batch_size=32, callbacks=[es], verbose=1)\n",
    "\n",
    "# Evaluate\n",
    "pred = np.argmax(final_model.predict(X_test), axis=1)\n",
    "print(\"\\n=== FINAL EVALUATION ON HOLDOUT TEST SET ===\")\n",
    "print(classification_report(y_test, pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
