{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\"Machine learning tools\"\n",
    "import pickle\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "\n",
    "\n",
    "from classification.datasets import Dataset\n",
    "from classification.utils.audio_student import AudioUtil, Feature_vector_DS\n",
    "\n",
    "from classification.utils.plots import (\n",
    "    plot_decision_boundaries,\n",
    "    plot_specgram,\n",
    "    show_confusion_matrix,\n",
    ")\n",
    "from classification.utils.utils import accuracy\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization, Input\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chainsaw\n",
      "fire\n",
      "fireworks\n",
      "gunshot\n"
     ]
    }
   ],
   "source": [
    "### TO RUN\n",
    "dataset = Dataset()\n",
    "classnames = dataset.list_classes()\n",
    "\n",
    "print(\"\\n\".join(classnames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TO RUN\n",
    "fm_dir = \"data/feature_matrices/\"  # where to save the features matrices\n",
    "model_dir = \"data/models/cnn\"  # where to save the models\n",
    "os.makedirs(fm_dir, exist_ok=True)\n",
    "os.makedirs(model_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TO RUN\n",
    "\n",
    "\"Creation of the dataset\"\n",
    "myds = Feature_vector_DS(dataset, Nft=512, nmel=20, duration=950, shift_pct=0.0)\n",
    "\n",
    "\"Some attributes...\"\n",
    "myds.nmel\n",
    "myds.duration\n",
    "myds.shift_pct\n",
    "myds.sr\n",
    "myds.data_aug\n",
    "myds.ncol\n",
    "\n",
    "idx = 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now create a new augmented dataset and observe if the classification results improve. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 300x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from classification.utils.plots import show_confusion_matrix\n",
    "\n",
    "# Matrice de confusion fournie\n",
    "cm = np.array([\n",
    "    [12,  0,  0, 5],\n",
    "    [9,  0,  1,  5],\n",
    "    [3,  1,  4,  2],\n",
    "    [3,  0,  4,  1]\n",
    "])\n",
    "\n",
    "classnames = [\"chainsaw\", \"fire\", \"fireworks\", \"gunshot\"]\n",
    "\n",
    "# Reconstruction de y_true et y_pred\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "for true_label, row in enumerate(cm):\n",
    "    for pred_label, count in enumerate(row):\n",
    "        y_true.extend([true_label] * count)\n",
    "        y_pred.extend([pred_label] * count)\n",
    "\n",
    "# Affichage de la matrice de confusion\n",
    "show_confusion_matrix(y_pred, y_true, classnames, title=\"Confusion matrix : ESC-50 dataset\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'chainsaw': 315, 'fire': 303, 'fireworks': 315, 'gunshot': 40}\n",
      "Shape of the training matrix : (486, 400)\n",
      "Shape of the test matrix : (487, 400)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "from sklearn.calibration import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "data_aug_factor = 1\n",
    "featveclen = len(myds[\"fire\", 0, \"\", \"\"])  # Same for all classes\n",
    "classnames = [\"chainsaw\", \"fire\", \"fireworks\", \"gunshot\"]  # Or wherever you store class names\n",
    "nclass = len(classnames)\n",
    "\n",
    "# Determine number of samples per class\n",
    "naudio_per_class = {cls: len(dataset.files.get(cls, [])) for cls in classnames}\n",
    "print(naudio_per_class)\n",
    "\n",
    "# Allocate feature matrix\n",
    "total_samples_basic = sum(naudio_per_class[c] for c in classnames)\n",
    "X_basic = np.zeros((total_samples_basic, featveclen))\n",
    "y_basic = np.zeros((total_samples_basic), dtype=object)\n",
    "total_samples_basic\n",
    "# Fill feature matrix\n",
    "idx = 0\n",
    "for class_idx, classname in enumerate(classnames):\n",
    "    for i in range(naudio_per_class[classname]):\n",
    "        featvec = myds[classname, i, \"\", \"\"]\n",
    "        X_basic[idx, :] = featvec\n",
    "        y_basic[idx] = classname\n",
    "        idx += 1\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_basic, y_basic, test_size=0.2, random_state=42)\n",
    "\n",
    "# Normalization of the data\n",
    "scaler = StandardScaler()\n",
    "X_train_norm = scaler.fit_transform(X_train)\n",
    "X_test_norm = scaler.transform(X_test)\n",
    "with open(os.path.join(model_dir, f\"scaler.pkl\"), \"wb\") as f:\n",
    "    pickle.dump(scaler, f)\n",
    "\n",
    "label_encoder           = LabelEncoder()\n",
    "y_train     = label_encoder.fit_transform(y_train)\n",
    "y_test      = label_encoder.transform(y_test)\n",
    "with open(os.path.join(model_dir, f\"label_encoder.pkl\"), \"wb\") as f:\n",
    "    pickle.dump(label_encoder, f)\n",
    "\n",
    "# Save the feature matrix and labels\n",
    "np.save(os.path.join(fm_dir, \"X_train.npy\"), X_train)\n",
    "np.save(os.path.join(fm_dir, \"X_test.npy\"), X_test)\n",
    "np.save(os.path.join(fm_dir, \"y_train.npy\"), y_train)\n",
    "np.save(os.path.join(fm_dir, \"y_test.npy\"), y_test)\n",
    "np.save(os.path.join(fm_dir, \"X_train_norm.npy\"), X_train_norm)\n",
    "np.save(os.path.join(fm_dir, \"X_test_norm.npy\"), X_test_norm)\n",
    "\n",
    "print(f\"Shape of the training matrix : {X_train.shape}\")\n",
    "print(f\"Shape of the test matrix : {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from classification.utils.plots import plot_specgram_textlabel\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "BASIC = False\n",
    "if BASIC:\n",
    "    # Charger les données\n",
    "    X = np.load(os.path.join(fm_dir, \"X_train_aug.npy\"), allow_pickle=True)\n",
    "    y = np.load(os.path.join(fm_dir, \"y_train_aug.npy\"), allow_pickle=True)\n",
    "\n",
    "    # Dossier où sauvegarder les images\n",
    "    save_dir = os.path.join(\"src/classification/melspec_aug\")\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "    # Initialiser les compteurs par classe\n",
    "    class_counters = {}\n",
    "\n",
    "    for i in range(len(X)):\n",
    "        melspec = X[i]\n",
    "        class_of_spec = y[i]\n",
    "\n",
    "        # Ne traiter que si on a < 10 exemples pour cette classe\n",
    "        if class_of_spec not in class_counters:\n",
    "            class_counters[class_of_spec] = 0\n",
    "        if class_counters[class_of_spec] >= 10:\n",
    "            continue\n",
    "\n",
    "        class_idx = class_counters[class_of_spec]\n",
    "\n",
    "        # Affichage + sauvegarde\n",
    "        fig, ax = plt.subplots()\n",
    "        plot_specgram_textlabel(\n",
    "            melspec.reshape((20, 20)),\n",
    "            ax=ax,\n",
    "            is_mel=True,\n",
    "            title=f\"MEL Spectrogram - {class_of_spec} #{class_idx}\",\n",
    "            xlabel=\"Mel vector\",\n",
    "            textlabel=f\"{class_of_spec}\",\n",
    "        )\n",
    "        plt.tight_layout()\n",
    "        save_path = os.path.join(save_dir, f\"melspec_{class_of_spec}_{class_idx}.png\")\n",
    "        fig.savefig(save_path)\n",
    "        plt.close(fig)\n",
    "\n",
    "        class_counters[class_of_spec] += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of transformations :  2\n",
      "Shape of the training matrix : (970, 400)\n",
      "Shape of the test matrix : (488, 400)\n",
      "------------------------------------------------------------\n",
      "Transformations: ['original', 'shifting'].\n"
     ]
    }
   ],
   "source": [
    "### AUGMENTED DATASET\n",
    "TEST_WITH_AUGMENTED_FV = False\n",
    "\n",
    "list_augmentation = [\"original\", \"shifting\"]\n",
    "myds.mod_data_aug(list_augmentation)\n",
    "print(\"Number of transformations : \", myds.data_aug_factor)\n",
    "\n",
    "n_bands = 20\n",
    "frames = 20\n",
    "# Préparer les splits\n",
    "X_train_list, y_train_list = [], []\n",
    "X_test_list,  y_test_list  = [], []\n",
    "\n",
    "for classname in classnames:\n",
    "    n = naudio_per_class[classname]\n",
    "\n",
    "    # Création des indices de base pour les sons originaux\n",
    "    original_indices = list(range(n))\n",
    "    train_idx, test_idx = train_test_split(original_indices, test_size=0.2, random_state=42)\n",
    "\n",
    "    for i in train_idx:\n",
    "        for aug in list_augmentation:\n",
    "            featvec = myds[classname, i, aug, \"\"]\n",
    "            X_train_list.append(featvec)\n",
    "            y_train_list.append(classname)\n",
    "\n",
    "    for i in test_idx:\n",
    "        if TEST_WITH_AUGMENTED_FV:\n",
    "            for aug in list_augmentation:\n",
    "                featvec = myds[classname, i, aug, \"\"]\n",
    "                X_test_list.append(featvec)\n",
    "                y_test_list.append(classname)\n",
    "        else:\n",
    "            featvec = myds[classname, i, \"\", \"\"]\n",
    "            X_test_list.append(featvec)\n",
    "            y_test_list.append(classname)\n",
    "\n",
    "# Conversion en tableaux numpy\n",
    "X_train_aug = np.array(X_train_list)\n",
    "y_train_aug = np.array(y_train_list, dtype=object)\n",
    "\n",
    "X_test_aug = np.array(X_test_list)\n",
    "y_test_aug = np.array(y_test_list, dtype=object)\n",
    "\n",
    "# --- 1) Z-SCORE GLOBAL -------------------------------\n",
    "scaler_global = StandardScaler().fit(X_train_aug)\n",
    "X_train_aug_norm_zscore_global = scaler_global.transform(X_train_aug)\n",
    "X_test_aug_norm_zscore_global  = scaler_global.transform(X_test_aug)\n",
    "\n",
    "with open(os.path.join(model_dir, \"scaler_aug_zscore_global.pkl\"), \"wb\") as f:\n",
    "    pickle.dump(scaler_global, f)\n",
    "np.save(os.path.join(fm_dir, \"X_train_aug_norm_zscore_global.npy\"), X_train_aug_norm_zscore_global)\n",
    "np.save(os.path.join(fm_dir, \"X_test_aug_norm_zscore_global.npy\"),  X_test_aug_norm_zscore_global)\n",
    "\n",
    "# --- 2) Z-SCORE PAR BANDE MEL ------------------------------------\n",
    "X_train_resh = X_train_aug.reshape(-1, n_bands, frames)\n",
    "X_test_resh  = X_test_aug.reshape(-1, n_bands, frames)\n",
    "\n",
    "mean_band = X_train_resh.mean(axis=(0, 2))          # (20,)\n",
    "std_band  = X_train_resh.std(axis=(0, 2)) + 1e-8    # (20,)\n",
    "\n",
    "X_train_aug_norm_zscore_band = ((X_train_resh - mean_band[None,:,None])\n",
    "                           / std_band[None,:,None]).reshape(-1, n_bands*frames)\n",
    "X_test_aug_norm_zscore_band  = ((X_test_resh  - mean_band[None,:,None])\n",
    "                           / std_band[None,:,None]).reshape(-1, n_bands*frames)\n",
    "\n",
    "np.save(os.path.join(model_dir, \"zscore_band_mean.npy\"), mean_band)\n",
    "np.save(os.path.join(model_dir, \"zscore_band_std.npy\"),  std_band)\n",
    "np.save(os.path.join(fm_dir, \"X_train_aug_norm_zscore_band.npy\"), X_train_aug_norm_zscore_band)\n",
    "np.save(os.path.join(fm_dir, \"X_test_aug_norm_zscore_band.npy\"),  X_test_aug_norm_zscore_band)\n",
    "\n",
    "# --- 3) MIN-MAX PAR BANDE MEL ------------------------------------\n",
    "min_band = X_train_resh.min(axis=(0, 2))\n",
    "max_band = X_train_resh.max(axis=(0, 2)) + 1e-8\n",
    "\n",
    "X_train_aug_norm_minmax = ((X_train_resh - min_band[None,:,None])\n",
    "                           / (max_band - min_band)[None,:,None]).reshape(-1, n_bands*frames)\n",
    "X_test_aug_norm_minmax  = ((X_test_resh  - min_band[None,:,None])\n",
    "                           / (max_band - min_band)[None,:,None]).reshape(-1, n_bands*frames)\n",
    "\n",
    "np.save(os.path.join(model_dir, \"min_band.npy\"), min_band)\n",
    "np.save(os.path.join(model_dir, \"max_band.npy\"), max_band)\n",
    "np.save(os.path.join(fm_dir, \"X_train_aug_norm_minmax.npy\"), X_train_aug_norm_minmax)\n",
    "np.save(os.path.join(fm_dir, \"X_test_aug_norm_minmax.npy\"),  X_test_aug_norm_minmax)\n",
    "\n",
    "# --- 4) GLOBAL MAX NORMALIZATION -------------------------------\n",
    "# Chaque spectrogramme est divisé par son max propre (par ligne)\n",
    "X_train_aug_norm_max = X_train_aug.copy().astype(np.float32)\n",
    "X_test_aug_norm_max  = X_test_aug.copy().astype(np.float32)\n",
    "\n",
    "X_train_max = X_train_aug_norm_max.max(axis=1, keepdims=True) + 1e-8 # éviter la division par 0\n",
    "X_test_max  = X_test_aug_norm_max.max(axis=1, keepdims=True) + 1e-8\n",
    "\n",
    "X_train_aug_norm_max /= X_train_max\n",
    "X_test_aug_norm_max  /= X_test_max\n",
    "\n",
    "np.save(os.path.join(fm_dir, \"X_train_aug_norm_max.npy\"), X_train_aug_norm_max)\n",
    "np.save(os.path.join(fm_dir, \"X_test_aug_norm_max.npy\"),  X_test_aug_norm_max)\n",
    "\n",
    "# Label encoding\n",
    "label_encoder_aug = LabelEncoder()\n",
    "y_train_aug     = label_encoder_aug.fit_transform(y_train_aug)\n",
    "y_test_aug      = label_encoder_aug.transform(y_test_aug)\n",
    "with open(os.path.join(model_dir, f\"label_encoder_aug.pkl\"), \"wb\") as f:\n",
    "    pickle.dump(label_encoder_aug, f)\n",
    "\n",
    "np.save(os.path.join(fm_dir, \"X_train_aug.npy\"), X_train_aug)\n",
    "np.save(os.path.join(fm_dir, \"X_test_aug.npy\"), X_test_aug)\n",
    "np.save(os.path.join(fm_dir, \"y_train_aug.npy\"), y_train_aug)\n",
    "np.save(os.path.join(fm_dir, \"y_test_aug.npy\"), y_test_aug)\n",
    "\n",
    "print(f\"Shape of the training matrix : {X_train_aug.shape}\")\n",
    "print(f\"Shape of the test matrix : {X_test_aug.shape}\")\n",
    "print(f\"------------------------------------------------------------\")\n",
    "print(f\"Transformations: {list_augmentation}.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FINAL MODEL SAVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== cnn_noaug_nonorm =====\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9130    0.9074    0.9102       162\n",
      "           1     0.8085    0.9212    0.8612       165\n",
      "           2     0.8898    0.7394    0.8077       142\n",
      "           3     0.8000    0.8889    0.8421        18\n",
      "\n",
      "    accuracy                         0.8624       487\n",
      "   macro avg     0.8528    0.8642    0.8553       487\n",
      "weighted avg     0.8667    0.8624    0.8612       487\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== cnn_noaug_norm =====\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8876    0.9259    0.9063       162\n",
      "           1     0.8750    0.9333    0.9032       165\n",
      "           2     0.8819    0.7887    0.8327       142\n",
      "           3     1.0000    0.8333    0.9091        18\n",
      "\n",
      "    accuracy                         0.8850       487\n",
      "   macro avg     0.9111    0.8703    0.8878       487\n",
      "weighted avg     0.8858    0.8850    0.8839       487\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== cnn_aug_nonorm =====\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8034    0.9051    0.8512       158\n",
      "           1     0.6272    0.9408    0.7526       152\n",
      "           2     0.9355    0.3671    0.5273       158\n",
      "           3     1.0000    1.0000    1.0000        20\n",
      "\n",
      "    accuracy                         0.7459       488\n",
      "   macro avg     0.8415    0.8032    0.7828       488\n",
      "weighted avg     0.7993    0.7459    0.7217       488\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== cnn_aug_zscore_global =====\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9187    0.9304    0.9245       158\n",
      "           1     0.8208    0.9342    0.8738       152\n",
      "           2     0.9481    0.8101    0.8737       158\n",
      "           3     1.0000    1.0000    1.0000        20\n",
      "\n",
      "    accuracy                         0.8955       488\n",
      "   macro avg     0.9219    0.9187    0.9180       488\n",
      "weighted avg     0.9011    0.8955    0.8954       488\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[76], line 168\u001b[0m\n\u001b[1;32m    165\u001b[0m X_te \u001b[38;5;241m=\u001b[39m reshape_for_cnn(cfg[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX_test\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    167\u001b[0m \u001b[38;5;66;03m# 2) entraînement + sauvegarde\u001b[39;00m\n\u001b[0;32m--> 168\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_cnn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_tr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43my_train\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_te\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43my_test\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtag\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;66;03m# 3) évaluation\u001b[39;00m\n\u001b[1;32m    171\u001b[0m evaluate(model, X_te, cfg[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_test\u001b[39m\u001b[38;5;124m\"\u001b[39m], tag)\n",
      "Cell \u001b[0;32mIn[76], line 97\u001b[0m, in \u001b[0;36mtrain_cnn\u001b[0;34m(X_tr, y_tr, X_val, y_val, name)\u001b[0m\n\u001b[1;32m     94\u001b[0m model \u001b[38;5;241m=\u001b[39m build_cnn(X_tr\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m:], n_classes)\n\u001b[1;32m     95\u001b[0m es \u001b[38;5;241m=\u001b[39m EarlyStopping(patience\u001b[38;5;241m=\u001b[39mpatience, restore_best_weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m---> 97\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_tr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_tr_cat\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     98\u001b[0m \u001b[43m          \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val_cat\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     99\u001b[0m \u001b[43m          \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    100\u001b[0m \u001b[43m          \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    101\u001b[0m \u001b[43m          \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mes\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    102\u001b[0m \u001b[43m          \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    104\u001b[0m model\u001b[38;5;241m.\u001b[39msave(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(model_dir, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "File \u001b[0;32m~/master_projet_elec/LELEC210X/.venv/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/master_projet_elec/LELEC210X/.venv/lib/python3.9/site-packages/keras/src/backend/tensorflow/trainer.py:371\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    369\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator:\n\u001b[1;32m    370\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m--> 371\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    372\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(step, logs)\n\u001b[1;32m    373\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n",
      "File \u001b[0;32m~/master_projet_elec/LELEC210X/.venv/lib/python3.9/site-packages/keras/src/backend/tensorflow/trainer.py:219\u001b[0m, in \u001b[0;36mTensorFlowTrainer._make_function.<locals>.function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfunction\u001b[39m(iterator):\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[1;32m    217\u001b[0m         iterator, (tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mIterator, tf\u001b[38;5;241m.\u001b[39mdistribute\u001b[38;5;241m.\u001b[39mDistributedIterator)\n\u001b[1;32m    218\u001b[0m     ):\n\u001b[0;32m--> 219\u001b[0m         opt_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmulti_step_on_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m opt_outputs\u001b[38;5;241m.\u001b[39mhas_value():\n\u001b[1;32m    221\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m~/master_projet_elec/LELEC210X/.venv/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/master_projet_elec/LELEC210X/.venv/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/master_projet_elec/LELEC210X/.venv/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[1;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[0;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[1;32m    880\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[1;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/master_projet_elec/LELEC210X/.venv/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/master_projet_elec/LELEC210X/.venv/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m     args,\n\u001b[1;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1326\u001b[0m     executing_eagerly)\n\u001b[1;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/master_projet_elec/LELEC210X/.venv/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m~/master_projet_elec/LELEC210X/.venv/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    261\u001b[0m     )\n",
      "File \u001b[0;32m~/master_projet_elec/LELEC210X/.venv/lib/python3.9/site-packages/tensorflow/python/eager/context.py:1688\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1686\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1687\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1688\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1689\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1690\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1691\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1692\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1693\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1694\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1695\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1696\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1697\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1698\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1702\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1703\u001b[0m   )\n",
      "File \u001b[0;32m~/master_projet_elec/LELEC210X/.venv/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization, Input\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# ========== PARAMETERS ==========\n",
    "\n",
    "# Hyperparamètres issus de l'optimisation\n",
    "conv_filters = 35\n",
    "dense_units = 255\n",
    "dropout_rate = 0.2605200001496385\n",
    "kernel_size = 3\n",
    "n_conv_layers = 1\n",
    "batch_norm = True\n",
    "activation = 'relu'\n",
    "epochs = 29\n",
    "batch_size = 29\n",
    "patience = 6\n",
    "\n",
    "A = True  # NOAUG NONORM\n",
    "B = True  # NOAUG NORM\n",
    "C = True  # AUG NONORM\n",
    "D = True  # AUG NORM ZSCORE GLOBAL\n",
    "E = True  # AUG NORM ZSCORE BAND\n",
    "F = True  # AUG NORM MINMAX BAND\n",
    "G = True\n",
    "\n",
    "X_train_aug = np.load(os.path.join(fm_dir, \"X_train_aug.npy\"))\n",
    "X_test_aug = np.load(os.path.join(fm_dir, \"X_test_aug.npy\"))\n",
    "y_train_aug = np.load(os.path.join(fm_dir, \"y_train_aug.npy\"))\n",
    "y_test_aug = np.load(os.path.join(fm_dir, \"y_test_aug.npy\"))\n",
    "\n",
    "X_train_aug_norm_zscore_global = np.load(os.path.join(fm_dir, \"X_train_aug_norm_zscore_global.npy\"))\n",
    "X_test_aug_norm_zscore_global = np.load(os.path.join(fm_dir, \"X_test_aug_norm_zscore_global.npy\"))\n",
    "\n",
    "X_train_aug_norm_zscore_band = np.load(os.path.join(fm_dir, \"X_train_aug_norm_zscore_band.npy\"))\n",
    "X_test_aug_norm_zscore_band = np.load(os.path.join(fm_dir, \"X_test_aug_norm_zscore_band.npy\"))\n",
    "\n",
    "X_train_aug_norm_minmax = np.load(os.path.join(fm_dir, \"X_train_aug_norm_minmax.npy\"))\n",
    "X_test_aug_norm_minmax = np.load(os.path.join(fm_dir, \"X_test_aug_norm_minmax.npy\"))\n",
    "\n",
    "X_train = np.load(os.path.join(fm_dir, \"X_train.npy\"))\n",
    "X_train_norm = np.load(os.path.join(fm_dir, \"X_train_norm.npy\"))\n",
    "X_test = np.load(os.path.join(fm_dir, \"X_test.npy\"))\n",
    "X_test_norm = np.load(os.path.join(fm_dir, \"X_test_norm.npy\"))\n",
    "y_train = np.load(os.path.join(fm_dir, \"y_train.npy\"))\n",
    "y_test = np.load(os.path.join(fm_dir, \"y_test.npy\"))\n",
    "\n",
    "\n",
    "# ========== HELPERS ==========\n",
    "\n",
    "def reshape_for_cnn(X):\n",
    "    \"\"\"Transforme (n_samples, n_features) -> (n, h, w, 1).\"\"\"\n",
    "    if X.ndim == 2:                        # vecteurs aplatis → carrés\n",
    "        side = int(np.sqrt(X.shape[1]))    # → 20 si 400 features, etc.\n",
    "        X = X.reshape((-1, side, side, 1))\n",
    "    elif X.ndim == 3:                      # déjà (n, h, w)\n",
    "        X = X[..., np.newaxis]             # → ajoute canal unique\n",
    "    return X\n",
    "\n",
    "def build_cnn(input_shape, n_classes):\n",
    "    model = Sequential([Input(shape=input_shape)])\n",
    "    for i in range(n_conv_layers):\n",
    "        model.add(Conv2D(conv_filters * (2**i),\n",
    "                         (kernel_size, kernel_size),\n",
    "                         activation=activation))\n",
    "        if batch_norm:\n",
    "            model.add(BatchNormalization())\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(dense_units, activation=activation))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(n_classes, activation='softmax'))\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def train_cnn(X_tr, y_tr, X_val, y_val, name):\n",
    "    \"\"\"Entraîne et sauvegarde le modèle, renvoie le modèle entraîné.\"\"\"\n",
    "    n_classes = len(np.unique(y_tr))\n",
    "    y_tr_cat  = to_categorical(y_tr,  num_classes=n_classes)\n",
    "    y_val_cat = to_categorical(y_val, num_classes=n_classes)\n",
    "\n",
    "    model = build_cnn(X_tr.shape[1:], n_classes)\n",
    "    es = EarlyStopping(patience=patience, restore_best_weights=True, verbose=0)\n",
    "\n",
    "    model.fit(X_tr, y_tr_cat,\n",
    "              validation_data=(X_val, y_val_cat),\n",
    "              epochs=epochs,\n",
    "              batch_size=batch_size,\n",
    "              callbacks=[es],\n",
    "              verbose=0)\n",
    "\n",
    "    model.save(os.path.join(model_dir, f\"{name}.h5\"))\n",
    "    return model\n",
    "\n",
    "def evaluate(model, X_te, y_te, title):\n",
    "    y_pred = np.argmax(model.predict(X_te, verbose=0), axis=1)\n",
    "    print(f\"\\n===== {title} =====\")\n",
    "    print(classification_report(y_te, y_pred, digits=4))\n",
    "\n",
    "# ========== SCENARIOS ==========\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "#  SCÉNARIOS À TESTER\n",
    "# ------------------------------------------------------------------\n",
    "scenarios = {\n",
    "    \"cnn_noaug_nonorm\": dict(\n",
    "        X_train=X_train,            X_test=X_test,\n",
    "        y_train=y_train,            y_test=y_test,\n",
    "        scenario = A),\n",
    "    \"cnn_noaug_norm\": dict(\n",
    "        X_train=X_train_norm,       X_test=X_test_norm,\n",
    "        y_train=y_train,            y_test=y_test,\n",
    "        scenario = B),                # déjà normalisé → pas besoin de scaler\n",
    "    \"cnn_aug_nonorm\": dict(\n",
    "        X_train=X_train_aug,        X_test=X_test_aug,\n",
    "        y_train=y_train_aug,        y_test=y_test_aug,\n",
    "        scenario = C),\n",
    "    \"cnn_aug_zscore_global\": dict(\n",
    "        X_train=X_train_aug_norm_zscore_global, \n",
    "        X_test=X_test_aug_norm_zscore_global,\n",
    "        y_train=y_train_aug, \n",
    "        y_test=y_test_aug,\n",
    "        scenario=D),\n",
    "\n",
    "    \"cnn_aug_zscore_band\": dict(\n",
    "        X_train=X_train_aug_norm_zscore_band, \n",
    "        X_test=X_test_aug_norm_zscore_band,\n",
    "        y_train=y_train_aug, \n",
    "        y_test=y_test_aug,\n",
    "        scenario=E),\n",
    "\n",
    "    \"cnn_aug_minmax_band\": dict(\n",
    "        X_train=X_train_aug_norm_minmax, \n",
    "        X_test=X_test_aug_norm_minmax,\n",
    "        y_train=y_train_aug, \n",
    "        y_test=y_test_aug,\n",
    "        scenario=F),\n",
    "    \"cnn_aug_max\": dict(\n",
    "        X_train=X_train_aug_norm_max, \n",
    "        X_test=X_test_aug_norm_max,\n",
    "        y_train=y_train_aug, \n",
    "        y_test=y_test_aug,\n",
    "        scenario=G),\n",
    "}\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "#  BOUCLE D’ENTRAÎNEMENT + ÉVALUATION\n",
    "# ------------------------------------------------------------------\n",
    "for tag, cfg in scenarios.items():\n",
    "    # 1) mise en forme CNN\n",
    "    if cfg[\"scenario\"]:\n",
    "        X_tr = reshape_for_cnn(cfg[\"X_train\"])\n",
    "        X_te = reshape_for_cnn(cfg[\"X_test\"])\n",
    "        \n",
    "        # 2) entraînement + sauvegarde\n",
    "        model = train_cnn(X_tr, cfg[\"y_train\"], X_te, cfg[\"y_test\"], tag)\n",
    "\n",
    "        # 3) évaluation\n",
    "        evaluate(model, X_te, cfg[\"y_test\"], tag)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HYPERPARAMETER TUNING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Bayesian optimization en cours…\n",
      "|   iter    |  target   | activa... | batch_... | batch_... | conv_f... | dense_... | dropou... |  epochs   | kernel... | n_conv... | patience  |\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "| \u001b[39m1        \u001b[39m | \u001b[39m0.6055   \u001b[39m | \u001b[39m0.3745   \u001b[39m | \u001b[39m0.9507   \u001b[39m | \u001b[39m51.14    \u001b[39m | \u001b[39m44.74    \u001b[39m | \u001b[39m66.95    \u001b[39m | \u001b[39m0.1624   \u001b[39m | \u001b[39m6.452    \u001b[39m | \u001b[39m4.732    \u001b[39m | \u001b[39m2.202    \u001b[39m | \u001b[39m7.665    \u001b[39m |\n",
      "| \u001b[35m2        \u001b[39m | \u001b[35m0.6389   \u001b[39m | \u001b[35m0.02058  \u001b[39m | \u001b[35m0.9699   \u001b[39m | \u001b[35m55.96    \u001b[39m | \u001b[35m26.19    \u001b[39m | \u001b[35m72.73    \u001b[39m | \u001b[35m0.1734   \u001b[39m | \u001b[35m12.61    \u001b[39m | \u001b[35m4.05     \u001b[39m | \u001b[35m1.864    \u001b[39m | \u001b[35m4.33     \u001b[39m |\n",
      "| \u001b[35m3        \u001b[39m | \u001b[35m0.7802   \u001b[39m | \u001b[35m0.6119   \u001b[39m | \u001b[35m0.1395   \u001b[39m | \u001b[35m30.02    \u001b[39m | \u001b[35m33.59    \u001b[39m | \u001b[35m134.2    \u001b[39m | \u001b[35m0.4141   \u001b[39m | \u001b[35m9.992    \u001b[39m | \u001b[35m4.028    \u001b[39m | \u001b[35m2.185    \u001b[39m | \u001b[35m2.372    \u001b[39m |\n",
      "| \u001b[35m4        \u001b[39m | \u001b[35m0.8458   \u001b[39m | \u001b[35m0.6075   \u001b[39m | \u001b[35m0.1705   \u001b[39m | \u001b[35m19.12    \u001b[39m | \u001b[35m61.55    \u001b[39m | \u001b[35m248.3    \u001b[39m | \u001b[35m0.4234   \u001b[39m | \u001b[35m12.62    \u001b[39m | \u001b[35m3.195    \u001b[39m | \u001b[35m2.368    \u001b[39m | \u001b[35m5.521    \u001b[39m |\n",
      "| \u001b[39m5        \u001b[39m | \u001b[39m0.8046   \u001b[39m | \u001b[39m0.122    \u001b[39m | \u001b[39m0.4952   \u001b[39m | \u001b[39m17.65    \u001b[39m | \u001b[39m59.65    \u001b[39m | \u001b[39m89.97    \u001b[39m | \u001b[39m0.365    \u001b[39m | \u001b[39m12.79    \u001b[39m | \u001b[39m4.04     \u001b[39m | \u001b[39m2.093    \u001b[39m | \u001b[39m3.479    \u001b[39m |\n",
      "| \u001b[39m6        \u001b[39m | \u001b[39m0.766    \u001b[39m | \u001b[39m0.8591   \u001b[39m | \u001b[39m0.657    \u001b[39m | \u001b[39m24.84    \u001b[39m | \u001b[39m53.65    \u001b[39m | \u001b[39m216.4    \u001b[39m | \u001b[39m0.4398   \u001b[39m | \u001b[39m15.1     \u001b[39m | \u001b[39m3.818    \u001b[39m | \u001b[39m1.31     \u001b[39m | \u001b[39m8.181    \u001b[39m |\n",
      "| \u001b[39m7        \u001b[39m | \u001b[39m0.8316   \u001b[39m | \u001b[39m0.6028   \u001b[39m | \u001b[39m0.3416   \u001b[39m | \u001b[39m18.2     \u001b[39m | \u001b[39m60.95    \u001b[39m | \u001b[39m251.2    \u001b[39m | \u001b[39m0.1391   \u001b[39m | \u001b[39m15.46    \u001b[39m | \u001b[39m3.44     \u001b[39m | \u001b[39m2.091    \u001b[39m | \u001b[39m5.896    \u001b[39m |\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[66], line 147\u001b[0m\n\u001b[1;32m    142\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m BayesianOptimization(f\u001b[38;5;241m=\u001b[39mcv_objective,\n\u001b[1;32m    143\u001b[0m                                  pbounds\u001b[38;5;241m=\u001b[39mpbounds,\n\u001b[1;32m    144\u001b[0m                                  random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m    146\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m🔍 Bayesian optimization en cours…\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 147\u001b[0m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmaximize\u001b[49m\u001b[43m(\u001b[49m\u001b[43minit_points\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_iter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m45\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;66;03m# ------------------------------------------------------------------\u001b[39;00m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;66;03m# 6) MEILLEURS PARAMÈTRES TROUVÉS\u001b[39;00m\n\u001b[1;32m    152\u001b[0m \u001b[38;5;66;03m#    ----------------------------------------------------\u001b[39;00m\n\u001b[1;32m    153\u001b[0m best \u001b[38;5;241m=\u001b[39m optimizer\u001b[38;5;241m.\u001b[39mmax[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparams\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m~/master_projet_elec/LELEC210X/.venv/lib/python3.9/site-packages/bayes_opt/bayesian_optimization.py:338\u001b[0m, in \u001b[0;36mBayesianOptimization.maximize\u001b[0;34m(self, init_points, n_iter)\u001b[0m\n\u001b[1;32m    336\u001b[0m     x_probe \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msuggest()\n\u001b[1;32m    337\u001b[0m     iteration \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 338\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprobe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_probe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlazy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    340\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bounds_transformer \u001b[38;5;129;01mand\u001b[39;00m iteration \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    341\u001b[0m     \u001b[38;5;66;03m# The bounds transformer should only modify the bounds after\u001b[39;00m\n\u001b[1;32m    342\u001b[0m     \u001b[38;5;66;03m# the init_points points (only for the true iterations)\u001b[39;00m\n\u001b[1;32m    343\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_bounds(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bounds_transformer\u001b[38;5;241m.\u001b[39mtransform(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_space))\n",
      "File \u001b[0;32m~/master_projet_elec/LELEC210X/.venv/lib/python3.9/site-packages/bayes_opt/bayesian_optimization.py:270\u001b[0m, in \u001b[0;36mBayesianOptimization.probe\u001b[0;34m(self, params, lazy)\u001b[0m\n\u001b[1;32m    268\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_queue\u001b[38;5;241m.\u001b[39mappend(params)\n\u001b[1;32m    269\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 270\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_space\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprobe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    271\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch(Events\u001b[38;5;241m.\u001b[39mOPTIMIZATION_STEP)\n",
      "File \u001b[0;32m~/master_projet_elec/LELEC210X/.venv/lib/python3.9/site-packages/bayes_opt/target_space.py:418\u001b[0m, in \u001b[0;36mTargetSpace.probe\u001b[0;34m(self, params)\u001b[0m\n\u001b[1;32m    416\u001b[0m     error_msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo target function has been provided.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    417\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(error_msg)\n\u001b[0;32m--> 418\u001b[0m target \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mdict_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    420\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constraint \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    421\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mregister(x, target)\n",
      "Cell \u001b[0;32mIn[66], line 118\u001b[0m, in \u001b[0;36mcv_objective\u001b[0;34m(conv_filters, dense_units, dropout_rate, epochs, batch_size, patience, kernel_size, n_conv_layers, batch_norm, activation)\u001b[0m\n\u001b[1;32m    114\u001b[0m model \u001b[38;5;241m=\u001b[39m build_cnn(conv_filters, dense_units, dropout_rate,\n\u001b[1;32m    115\u001b[0m                   kernel_size, n_conv_layers, batch_norm, activation)\n\u001b[1;32m    117\u001b[0m es \u001b[38;5;241m=\u001b[39m EarlyStopping(patience\u001b[38;5;241m=\u001b[39mpatience, restore_best_weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m--> 118\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_tr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_tr_cat\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    119\u001b[0m \u001b[43m          \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val_cat\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    120\u001b[0m \u001b[43m          \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    121\u001b[0m \u001b[43m          \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mes\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    123\u001b[0m val_pred \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(model\u001b[38;5;241m.\u001b[39mpredict(X_val, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    124\u001b[0m scores\u001b[38;5;241m.\u001b[39mappend((val_pred \u001b[38;5;241m==\u001b[39m y_val)\u001b[38;5;241m.\u001b[39mmean())\n",
      "File \u001b[0;32m~/master_projet_elec/LELEC210X/.venv/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/master_projet_elec/LELEC210X/.venv/lib/python3.9/site-packages/keras/src/backend/tensorflow/trainer.py:369\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    367\u001b[0m callbacks\u001b[38;5;241m.\u001b[39mon_epoch_begin(epoch)\n\u001b[1;32m    368\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m epoch_iterator\u001b[38;5;241m.\u001b[39mcatch_stop_iteration():\n\u001b[0;32m--> 369\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator:\n\u001b[1;32m    370\u001b[0m         callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m    371\u001b[0m         logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_function(iterator)\n",
      "File \u001b[0;32m~/master_projet_elec/LELEC210X/.venv/lib/python3.9/site-packages/keras/src/backend/tensorflow/trainer.py:734\u001b[0m, in \u001b[0;36mTFEpochIterator.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    733\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__next__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_epoch_iterator\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/master_projet_elec/LELEC210X/.venv/lib/python3.9/site-packages/keras/src/trainers/epoch_iterator.py:112\u001b[0m, in \u001b[0;36mEpochIterator._enumerate_iterator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m step, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_current_iterator\n\u001b[1;32m    111\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_batches \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_steps_seen \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_batches:\n\u001b[0;32m--> 112\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_current_iterator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43miter\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    113\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_steps_seen \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/master_projet_elec/LELEC210X/.venv/lib/python3.9/site-packages/tensorflow/python/data/ops/dataset_ops.py:501\u001b[0m, in \u001b[0;36mDatasetV2.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    499\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecuting_eagerly() \u001b[38;5;129;01mor\u001b[39;00m ops\u001b[38;5;241m.\u001b[39minside_function():\n\u001b[1;32m    500\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mcolocate_with(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variant_tensor):\n\u001b[0;32m--> 501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43miterator_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mOwnedIterator\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    502\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    503\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`tf.data.Dataset` only supports Python-style \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    504\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miteration in eager mode or within tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/master_projet_elec/LELEC210X/.venv/lib/python3.9/site-packages/tensorflow/python/data/ops/iterator_ops.py:709\u001b[0m, in \u001b[0;36mOwnedIterator.__init__\u001b[0;34m(self, dataset, components, element_spec)\u001b[0m\n\u001b[1;32m    705\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m (components \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m element_spec \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    706\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    707\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhen `dataset` is provided, `element_spec` and `components` must \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    708\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnot be specified.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 709\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    711\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_next_call_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[0;32m~/master_projet_elec/LELEC210X/.venv/lib/python3.9/site-packages/tensorflow/python/data/ops/iterator_ops.py:748\u001b[0m, in \u001b[0;36mOwnedIterator._create_iterator\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    745\u001b[0m   \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(fulltype\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39margs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(\n\u001b[1;32m    746\u001b[0m       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flat_output_types)\n\u001b[1;32m    747\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterator_resource\u001b[38;5;241m.\u001b[39mop\u001b[38;5;241m.\u001b[39mexperimental_set_type(fulltype)\n\u001b[0;32m--> 748\u001b[0m \u001b[43mgen_dataset_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmake_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mds_variant\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_iterator_resource\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/master_projet_elec/LELEC210X/.venv/lib/python3.9/site-packages/tensorflow/python/ops/gen_dataset_ops.py:3478\u001b[0m, in \u001b[0;36mmake_iterator\u001b[0;34m(dataset, iterator, name)\u001b[0m\n\u001b[1;32m   3476\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tld\u001b[38;5;241m.\u001b[39mis_eager:\n\u001b[1;32m   3477\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3478\u001b[0m     _result \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_FastPathExecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3479\u001b[0m \u001b[43m      \u001b[49m\u001b[43m_ctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mMakeIterator\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3480\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _result\n\u001b[1;32m   3481\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import classification_report\n",
    "from bayes_opt import BayesianOptimization\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization, Input\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# --- CONFIG FLAGS ---\n",
    "NORMALIZATION = False\n",
    "TRANSFORMATION = False\n",
    "TYPE = \"zscore_global\" # \"minmax_band\" or \"zscore_band\" or \"zscore_global\"\n",
    "\n",
    "if TRANSFORMATION:\n",
    "    if NORMALIZATION:\n",
    "        if TYPE == \"zscore_global\":\n",
    "            X_train = np.load(os.path.join(fm_dir, \"X_train_aug_norm_zscore_global.npy\"))\n",
    "            X_test = np.load(os.path.join(fm_dir, \"X_test_aug_norm_zscore_global.npy\"))\n",
    "            y_train = np.load(os.path.join(fm_dir, \"y_train_aug.npy\"))\n",
    "            y_test = np.load(os.path.join(fm_dir, \"y_test_aug.npy\"))\n",
    "        elif TYPE == \"zscore_band\":\n",
    "            X_train = np.load(os.path.join(fm_dir, \"X_train_aug_norm_zscore_band.npy\"))\n",
    "            X_test = np.load(os.path.join(fm_dir, \"X_test_aug_norm_zscore_band.npy\"))\n",
    "            y_train = np.load(os.path.join(fm_dir, \"y_train_aug.npy\"))\n",
    "            y_test = np.load(os.path.join(fm_dir, \"y_test_aug.npy\"))\n",
    "        elif TYPE == \"minmax_band\":\n",
    "            X_train = np.load(os.path.join(fm_dir, \"X_train_aug_norm_minmax.npy\"))\n",
    "            X_test = np.load(os.path.join(fm_dir, \"X_test_aug_norm_minmax.npy\"))\n",
    "            y_train = np.load(os.path.join(fm_dir, \"y_train_aug.npy\"))\n",
    "            y_test = np.load(os.path.join(fm_dir, \"y_test_aug.npy\"))\n",
    "else:\n",
    "    if NORMALIZATION:\n",
    "        X_train = np.load(os.path.join(fm_dir, \"X_train_norm.npy\"))\n",
    "        X_test = np.load(os.path.join(fm_dir, \"X_test_norm.npy\"))\n",
    "        y_train = np.load(os.path.join(fm_dir, \"y_train.npy\"))\n",
    "        y_test = np.load(os.path.join(fm_dir, \"y_test.npy\"))\n",
    "        used_scaler = scaler\n",
    "    else :\n",
    "        X_train = np.load(os.path.join(fm_dir, \"X_train.npy\"))\n",
    "        X_test = np.load(os.path.join(fm_dir, \"X_test.npy\"))\n",
    "        y_train = np.load(os.path.join(fm_dir, \"y_train.npy\"))\n",
    "        y_test = np.load(os.path.join(fm_dir, \"y_test.npy\"))\n",
    "        used_scaler = scaler\n",
    "\n",
    "n_classes = len(np.unique(y_train))\n",
    "\n",
    "\n",
    "# --- STEP 2: Reshape for CNN ---\n",
    "def reshape_for_cnn(arr):\n",
    "    if arr.ndim == 2:                         # (n_samples, 400) → (n,20,20,1)\n",
    "        side = int(np.sqrt(arr.shape[1]))\n",
    "        arr = arr.reshape((-1, side, side, 1))\n",
    "    elif arr.ndim == 3:                       # (n,20,20) → ajoute canal\n",
    "        arr = arr[..., np.newaxis]\n",
    "    return arr\n",
    "\n",
    "X_train = reshape_for_cnn(X_train)\n",
    "X_test  = reshape_for_cnn(X_test)\n",
    "\n",
    "# --- STEP 3: Model builder with hyperparams ---\n",
    "def build_cnn(conv_filters, dense_units, dropout_rate, kernel_size,\n",
    "              n_conv_layers, batch_norm, activation):\n",
    "\n",
    "    model = Sequential([Input(shape=X_train.shape[1:])])\n",
    "\n",
    "    for i in range(n_conv_layers):\n",
    "        model.add(Conv2D(conv_filters * (2**i),\n",
    "                         (kernel_size, kernel_size),\n",
    "                         activation=activation))\n",
    "        if batch_norm:\n",
    "            model.add(BatchNormalization())\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(dense_units, activation=activation))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(n_classes, activation='softmax'))\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# --- STEP 4: Cross-validation function for BO ---\n",
    "def cv_objective(conv_filters, dense_units, dropout_rate, epochs, batch_size,\n",
    "                 patience, kernel_size, n_conv_layers, batch_norm, activation):\n",
    "\n",
    "    # cast & mappings\n",
    "    conv_filters   = int(conv_filters)\n",
    "    dense_units    = int(dense_units)\n",
    "    kernel_size    = int(kernel_size)\n",
    "    n_conv_layers  = int(n_conv_layers)\n",
    "    batch_norm     = bool(round(batch_norm))\n",
    "    activation     = 'relu' if round(activation) == 0 else 'tanh'\n",
    "    epochs         = int(epochs)\n",
    "    batch_size     = int(batch_size)\n",
    "    patience       = int(patience)\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "    scores = []\n",
    "\n",
    "    for tr_idx, val_idx in skf.split(X_train, y_train):\n",
    "        X_tr, X_val = X_train[tr_idx], X_train[val_idx]\n",
    "        y_tr, y_val = y_train[tr_idx], y_train[val_idx]\n",
    "\n",
    "        y_tr_cat  = to_categorical(y_tr,  num_classes=n_classes)\n",
    "        y_val_cat = to_categorical(y_val, num_classes=n_classes)\n",
    "\n",
    "        model = build_cnn(conv_filters, dense_units, dropout_rate,\n",
    "                          kernel_size, n_conv_layers, batch_norm, activation)\n",
    "\n",
    "        es = EarlyStopping(patience=patience, restore_best_weights=True, verbose=0)\n",
    "        model.fit(X_tr, y_tr_cat,\n",
    "                  validation_data=(X_val, y_val_cat),\n",
    "                  epochs=epochs, batch_size=batch_size,\n",
    "                  verbose=0, callbacks=[es])\n",
    "\n",
    "        val_pred = np.argmax(model.predict(X_val, verbose=0), axis=1)\n",
    "        scores.append((val_pred == y_val).mean())\n",
    "\n",
    "    return np.mean(scores)\n",
    "\n",
    "# --- STEP 5: Bayesian Optimization space ---\n",
    "pbounds = {\n",
    "    'conv_filters': (16, 64),\n",
    "    'dense_units': (32, 256),\n",
    "    'dropout_rate': (0.1, 0.5),\n",
    "    'epochs': (5, 30),\n",
    "    'batch_size': (16, 64),\n",
    "    'patience': (2, 10),\n",
    "    'kernel_size': (3, 5),\n",
    "    'n_conv_layers': (1, 3),\n",
    "    'batch_norm': (0, 1),      # 0 = False, 1 = True\n",
    "    'activation': (0, 1)       # 0 = relu, 1 = tanh\n",
    "}\n",
    "\n",
    "optimizer = BayesianOptimization(f=cv_objective,\n",
    "                                 pbounds=pbounds,\n",
    "                                 random_state=42)\n",
    "\n",
    "print(\"🔍 Bayesian optimization en cours…\")\n",
    "optimizer.maximize(init_points=5, n_iter=45)\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 6) MEILLEURS PARAMÈTRES TROUVÉS\n",
    "#    ----------------------------------------------------\n",
    "best = optimizer.max['params']\n",
    "best['conv_filters']  = int(best['conv_filters'])\n",
    "best['dense_units']   = int(best['dense_units'])\n",
    "best['kernel_size']   = int(best['kernel_size'])\n",
    "best['n_conv_layers'] = int(best['n_conv_layers'])\n",
    "best['batch_norm']    = bool(round(best['batch_norm']))\n",
    "best['activation']    = 'relu' if round(best['activation']) == 0 else 'tanh'\n",
    "best['epochs']        = int(best['epochs'])\n",
    "best['batch_size']    = int(best['batch_size'])\n",
    "best['patience']      = int(best['patience'])\n",
    "\n",
    "print(\"\\n✅ Best hyper-parameters:\")\n",
    "print(f\"conv_filters = {int(best['conv_filters'])}\")\n",
    "print(f\"dense_units = {int(best['dense_units'])}\")\n",
    "print(f\"dropout_rate = {float(best['dropout_rate']):.2f}\")\n",
    "print(f\"kernel_size = {int(best['kernel_size'])}\")\n",
    "print(f\"n_conv_layers = {int(best['n_conv_layers'])}\")\n",
    "print(f\"batch_norm = {best['batch_norm']}\")\n",
    "print(f\"activation = {best['activation']}\")\n",
    "print(f\"epochs = {int(best['epochs'])}\")\n",
    "print(f\"batch_size = {int(best['batch_size'])}\")\n",
    "print(f\"patience = {int(best['patience'])}\")\n",
    "print(f\"CV Accuracy = {optimizer.max['target']:.4f}\")\n",
    "\n",
    "\"\"\"\n",
    "# ------------------------------------------------------------------\n",
    "# 7) ENTRAÎNEMENT FINAL SUR TOUT LE TRAIN, ÉVALUATION SUR TEST\n",
    "#    ----------------------------------------------------\n",
    "y_train_cat = to_categorical(y_train, num_classes=n_classes)\n",
    "y_test_cat  = to_categorical(y_test,  num_classes=n_classes)\n",
    "\n",
    "final_model = build_cnn(**best)\n",
    "es = EarlyStopping(patience=best['patience'], restore_best_weights=True)\n",
    "final_model.fit(X_train, y_train_cat,\n",
    "                validation_split=0.2,\n",
    "                epochs=best['epochs'],\n",
    "                batch_size=best['batch_size'],\n",
    "                callbacks=[es], verbose=1)\n",
    "\n",
    "y_pred = np.argmax(final_model.predict(X_test), axis=1)\n",
    "print(\"\\n📊 === HOLD-OUT TEST REPORT ===\")\n",
    "print(classification_report(y_test, y_pred, digits=4))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------ DATASET_2 ------------------\n",
    "\n",
    "AUG NORM :\n",
    "\n",
    "conv_filters = 35\n",
    "dense_units = 255\n",
    "dropout_rate = 0.2605200001496385\n",
    "kernel_size = 3\n",
    "n_conv_layers = 1\n",
    "batch_norm = True\n",
    "activation = relu\n",
    "epochs = 29\n",
    "batch_size = 29\n",
    "patience = 6\n",
    "CV Accuracy = 0.9105\n",
    "\n",
    "AUG NONORM\n",
    "\n",
    "conv_filters = 63\n",
    "dense_units = 184\n",
    "dropout_rate = 0.44\n",
    "kernel_size = 4\n",
    "n_conv_layers = 1\n",
    "batch_norm = True\n",
    "activation = relu\n",
    "epochs = 26\n",
    "batch_size = 57\n",
    "patience = 8\n",
    "CV Accuracy = 0.9097\n",
    "\n",
    "NOAUG NORM\n",
    "\n",
    "conv_filters = 45\n",
    "dense_units = 239\n",
    "dropout_rate = 0.34\n",
    "kernel_size = 3\n",
    "n_conv_layers = 1\n",
    "batch_norm = False\n",
    "activation = relu\n",
    "epochs = 23\n",
    "batch_size = 16\n",
    "patience = 8\n",
    "CV Accuracy = 0.8557\n",
    "\n",
    "NOAUG NONORM\n",
    "\n",
    "conv_filters = 48\n",
    "dense_units = 85\n",
    "dropout_rate = 0.21\n",
    "kernel_size = 3\n",
    "n_conv_layers = 1\n",
    "batch_norm = False\n",
    "activation = relu\n",
    "epochs = 29\n",
    "batch_size = 17\n",
    "patience = 6\n",
    "CV Accuracy = 0.8219\n",
    "\n",
    "\n",
    "------------------ DATASET_2_gun_from_1 ------------------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
