{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\"Machine learning tools\"\n",
    "import pickle\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from classification.datasets import Dataset\n",
    "from classification.utils.audio_student import AudioUtil, Feature_vector_DS\n",
    "\n",
    "from classification.utils.plots import (\n",
    "    plot_decision_boundaries,\n",
    "    plot_specgram,\n",
    "    show_confusion_matrix,\n",
    ")\n",
    "from classification.utils.utils import accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chainsaw\n",
      "fire\n",
      "fireworks\n",
      "gunshot\n"
     ]
    }
   ],
   "source": [
    "### TO RUN\n",
    "dataset = Dataset()\n",
    "classnames = dataset.list_classes()\n",
    "\n",
    "print(\"\\n\".join(classnames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TO RUN\n",
    "fm_dir = \"data/feature_matrices/\"  # where to save the features matrices\n",
    "new_dataset_dir = \"src/classification/datasets/new_dataset/melvecs/\"\n",
    "model_dir = \"data/models/random_forest\"  # where to save the models\n",
    "os.makedirs(fm_dir, exist_ok=True)\n",
    "os.makedirs(model_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TO RUN\n",
    "\n",
    "\"Creation of the dataset\"\n",
    "myds = Feature_vector_DS(dataset, Nft=512, nmel=20, duration=950, shift_pct=0.0)\n",
    "\n",
    "\"Some attributes...\"\n",
    "myds.nmel\n",
    "myds.duration\n",
    "myds.shift_pct\n",
    "myds.sr\n",
    "myds.data_aug\n",
    "myds.ncol\n",
    "\n",
    "\n",
    "idx = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'chainsaw': 315, 'fire': 303, 'fireworks': 315, 'gunshot': 40}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the training matrix : (779, 400)\n",
      "Shape of the test matrix : (194, 400)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "from sklearn.calibration import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "data_aug_factor = 1\n",
    "featveclen = len(myds[\"fire\", 0, \"\", \"\"])  # Same for all classes\n",
    "classnames = [\"chainsaw\", \"fire\", \"fireworks\", \"gunshot\"]  # Or wherever you store class names\n",
    "nclass = len(classnames)\n",
    "\n",
    "# Determine number of samples per class\n",
    "naudio_per_class = {cls: len(dataset.files.get(cls, [])) for cls in classnames}\n",
    "print(naudio_per_class)\n",
    "\n",
    "# Allocate feature matrix\n",
    "total_samples_basic = sum(naudio_per_class[c] for c in classnames)\n",
    "\n",
    "X_train = []\n",
    "X_test = []\n",
    "y_train = []\n",
    "y_test = []\n",
    "\n",
    "for class_idx, classname in enumerate(classnames):\n",
    "    for i in range(naudio_per_class[classname]):\n",
    "        featvec = myds[classname, i, \"\", \"\"]\n",
    "        if i < naudio_per_class[classname] * 0.8:\n",
    "            X_train.append(featvec)\n",
    "            y_train.append(classname)\n",
    "        else:\n",
    "            X_test.append(featvec)\n",
    "            y_test.append(classname)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train = np.array(X_train)\n",
    "X_test = np.array(X_test)\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "# Normalization of the data\n",
    "scaler = StandardScaler()\n",
    "X_train_norm = scaler.fit_transform(X_train)\n",
    "X_test_norm = scaler.transform(X_test)\n",
    "with open(os.path.join(model_dir, f\"scaler.pkl\"), \"wb\") as f:\n",
    "    pickle.dump(scaler, f)\n",
    "\n",
    "label_encoder           = LabelEncoder()\n",
    "y_train     = label_encoder.fit_transform(y_train)\n",
    "y_test      = label_encoder.transform(y_test)\n",
    "with open(os.path.join(model_dir, f\"label_encoder.pkl\"), \"wb\") as f:\n",
    "    pickle.dump(label_encoder, f)\n",
    "\n",
    "# Save the feature matrix and labels\n",
    "np.save(os.path.join(fm_dir, \"X_train.npy\"), X_train)\n",
    "np.save(os.path.join(fm_dir, \"X_test.npy\"), X_test)\n",
    "np.save(os.path.join(fm_dir, \"y_train.npy\"), y_train)\n",
    "np.save(os.path.join(fm_dir, \"y_test.npy\"), y_test)\n",
    "np.save(os.path.join(fm_dir, \"X_train_norm.npy\"), X_train_norm)\n",
    "np.save(os.path.join(fm_dir, \"X_test_norm.npy\"), X_test_norm)\n",
    "\n",
    "print(f\"Shape of the training matrix : {X_train.shape}\")\n",
    "print(f\"Shape of the test matrix : {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now create a new augmented dataset and observe if the classification results improve. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of transformations :  2\n",
      "Shape of the training matrix : (1556, 400)\n",
      "Shape of the test matrix : (191, 400)\n",
      "------------------------------------------------------------\n",
      "Transformations: ['original', 'shifting'].\n"
     ]
    }
   ],
   "source": [
    "### AUGMENTED DATASET\n",
    "TEST_WITH_AUGMENTED_FV = False\n",
    "\n",
    "list_augmentation = [\"original\", \"noise\", \"shifting\"]\n",
    "myds.mod_data_aug(list_augmentation)\n",
    "print(\"Number of transformations : \", myds.data_aug_factor)\n",
    "\n",
    "n_bands = 20\n",
    "frames = 20\n",
    "# Préparer les splits\n",
    "X_train_list, y_train_list = [], []\n",
    "X_test_list,  y_test_list  = [], []\n",
    "\n",
    "for classname in classnames:\n",
    "    n = naudio_per_class[classname]\n",
    "\n",
    "    # Création des indices de base pour les sons originaux\n",
    "    limit = round(n*0.8)\n",
    "    train_idx = list(range(limit))\n",
    "    test_idx  = list(range(limit+1, n))\n",
    "    \n",
    "    for i in train_idx:\n",
    "        for aug in list_augmentation:\n",
    "            featvec = myds[classname, i, aug, \"\"]\n",
    "            X_train_list.append(featvec)\n",
    "            y_train_list.append(classname)\n",
    "\n",
    "    for i in test_idx:\n",
    "        if TEST_WITH_AUGMENTED_FV:\n",
    "            for aug in list_augmentation:\n",
    "                featvec = myds[classname, i, aug, \"\"]\n",
    "                X_test_list.append(featvec)\n",
    "                y_test_list.append(classname)\n",
    "        else:\n",
    "            featvec = myds[classname, i, \"\", \"\"]\n",
    "            X_test_list.append(featvec)\n",
    "            y_test_list.append(classname)\n",
    "\n",
    "# Conversion en tableaux numpy\n",
    "X_train_aug = np.array(X_train_list)\n",
    "y_train_aug = np.array(y_train_list, dtype=object)\n",
    "\n",
    "X_test_aug = np.array(X_test_list)\n",
    "y_test_aug = np.array(y_test_list, dtype=object)\n",
    "\n",
    "# --- 1) Z-SCORE GLOBAL -------------------------------\n",
    "scaler_global = StandardScaler().fit(X_train_aug)\n",
    "X_train_aug_norm_zscore_global = scaler_global.transform(X_train_aug)\n",
    "X_test_aug_norm_zscore_global  = scaler_global.transform(X_test_aug)\n",
    "\n",
    "with open(os.path.join(model_dir, \"scaler_aug_zscore_global.pkl\"), \"wb\") as f:\n",
    "    pickle.dump(scaler_global, f)\n",
    "np.save(os.path.join(fm_dir, \"X_train_aug_norm_zscore_global.npy\"), X_train_aug_norm_zscore_global)\n",
    "np.save(os.path.join(fm_dir, \"X_test_aug_norm_zscore_global.npy\"),  X_test_aug_norm_zscore_global)\n",
    "\n",
    "# --- 2) Z-SCORE PAR BANDE MEL ------------------------------------\n",
    "X_train_resh = X_train_aug.reshape(-1, n_bands, frames)\n",
    "X_test_resh  = X_test_aug.reshape(-1, n_bands, frames)\n",
    "\n",
    "mean_band = X_train_resh.mean(axis=(0, 2))          # (20,)\n",
    "std_band  = X_train_resh.std(axis=(0, 2)) + 1e-8    # (20,)\n",
    "\n",
    "X_train_aug_norm_zscore_band = ((X_train_resh - mean_band[None,:,None])\n",
    "                           / std_band[None,:,None]).reshape(-1, n_bands*frames)\n",
    "X_test_aug_norm_zscore_band  = ((X_test_resh  - mean_band[None,:,None])\n",
    "                           / std_band[None,:,None]).reshape(-1, n_bands*frames)\n",
    "\n",
    "np.save(os.path.join(model_dir, \"zscore_band_mean.npy\"), mean_band)\n",
    "np.save(os.path.join(model_dir, \"zscore_band_std.npy\"),  std_band)\n",
    "np.save(os.path.join(fm_dir, \"X_train_aug_norm_zscore_band.npy\"), X_train_aug_norm_zscore_band)\n",
    "np.save(os.path.join(fm_dir, \"X_test_aug_norm_zscore_band.npy\"),  X_test_aug_norm_zscore_band)\n",
    "\n",
    "# --- 3) MIN-MAX PAR BANDE MEL ------------------------------------\n",
    "min_band = X_train_resh.min(axis=(0, 2))\n",
    "max_band = X_train_resh.max(axis=(0, 2)) + 1e-8\n",
    "\n",
    "X_train_aug_norm_minmax = ((X_train_resh - min_band[None,:,None])\n",
    "                           / (max_band - min_band)[None,:,None]).reshape(-1, n_bands*frames)\n",
    "X_test_aug_norm_minmax  = ((X_test_resh  - min_band[None,:,None])\n",
    "                           / (max_band - min_band)[None,:,None]).reshape(-1, n_bands*frames)\n",
    "\n",
    "np.save(os.path.join(model_dir, \"min_band.npy\"), min_band)\n",
    "np.save(os.path.join(model_dir, \"max_band.npy\"), max_band)\n",
    "np.save(os.path.join(fm_dir, \"X_train_aug_norm_minmax.npy\"), X_train_aug_norm_minmax)\n",
    "np.save(os.path.join(fm_dir, \"X_test_aug_norm_minmax.npy\"),  X_test_aug_norm_minmax)\n",
    "\n",
    "# --- 4) GLOBAL MAX NORMALIZATION -------------------------------\n",
    "# Chaque spectrogramme est divisé par son max propre (par ligne)\n",
    "X_train_aug_norm_max = X_train_aug.copy().astype(np.float32)\n",
    "X_test_aug_norm_max  = X_test_aug.copy().astype(np.float32)\n",
    "\n",
    "X_train_max = X_train_aug_norm_max.max(axis=1, keepdims=True) + 1e-8 # éviter la division par 0\n",
    "X_test_max  = X_test_aug_norm_max.max(axis=1, keepdims=True) + 1e-8\n",
    "\n",
    "X_train_aug_norm_max /= X_train_max\n",
    "X_test_aug_norm_max  /= X_test_max\n",
    "\n",
    "np.save(os.path.join(fm_dir, \"X_train_aug_norm_max.npy\"), X_train_aug_norm_max)\n",
    "np.save(os.path.join(fm_dir, \"X_test_aug_norm_max.npy\"),  X_test_aug_norm_max)\n",
    "\n",
    "# --- 5) L2 NORMALIZATION -------------------------------\n",
    "X_train_aug_norm_l2 = X_train_aug.copy().astype(np.float32)\n",
    "X_test_aug_norm_l2  = X_test_aug.copy().astype(np.float32)\n",
    "\n",
    "X_train_l2 = np.sqrt(np.sum(X_train_aug_norm_l2**2, axis=1, keepdims=True)) + 1e-8\n",
    "X_test_l2  = np.sqrt(np.sum(X_test_aug_norm_l2**2, axis=1, keepdims=True)) + 1e-8\n",
    "\n",
    "X_train_aug_norm_l2 /= X_train_l2\n",
    "X_test_aug_norm_l2  /= X_test_l2\n",
    "\n",
    "np.save(os.path.join(fm_dir, \"X_train_aug_norm_l2.npy\"), X_train_aug_norm_l2)\n",
    "np.save(os.path.join(fm_dir, \"X_test_aug_norm_l2.npy\"),  X_test_aug_norm_l2)\n",
    "\n",
    "\n",
    "# Label encoding\n",
    "label_encoder_aug = LabelEncoder()\n",
    "y_train_aug     = label_encoder_aug.fit_transform(y_train_aug)\n",
    "y_test_aug      = label_encoder_aug.transform(y_test_aug)\n",
    "with open(os.path.join(model_dir, f\"label_encoder_aug.pkl\"), \"wb\") as f:\n",
    "    pickle.dump(label_encoder_aug, f)\n",
    "\n",
    "np.save(os.path.join(fm_dir, \"X_train_aug.npy\"), X_train_aug)\n",
    "np.save(os.path.join(fm_dir, \"X_test_aug.npy\"), X_test_aug)\n",
    "np.save(os.path.join(fm_dir, \"y_train_aug.npy\"), y_train_aug)\n",
    "np.save(os.path.join(fm_dir, \"y_test_aug.npy\"), y_test_aug)\n",
    "\n",
    "print(f\"Shape of the training matrix : {X_train_aug.shape}\")\n",
    "print(f\"Shape of the test matrix : {X_test_aug.shape}\")\n",
    "print(f\"------------------------------------------------------------\")\n",
    "print(f\"Transformations: {list_augmentation}.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FINAL MODEL SAVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Scenario A: PCA NOAUG NONORM ===\n",
      "Overall accuracy : 0.6031  |  CV accuracy : 0.5829\n",
      "Class 0: P=0.658 R=0.794 Acc=0.794\n",
      "Class 1: P=0.691 R=0.633 Acc=0.633\n",
      "Class 2: P=0.424 R=0.397 Acc=0.397\n",
      "Class 3: P=1.000 R=0.500 Acc=0.500\n",
      "\n",
      "=== Scenario B: NOPCA NOAUG NONORM ===\n",
      "Overall accuracy : 0.7629  |  CV accuracy : 0.7833\n",
      "Class 0: P=0.833 R=0.794 Acc=0.794\n",
      "Class 1: P=0.769 R=0.833 Acc=0.833\n",
      "Class 2: P=0.678 R=0.635 Acc=0.635\n",
      "Class 3: P=0.800 R=1.000 Acc=1.000\n",
      "\n",
      "=== Scenario C: PCA AUG NONORM ===\n",
      "Overall accuracy : 0.6230  |  CV accuracy : 0.6020\n",
      "Class 0: P=0.686 R=0.774 Acc=0.774\n",
      "Class 1: P=0.702 R=0.667 Acc=0.667\n",
      "Class 2: P=0.421 R=0.387 Acc=0.387\n",
      "Class 3: P=1.000 R=1.000 Acc=1.000\n",
      "\n",
      "=== Scenario D: NOPCA AUG NONORM ===\n",
      "Overall accuracy : 0.8010  |  CV accuracy : 0.7853\n",
      "Class 0: P=0.862 R=0.806 Acc=0.806\n",
      "Class 1: P=0.831 R=0.900 Acc=0.900\n",
      "Class 2: P=0.724 R=0.677 Acc=0.677\n",
      "Class 3: P=0.700 R=1.000 Acc=1.000\n",
      "\n",
      "=== Scenario E: NOPCA NOAUG NONORM (alias) ===\n",
      "Overall accuracy : 0.7629  |  CV accuracy : 0.7833\n",
      "Class 0: P=0.833 R=0.794 Acc=0.794\n",
      "Class 1: P=0.769 R=0.833 Acc=0.833\n",
      "Class 2: P=0.678 R=0.635 Acc=0.635\n",
      "Class 3: P=0.800 R=1.000 Acc=1.000\n",
      "\n",
      "=== Scenario F: PCA NOAUG NORM ===\n",
      "Overall accuracy : 0.6753  |  CV accuracy : 0.6345\n",
      "Class 0: P=0.662 R=0.841 Acc=0.841\n",
      "Class 1: P=0.772 R=0.733 Acc=0.733\n",
      "Class 2: P=0.574 R=0.492 Acc=0.492\n",
      "Class 3: P=1.000 R=0.375 Acc=0.375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ppasture/master_projet_elec/LELEC210X/.venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Scenario G: PCA AUG NORM ===\n",
      "Overall accuracy : 0.6440  |  CV accuracy : 0.5293\n",
      "Class 0: P=0.615 R=0.774 Acc=0.774\n",
      "Class 1: P=0.648 R=0.767 Acc=0.767\n",
      "Class 2: P=0.690 R=0.468 Acc=0.468\n",
      "Class 3: P=0.000 R=0.000 Acc=0.000\n",
      "\n",
      "=== Scenario H: NOPCA AUG NORM ===\n",
      "Overall accuracy : 0.7330  |  CV accuracy : 0.6594\n",
      "Class 0: P=0.770 R=0.758 Acc=0.758\n",
      "Class 1: P=0.685 R=0.833 Acc=0.833\n",
      "Class 2: P=0.740 R=0.597 Acc=0.597\n",
      "Class 3: P=0.857 R=0.857 Acc=0.857\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score\n",
    "\n",
    "# =========================\n",
    "# 1) HYPERPARAMS & PATHS\n",
    "# =========================\n",
    "# Define or ensure these variables exist:\n",
    "# fm_dir = \"/path/to/features/\"\n",
    "# model_dir = \"/path/to/save/models/\"\n",
    "\n",
    "n_estimators = 400\n",
    "max_depth = 20\n",
    "min_samples_split = 5\n",
    "min_samples_leaf = 2\n",
    "random_state = 42\n",
    "\n",
    "# =========================\n",
    "# 2) LOAD DATA\n",
    "# =========================\n",
    "X_train_aug = np.load(os.path.join(fm_dir, \"X_train_aug.npy\"))\n",
    "X_test_aug = np.load(os.path.join(fm_dir, \"X_test_aug.npy\"))\n",
    "y_train_aug = np.load(os.path.join(fm_dir, \"y_train_aug.npy\"))\n",
    "y_test_aug = np.load(os.path.join(fm_dir, \"y_test_aug.npy\"))\n",
    "\n",
    "X_train_aug_norm = np.load(os.path.join(fm_dir, \"X_train_aug_norm_max.npy\"))\n",
    "X_test_aug_norm = np.load(os.path.join(fm_dir, \"X_test_aug_norm_max.npy\"))\n",
    "\n",
    "\n",
    "X_train = np.load(os.path.join(fm_dir, \"X_train.npy\"))\n",
    "X_test = np.load(os.path.join(fm_dir, \"X_test.npy\"))\n",
    "y_train = np.load(os.path.join(fm_dir, \"y_train.npy\"))\n",
    "y_test = np.load(os.path.join(fm_dir, \"y_test.npy\"))\n",
    "\n",
    "X_train_norm = np.load(os.path.join(fm_dir, \"X_train_norm.npy\"))\n",
    "X_test_norm = np.load(os.path.join(fm_dir, \"X_test_norm.npy\"))\n",
    "\n",
    "\n",
    "\n",
    "# FROM HERE MODIFY PLEASE CHAT GPT\n",
    "\n",
    "\n",
    "def save_obj(obj, name):\n",
    "    with open(os.path.join(model_dir, f\"{name}.pkl\"), \"wb\") as f:\n",
    "        pickle.dump(obj, f)\n",
    "\n",
    "def build_rf():\n",
    "    return RandomForestClassifier(\n",
    "        n_estimators=n_estimators,\n",
    "        max_depth=max_depth,\n",
    "        min_samples_split=min_samples_split,\n",
    "        min_samples_leaf=min_samples_leaf,\n",
    "        random_state=random_state,\n",
    "    )\n",
    "\n",
    "def evaluate(model, Xte, yte, tag):\n",
    "    pred   = model.predict(Xte)\n",
    "    acc    = (pred == yte).mean()\n",
    "    cv_acc = cross_val_score(model, Xte, yte, cv=5, scoring=\"accuracy\").mean()\n",
    "\n",
    "    classes = np.unique(yte)\n",
    "    prec = precision_score(yte, pred, average=None, labels=classes)\n",
    "    rec  = recall_score(yte, pred, average=None, labels=classes)\n",
    "    cm   = confusion_matrix(yte, pred, labels=classes)\n",
    "    per_cls_acc = [cm[i, i] / cm[i, :].sum() for i in range(len(classes))]\n",
    "\n",
    "    print(f\"\\n=== {tag} ===\")\n",
    "    print(f\"Overall accuracy : {acc:.4f}  |  CV accuracy : {cv_acc:.4f}\")\n",
    "    for i, c in enumerate(classes):\n",
    "        print(f\"Class {c}: P={prec[i]:.3f} R={rec[i]:.3f} Acc={per_cls_acc[i]:.3f}\")\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 3) SCÉNARIOS A → H\n",
    "# ------------------------------------------------------------------\n",
    "models = {}\n",
    "\n",
    "# A : PCA, no‑aug, no‑norm\n",
    "pca_A   = PCA(n_components=0.99).fit(X_train)\n",
    "Xtr_A   = pca_A.transform(X_train)\n",
    "Xte_A   = pca_A.transform(X_test)\n",
    "rf_A    = build_rf().fit(Xtr_A, y_train)\n",
    "save_obj(pca_A, \"pca_A\"); save_obj(rf_A, \"rf_A\")\n",
    "models[\"A\"] = (rf_A, Xte_A, y_test)\n",
    "\n",
    "# B : noPCA, no‑aug, no‑norm\n",
    "rf_B = build_rf().fit(X_train, y_train)\n",
    "save_obj(rf_B, \"rf_B\")\n",
    "models[\"B\"] = (rf_B, X_test, y_test)\n",
    "\n",
    "# C : PCA, aug, no‑norm\n",
    "pca_C  = PCA(n_components=0.99).fit(X_train_aug)\n",
    "Xtr_C  = pca_C.transform(X_train_aug)\n",
    "Xte_C  = pca_C.transform(X_test_aug)\n",
    "rf_C   = build_rf().fit(Xtr_C, y_train_aug)\n",
    "save_obj(pca_C, \"pca_C\"); save_obj(rf_C, \"rf_C\")\n",
    "models[\"C\"] = (rf_C, Xte_C, y_test_aug)\n",
    "\n",
    "# D : noPCA, aug, no‑norm\n",
    "rf_D = build_rf().fit(X_train_aug, y_train_aug)\n",
    "save_obj(rf_D, \"rf_D\")\n",
    "models[\"D\"] = (rf_D, X_test_aug, y_test_aug)\n",
    "\n",
    "# E : alias de B (noPCA, no‑aug, no‑norm)\n",
    "models[\"E\"] = models[\"B\"]\n",
    "\n",
    "# F : PCA, no‑aug, norm\n",
    "pca_F  = PCA(n_components=0.99).fit(X_train_norm)\n",
    "Xtr_F  = pca_F.transform(X_train_norm)\n",
    "Xte_F  = pca_F.transform(X_test_norm)\n",
    "rf_F   = build_rf().fit(Xtr_F, y_train)\n",
    "save_obj(pca_F, \"pca_F\"); save_obj(rf_F, \"rf_F\")\n",
    "models[\"F\"] = (rf_F, Xte_F, y_test)\n",
    "\n",
    "# G : PCA, aug, norm\n",
    "pca_G  = PCA(n_components=0.99).fit(X_train_aug_norm)\n",
    "Xtr_G  = pca_G.transform(X_train_aug_norm)\n",
    "Xte_G  = pca_G.transform(X_test_aug_norm)\n",
    "rf_G   = build_rf().fit(Xtr_G, y_train_aug)\n",
    "save_obj(pca_G, \"pca_G\"); save_obj(rf_G, \"rf_G\")\n",
    "models[\"G\"] = (rf_G, Xte_G, y_test_aug)\n",
    "\n",
    "# H : noPCA, aug, norm\n",
    "rf_H = build_rf().fit(X_train_aug_norm, y_train_aug)\n",
    "save_obj(rf_H, \"rf_H\")\n",
    "models[\"H\"] = (rf_H, X_test_aug_norm, y_test_aug)\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 4) ÉVALUATION GLOBALE\n",
    "# ------------------------------------------------------------------\n",
    "scenario_names = {\n",
    "    \"A\": \"PCA NOAUG NONORM\",\n",
    "    \"B\": \"NOPCA NOAUG NONORM\",\n",
    "    \"C\": \"PCA AUG NONORM\",\n",
    "    \"D\": \"NOPCA AUG NONORM\",\n",
    "    \"E\": \"NOPCA NOAUG NONORM (alias)\",\n",
    "    \"F\": \"PCA NOAUG NORM\",\n",
    "    \"G\": \"PCA AUG NORM\",\n",
    "    \"H\": \"NOPCA AUG NORM\",\n",
    "}\n",
    "\n",
    "for tag, (model, Xeval, yeval) in models.items():\n",
    "    evaluate(model, Xeval, yeval, f\"Scenario {tag}: {scenario_names[tag]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MEAN ACCURACY ON 20 ITERATIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimport os\\nimport numpy as np\\nimport pickle\\nimport matplotlib.pyplot as plt\\nfrom sklearn.ensemble import RandomForestClassifier\\nfrom sklearn.model_selection import train_test_split, cross_val_score\\nfrom sklearn.metrics import confusion_matrix, precision_score, recall_score\\nfrom classification.utils.utils import accuracy\\n\\nNORMALIZATION = True\\nTRANSFORMATION = True\\n\\n# Ensure dataset (X_aug, y_aug) exists\\n\\nif TRANSFORMATION:\\n    try:\\n        X = X_basic_aug\\n        y = y_basic_aug\\n    except NameError:\\n        raise ValueError(\"X_aug and y_aug must be defined before running this script.\")\\nelse:\\n    try:\\n        X = X_basic\\n        y = y_basic\\n    except NameError:\\n        raise ValueError(\"X and y must be defined before running this script.\")\\nif NORMALIZATION:\\n    X = np.array([x/np.linalg.norm(x) if np.linalg.norm(x) != 0 else x for x in X])\\n    \\n\\n\\n# Number of iterations\\nnum_iterations = 20\\n\\n# Lists to store scores\\naccuracy_scores = []\\ncv_accuracy_scores = []\\n\\nfor i in range(num_iterations):\\n    print(f\"\\nIteration {i + 1}/{num_iterations}\")\\n\\n    # Split the dataset into training and testing subsets\\n    X_train, X_test, y_train, y_test = train_test_split(\\n        X, y, test_size=0.3, stratify=y, random_state=i  # Different splits per iteration\\n    )\\n\\n    # Train the Random Forest model\\n    model = RandomForestClassifier(\\n        n_estimators=400,\\n        max_depth=20,\\n        min_samples_split=5,\\n        min_samples_leaf=2,\\n        random_state=i  # Different initialization per iteration\\n    )\\n    model.fit(X_train, y_train)\\n\\n    # Make predictions\\n    y_pred = model.predict(X_test)\\n\\n    # Compute overall accuracy\\n    test_accuracy = accuracy(y_pred, y_test)\\n    accuracy_scores.append(test_accuracy)\\n\\n    # Perform cross-validation on the training set\\n    cv_scores = cross_val_score(model, X_train, y_train, cv=10, scoring=\\'accuracy\\')\\n    mean_cv_accuracy = np.mean(cv_scores)\\n    cv_accuracy_scores.append(mean_cv_accuracy)\\n\\n    print(f\"Test Accuracy: {test_accuracy:.4f} | Mean CV Accuracy: {mean_cv_accuracy:.4f}\")\\n\\n# Compute overall statistics\\nmean_test_accuracy = np.mean(accuracy_scores)\\nstd_test_accuracy = np.std(accuracy_scores)\\n\\nmean_cv_accuracy = np.mean(cv_accuracy_scores)\\nstd_cv_accuracy = np.std(cv_accuracy_scores)\\n\\n# Print final results\\nprint(\"\\n=== FINAL RESULTS AFTER 20 ITERATIONS ===\")\\nprint(f\"Mean Test Accuracy: {mean_test_accuracy:.4f} ± {std_test_accuracy:.4f}\")\\nprint(f\"Mean Cross-Validation Accuracy: {mean_cv_accuracy:.4f} ± {std_cv_accuracy:.4f}\")\\n\\n'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score\n",
    "from classification.utils.utils import accuracy\n",
    "\n",
    "NORMALIZATION = True\n",
    "TRANSFORMATION = True\n",
    "\n",
    "# Ensure dataset (X_aug, y_aug) exists\n",
    "\n",
    "if TRANSFORMATION:\n",
    "    try:\n",
    "        X = X_basic_aug\n",
    "        y = y_basic_aug\n",
    "    except NameError:\n",
    "        raise ValueError(\"X_aug and y_aug must be defined before running this script.\")\n",
    "else:\n",
    "    try:\n",
    "        X = X_basic\n",
    "        y = y_basic\n",
    "    except NameError:\n",
    "        raise ValueError(\"X and y must be defined before running this script.\")\n",
    "if NORMALIZATION:\n",
    "    X = np.array([x/np.linalg.norm(x) if np.linalg.norm(x) != 0 else x for x in X])\n",
    "    \n",
    "\n",
    "\n",
    "# Number of iterations\n",
    "num_iterations = 20\n",
    "\n",
    "# Lists to store scores\n",
    "accuracy_scores = []\n",
    "cv_accuracy_scores = []\n",
    "\n",
    "for i in range(num_iterations):\n",
    "    print(f\"\\nIteration {i + 1}/{num_iterations}\")\n",
    "\n",
    "    # Split the dataset into training and testing subsets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.3, stratify=y, random_state=i  # Different splits per iteration\n",
    "    )\n",
    "\n",
    "    # Train the Random Forest model\n",
    "    model = RandomForestClassifier(\n",
    "        n_estimators=400,\n",
    "        max_depth=20,\n",
    "        min_samples_split=5,\n",
    "        min_samples_leaf=2,\n",
    "        random_state=i  # Different initialization per iteration\n",
    "    )\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Compute overall accuracy\n",
    "    test_accuracy = accuracy(y_pred, y_test)\n",
    "    accuracy_scores.append(test_accuracy)\n",
    "\n",
    "    # Perform cross-validation on the training set\n",
    "    cv_scores = cross_val_score(model, X_train, y_train, cv=10, scoring='accuracy')\n",
    "    mean_cv_accuracy = np.mean(cv_scores)\n",
    "    cv_accuracy_scores.append(mean_cv_accuracy)\n",
    "\n",
    "    print(f\"Test Accuracy: {test_accuracy:.4f} | Mean CV Accuracy: {mean_cv_accuracy:.4f}\")\n",
    "\n",
    "# Compute overall statistics\n",
    "mean_test_accuracy = np.mean(accuracy_scores)\n",
    "std_test_accuracy = np.std(accuracy_scores)\n",
    "\n",
    "mean_cv_accuracy = np.mean(cv_accuracy_scores)\n",
    "std_cv_accuracy = np.std(cv_accuracy_scores)\n",
    "\n",
    "# Print final results\n",
    "print(\"\\n=== FINAL RESULTS AFTER 20 ITERATIONS ===\")\n",
    "print(f\"Mean Test Accuracy: {mean_test_accuracy:.4f} ± {std_test_accuracy:.4f}\")\n",
    "print(f\"Mean Cross-Validation Accuracy: {mean_cv_accuracy:.4f} ± {std_cv_accuracy:.4f}\")\n",
    "\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
